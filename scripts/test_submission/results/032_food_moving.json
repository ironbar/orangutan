{"elapsed_time": 415.71115922927856, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.027500060386955738, -0.4084999095648527, 0.2635000143200159, 0.423500033095479, 0.22350004687905312], "steps": [117, 226, 58, 18, 68], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8589999545365572, 0.759000021032989, 0.8309999564662576, 0.8910000119358301, 0.7389999628067017], "steps": [34, 59, 41, 26, 64], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7739999732002616, 1.8419999685138464, 1.7419999754056334, 1.8739999663084745, 1.877999966032803], "steps": [55, 38, 63, 30, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.7250002874061465, 2.845000279136002, 2.6250002942979336, 2.861000039614737, 2.90500027500093], "steps": [67, 37, 92, 33, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7400001203641295, 3.876000110991299, 3.7320001209154725, 3.736000120639801, 3.024000408127904], "steps": [63, 29, 65, 64, 242], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.746999715454876, 4.663000198081136, 4.830999709665775, 4.634999723173678, 4.418999738059938], "steps": [61, 82, 40, 89, 143], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.1315000532194972, 0.34350003860890865, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [91, 38, 250, 250, 250], "results": [1, 1, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.6750000268220901, 0.8389999559149146, 0.7509999619796872, 0.7629999611526728, 0.7829999597743154], "steps": [80, 39, 61, 58, 53], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7740000924095511, 1.9099999638274312, 1.629999983124435, 1.8379999687895179, 1.421999997459352], "steps": [55, 21, 91, 39, 143], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.8490000404417515, 2.8090002816170454, 2.877000038512051, 2.9170000357553363, 2.8890000376850367], "steps": [36, 46, 29, 19, 26], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.1680001597851515, 3.936000106856227, 3.644000126980245, 3.032000407576561, 3.8400001134723425], "steps": [206, 14, 87, 240, 38], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.806999711319804, 4.763000191189349, 4.751000192016363, 4.92699970304966, 4.811000187881291], "steps": [46, 57, 60, 16, 45], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.27550004329532385, 0.02750003058463335, -0.39249994046986103, -0.12049992941319942, -0.3844999112188816], "steps": [55, 117, 222, 154, 220], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.826999956741929, 0.8150000171735883, 0.8390000155195594, 0.1310000643134117, 0.40700004529207945], "steps": [42, 45, 39, 216, 147], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.914999703876674, 4.2750002248212695, 4.810999711044133, 4.827000186778605, 4.826999709941447], "steps": [19, 179, 45, 41, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.12049992941319942, -0.10849996004253626, 0.02350006066262722, -1.003999930806458, 0.2835000427439809], "steps": [154, 151, 118, 250, 53], "results": [1, 1, 1, 0, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.11100006569176912, 0.7630000207573175, 0.8350000157952309, 0.3270000508055091, -1.003999930806458], "steps": [221, 58, 40, 167, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.863000184297562, 4.678999720141292, 4.950999701395631, 4.983000176027417, 4.803000188432634], "steps": [32, 78, 10, 2, 47], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.759000055026263, 0.5030000130645931, 0.5290000112727284, 0.8829999868758023, 0.8190000508911908], "steps": [119, 247, 234, 57, 89], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8690000474452972, 0.5530000096186996, 0.8710000473074615, 0.603000006172806, 0.8630000478588045], "steps": [64, 222, 63, 197, 67], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.4429998970590532, 0.810999991837889, 0.6330000041052699, 0.7010000590234995, 0.5710000679828227], "steps": [221, 93, 182, 148, 213], "results": [0, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.7210000576451421, 0.8249999908730388, 0.818999991286546, 0.8209999911487103, 0.7089999988675117], "steps": [138, 86, 89, 88, 144], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.9970000651665032, -0.189999935682863, -0.002999892458319664, 3.1499999738298357, 1.9950001249089837], "steps": [499, 94, 500, 422, 500], "results": [0.5, 0, 0, 1, 0.5]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9189999843947589, 0.9069999852217734, 0.705000058747828, 0.8909999863244593, -1.1350000374950469], "steps": [39, 45, 146, 53, 67], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.76700005447492, 0.880999987013638, 0.8810000466182828, 0.8289999905973673, 0.7749999943189323], "steps": [115, 58, 58, 84, 111], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.8310000500641763, 0.7190000577829778, -1.0730000417679548, 0.8209999911487103, 0.8249999908730388], "steps": [83, 139, 36, 88, 86], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, 0.8970000455155969, 0.9190000439994037, 0.8989999857731164, 0.9169999845325947], "steps": [47, 50, 39, 49, 40], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.5430000103078783, -1.0989999207668006, -1.1069999202154577, 0.8669999879784882, -1.0550000430084765], "steps": [227, 49, 53, 65, 27], "results": [1, 0, 0, 1, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0309999254532158, 0.36300002271309495, 0.7769999941810966, 0.8949999860487878, 0.5250000115483999], "steps": [15, 317, 110, 51, 236], "results": [0, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8709999877028167], "steps": [63], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.5770000079646707], "steps": [210], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.9230000437237322], "steps": [37], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.6330000041052699], "steps": [182], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.5570000093430281], "steps": [220], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.772999994456768], "steps": [112], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.06100004352629185], "steps": [468], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.8909999863244593], "steps": [53], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [0.6110000056214631], "steps": [193], "results": [1]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "RedRandomWall.yaml": {"rewards": [0.5770000079646707, -1.0019999309442937, 0.32900002505630255, 0.6210000645369291, 0.5930000068619847], "steps": [210, 500, 334, 188, 202], "results": [1, 0, 1, 1, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.864000026602298], "steps": [66], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.483999993186444], "steps": [256], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8419999685138464], "steps": [77], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.7560000936500728], "steps": [120], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7600000337697566], "steps": [118], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.869999966584146], "steps": [63], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.7300000358372927], "steps": [133], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.5510001801885664], "steps": [222], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8379999687895179], "steps": [79], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9669999810867012], "steps": [15], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.8049999922513962, 0.2770000286400318, 0.5730000082403421, 0.9509999821893871, 0.7529999958351254, 0.7289999974891543, -1.0019999309442937, -1.0019999309442937, 0.9569999817758799, 0.934999983292073], "steps": [96, 360, 212, 23, 122, 134, 500, 500, 20, 31], "results": [1, 1, 1, 1, 1, 1, 0, 0, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.8770000468939543, 0.19700003415346146, -1.0019999309442937, 0.8789999871514738, 0.8650000477209687, 0.8569999886676669, 0.9689999809488654, 0.6230000047944486, 0.3350000842474401, 0.8069999921135604], "steps": [60, 400, 500, 59, 66, 70, 14, 187, 331, 95], "results": [1, 1, 0, 1, 1, 1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.6010000063106418], "steps": [198], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_3.yaml": {"rewards": [0.4190000188536942], "steps": [289], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [0.45100001664832234], "steps": [273], "results": [1]}, "Ring_2.yaml": {"rewards": [0.04300004476681352], "steps": [477], "results": [1]}, "Ring_3.yaml": {"rewards": [-1.6879999269731343], "steps": [343], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.3099999530240893], "steps": [154], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.40966666326858103], "steps": [441], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.7229999932460487], "steps": [206], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937, 1.03600002406165, -0.0029999520629644394, 1.1780000738799572, 1.6359999827109277, -1.0019999309442937, -0.0029999520629644394], "steps": [499, 500, 500, 500, 480, 500, 409, 180, 500, 500], "results": [0.5, 0, 0.5, 0, 1, 0.5, 1, 1, 0, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 1.7379999672994018, -0.004999926313757896, -0.004999926313757896, -0.004999926313757896, -0.004999985918402672, 1.16200006660074, -1.003999930806458, 1.7060000291094184], "steps": [249, 250, 64, 250, 250, 250, 250, 208, 250, 72], "results": [0, 0, 1, 0.5, 0.5, 0.5, 0.5, 1, 0, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.7189999641850591, -1.003999930806458, -1.003999930806458, 0.1270000645890832, 0.4309999840334058, -1.003999930806458, 0.7669999608770013, -1.003999930806458, 0.9070000108331442, 0.3070000521838665], "steps": [69, 250, 250, 217, 141, 250, 57, 250, 22, 172], "results": [1, 0, 0, 1, 1, 0, 1, 0, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, 0.9110000105574727, 0.24699999671429396, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.23099999781697989, 0.7990000182762742, -1.003999930806458, 0.16300006210803986], "steps": [249, 21, 187, 250, 250, 250, 191, 49, 250, 208], "results": [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]}, "InternalMemory_3.yaml": {"rewards": [0.6990000121295452, 0.6990000121295452, 0.812333288602531, 0.872333349660039, 0.7723333472386003, 0.8123333482071757, 0.7256666794419289, 0.485666673630476, 0.6856666784733534, 0.712333345785737], "steps": [44, 44, 27, 18, 33, 27, 40, 76, 46, 42], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, 0.2290000393986702, -1.0099999774247408, 0.8390000257641077, -1.0099999774247408, 0.5490000322461128, 0.8690000250935555, 0.5290000326931477, 0.6190000306814909, 0.29900003783404827], "steps": [99, 76, 100, 15, 100, 44, 12, 46, 37, 69], "results": [0, 1, 0, 1, 0, 1, 1, 1, 1, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8710000133141875], "steps": [31], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.726984126984127, "level_03_obstacles": 0.8500000000000001, "level_04_avoidance": 0.375, "level_05_spatial_reasoning": 0.5, "level_06_generalization": 0.5, "level_07_internal_memory": 0.7, "level_09_advanced_preferences": 0.2, "mean_score": 0.5502834467120181}