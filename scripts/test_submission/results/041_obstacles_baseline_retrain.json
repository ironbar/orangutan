{"elapsed_time": 1872.6409919261932, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2675000438466668, 0.36750003695487976, 0.20750004798173904, 0.423500033095479, 0.31950004026293755], "steps": [57, 32, 72, 18, 44], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.7070000246167183, 0.8190000168979168, 0.8309999564662576, 0.8990000113844872, 0.759000021032989], "steps": [72, 44, 41, 24, 59], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7820000918582082, 1.853999967686832, 1.8540000868961215, 1.8739999663084745, 1.8659999668598175], "steps": [53, 35, 35, 30, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.6250000558793545, 2.853000278584659, 2.5170000633224845, 2.8650002777576447, 2.9050000365823507], "steps": [92, 35, 119, 32, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7400001203641295, 3.868000349961221, 3.7920001167804003, 3.8200001148507, 3.612000129185617], "steps": [63, 31, 50, 43, 95], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.8230001870542765, 4.714999717660248, 4.586999726481736, 4.667000197805464, 4.7070001950487494], "steps": [42, 69, 101, 81, 71], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.31950004026293755, 0.199500048533082, 0.4235000032931566, 0.3355000391602516, 0.2675000438466668], "steps": [44, 74, 18, 40, 57], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9310000091791153, 0.8429999556392431, 0.6910000257194042, 0.7790000196546316, 0.8309999564662576], "steps": [16, 38, 76, 54, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7819999726489186, 1.9179999632760882, 1.7339999759569764, 1.845999968238175, 1.7259999765083194], "steps": [53, 19, 65, 37, 67], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.697000050917268, 2.7770002838224173, 2.9130000360310078, 2.9090002747252584, 2.8970000371336937], "steps": [74, 54, 20, 21, 24], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.760000118985772, 3.9320003455504775, 3.8560003507882357, 3.7800001176074147, 3.884000110439956], "steps": [58, 15, 34, 53, 27], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.7629997143521905, 4.767000190913677, 4.822999710217118, 4.751000192016363, 4.811000187881291], "steps": [57, 56, 42, 60, 45], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.2915000421926379, 0.14750005211681128, 0.29150001239031553, 0.22350001707673073, 0.27550004329532385], "steps": [51, 87, 51, 68, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.2190000582486391, 0.42299998458474874, 0.3510000491514802, 0.8149999575689435, 0.5750000337138772], "steps": [194, 143, 161, 45, 105], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.471000211313367, 4.719000194221735, 4.794999712146819, 4.755000191740692, 4.1510002333670855], "steps": [130, 68, 49, 59, 210], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.19950001873075962, -0.016499966382980347, 0.051500058732926846, 0.12750005349516869, 0.15950002148747444], "steps": [74, 128, 111, 92, 84], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7830000193789601, 0.594999972730875, 0.7310000229626894, 0.8310000160709023, 0.7830000193789601], "steps": [53, 100, 66, 41, 53], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.86700018402189, 4.575000204145908, 4.9470001785084605, 4.983000176027417, 4.874999706633389], "steps": [31, 104, 11, 2, 29], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8369999900460243, 0.8710000473074615, 0.8709999877028167, 0.9190000439994037, 0.7629999951459467], "steps": [80, 63, 63, 39, 117], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9109999849461019, 0.8410000493749976, 0.8909999863244593, 0.8609999883919954, 0.9090000446885824], "steps": [43, 78, 53, 68, 44], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8169999914243817, 0.8969999859109521, -1.3090000255033374, 0.8910000459291041, 0.40300001995638013], "steps": [90, 50, 154, 53, 297], "results": [1, 1, 0, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.22100009210407734, 0.22700009169057012, 0.8069999921135604, 0.7549999956972897, 0.6430000034160912], "steps": [388, 385, 95, 121, 177], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.5419999468140304, 3.456000012345612, 0.5710000596009195, 1.9950001249089837, 3.4300000141374767], "steps": [226, 269, 213, 500, 282], "results": [1, 1, 0, 0.5, 1]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.9209999842569232, 0.9169999845325947, 0.9189999843947589, 0.9009999856352806], "steps": [36, 38, 40, 39, 48], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.7070000586099923, 0.9130000444129109, 0.8849999867379665, -0.24800001690164208, -1.0569999236613512], "steps": [145, 42, 56, 123, 28], "results": [1, 1, 1, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0449999244883657, 0.9089999850839376, -1.0669999229721725, -1.0830000410787761, 0.8709999877028167], "steps": [22, 44, 33, 41, 63], "results": [0, 1, 0, 0, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9070000448264182, 0.9090000446885824, 0.8850000463426113, 0.9250000435858965, 0.9230000437237322], "steps": [45, 44, 56, 36, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.6750000012107193, 0.9169999845325947, 0.42100007832050323, -1.0429999246262014, -1.03299992531538], "steps": [161, 40, 288, 21, 16], "results": [1, 1, 1, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7929999930784106, -1.0969999209046364, -1.0449999244883657, 0.921000043861568, 0.8810000466182828], "steps": [102, 48, 22, 38, 58], "results": [1, 0, 0, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8850000463426113], "steps": [56], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.9350000428967178], "steps": [31], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.880999987013638], "steps": [58], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.6989999995566905], "steps": [149], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.5510000097565353], "steps": [223], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.5390000701881945], "steps": [229], "results": [1]}, "RedWall_1.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [0.3990000202320516], "steps": [299], "results": [1]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.880999987013638, -1.0019999309442937, 0.40300001995638013, 0.12500003911554813, 0.5430000103078783], "steps": [58, 500, 297, 436, 227], "results": [1, 0, 1, 1, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.8439999683760107], "steps": [76], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8760000257752836], "steps": [60], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.861999967135489], "steps": [67], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.9140000231564045], "steps": [41], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.9000000241212547], "steps": [48], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8019999712705612], "steps": [97], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8899999652057886], "steps": [53], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.8430000408552587], "steps": [76], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8599999672733247], "steps": [68], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.8590000397525728], "steps": [68], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.840000028256327], "steps": [78], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240001756697893], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9509999821893871], "steps": [23], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [0.921000043861568], "steps": [38], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9669999810867012], "steps": [15], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9549999819137156, 0.9229999841190875, 0.6929999999701977, 0.9190000439994037, 0.9149999846704304, 0.864999988116324, 0.8029999923892319, 0.9549999819137156, 0.7970000524073839, 0.996999979019165], "steps": [21, 37, 152, 39, 41, 66, 97, 21, 100, 0], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.541000010445714, 0.6190000050701201, 0.5990000064484775, 0.9489999823272228, 0.9509999821893871, -1.0019999309442937, 0.7610000548884273, 0.7370000565424562, 0.9049999853596091, -1.0019999309442937], "steps": [228, 189, 199, 24, 23, 500, 118, 130, 46, 500], "results": [1, 1, 1, 1, 1, 0, 1, 1, 1, 0]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, 0.6110000312328339, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 96, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [0.6070000315085053, 0.7669999608770013, 0.751000021584332, 0.38300004694610834, 0.7870000191032887], "steps": [97, 57, 61, 153, 52], "results": [1, 1, 1, 1, 1]}, "Goal_on_platform_4.yaml": {"rewards": [0.5616666986607015, -1.0026666559278965, 0.3056667014025152, 0.7776666963472962, 0.7083333637565374], "steps": [163, 375, 259, 82, 108], "results": [1, 0, 1, 1, 1]}, "Goal_on_platform_5.yaml": {"rewards": [0.12300009885802865, 0.7349999970756471, 0.3610000228509307, 0.549000009894371, 0.7309999973513186], "steps": [437, 131, 318, 224, 133], "results": [1, 1, 1, 1, 1]}, "Goal_on_platform_6.yaml": {"rewards": [0.7589999614283442, 0.4150000447407365, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [59, 145, 250, 250, 250], "results": [1, 1, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [0.8910000459291041], "steps": [53], "results": [1]}, "Wall_with_ramp_2.yaml": {"rewards": [0.6710000270977616], "steps": [81], "results": [1]}, "Wall_with_obstacle_1.yaml": {"rewards": [0.41100001940503716], "steps": [293], "results": [1]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [0.6230000643990934], "steps": [187], "results": [1]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [0.42900007776916027], "steps": [284], "results": [1]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [0.3850000211969018], "steps": [306], "results": [1]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "Wall_with_tunnel_4.yaml": {"rewards": [0.6810000604018569], "steps": [158], "results": [1]}, "Wall_with_tunnel_5.yaml": {"rewards": [0.2830000282265246], "steps": [357], "results": [1]}, "Wall_with_tunnel_6.yaml": {"rewards": [0.756999995559454], "steps": [120], "results": [1]}, "Wall_middle.yaml": {"rewards": [0.6330000041052699], "steps": [182], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.42100007832050323], "steps": [288], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [0.16300003649666905], "steps": [417], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [0.7389999967999756], "steps": [129], "results": [1]}, "Navigation_1.yaml": {"rewards": [1.4699999941512942, 1.5820000460371375, 1.7820000918582082, 1.5959999854676425, 1.861999967135489], "steps": [263, 207, 107, 200, 67], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [1.707999977748841, 1.7599999741651118, 1.8139999704435468, 1.6220000432804227, 1.6460001012310386], "steps": [144, 118, 91, 187, 175], "results": [1, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [1.4580000545829535, 1.8620000267401338, 1.872000026050955, 1.5980000449344516, 1.6060000443831086], "steps": [269, 67, 62, 199, 195], "results": [1, 1, 1, 1, 1]}, "Navigation_4.yaml": {"rewards": [1.5500000482425094, 1.516000050585717, -1.0019999309442937, 1.2800000668503344, 1.6739999800920486], "steps": [223, 240, 500, 358, 161], "results": [1, 1, 0, 1, 1]}, "Navigation_5.yaml": {"rewards": [1.9080000235699117, 1.8919999650679529, 1.4479999956674874, 1.7500000344589353, 1.8819999657571316], "steps": [44, 52, 274, 123, 57], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.8840000252239406, 1.8280000290833414, 1.7180000366643071, 1.6979999784380198, 1.7240000958554447], "steps": [56, 84, 139, 149, 136], "results": [1, 1, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.8440000279806554, 1.7599999741651118, 1.7259999765083194, 1.7160000368021429, 1.7700000926852226], "steps": [76, 118, 135, 140, 113], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [-0.000999892596155405, 1.8360000881366432, -0.0029999520629644394, 1.8299999693408608, 1.1180000780150294], "steps": [499, 80, 500, 83, 439], "results": [0.5, 1, 0.5, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [1.7000000379048288, 1.324000063817948, 1.6519999816082418, 1.7679999736137688, 1.81800002977252], "steps": [148, 336, 172, 114, 89], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [1.0860000206157565, 1.6199999838136137, -0.002999892458319664, 1.6419999822974205, 1.6959999785758555], "steps": [455, 188, 500, 177, 150], "results": [1, 1, 0.5, 1, 1]}, "Navigation_on_platform_3.yaml": {"rewards": [1.424000056926161, 1.0960000199265778, 1.529999990016222, 1.656000040937215, -0.002999892458319664], "steps": [286, 450, 233, 170, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_on_platform_4.yaml": {"rewards": [1.6580000747926533, -0.6420000237412751, 1.8420000281184912, 1.1860000733286142, -1.0019999309442937], "steps": [169, 320, 77, 405, 500], "results": [1, 0, 1, 1, 0]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [1.362000061199069, 1.0580000225454569, 1.9279999625869095, 1.5660000471398234, 1.513999991118908], "steps": [317, 469, 34, 215, 241], "results": [1, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [1.4280000566504896, 1.6600000406615436, 1.5460001081228256, 1.553999988362193, -0.002999892458319664], "steps": [284, 168, 225, 221, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [1.6640000403858721, 1.8939999649301171, 1.910000023432076, -0.002999892458319664, 1.2080000122077763], "steps": [166, 51, 43, 500, 394], "results": [1, 1, 1, 0.5, 1]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [1.298000006005168, 1.632000042591244, 1.338000062853098, -0.002999892458319664, -1.0019999309442937], "steps": [349, 182, 329, 500, 500], "results": [1, 1, 1, 0.5, 0]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [1.5540000479668379, 1.81800002977252, -0.0029999520629644394, 1.3360000629909337, 1.8919999650679529], "steps": [221, 89, 500, 330, 52], "results": [1, 1, 0.5, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.7429999965243042], "steps": [127], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.6430000034160912], "steps": [177], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.3490000832825899], "steps": [324], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.40700001968070865], "steps": [295], "results": [1]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.5643332686740905], "steps": [325], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.2323332722298801], "steps": [574], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.24900009017437696, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [374, 500, 500, 500, 500], "results": [1, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [-1.4490000512450933, 0.7423333670012653, -5.387666861526668, 0.6983333108946681, -7.8553335391916335], "steps": [143, 34, 409, 36, 500], "results": [0, 1, 0, 1, 0]}, "ChessBoard_4.yaml": {"rewards": [-3.0743334302678704, 0.41366670932620764, -3.312333334237337, -2.9836668078787625, 0.5416666478849947], "steps": [259, 45, 318, 267, 41], "results": [0, 1, 0, 0, 1]}, "Labyrinth_1.yaml": {"rewards": [-1.8894445423502475, 0.7069999813102186, -6.73022238095291, -5.48133350443095, -6.1568890602793545], "steps": [372, 38, 750, 750, 750], "results": [0, 1, 0, 0, 0]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.5043333154171705, -6.455333282705396, -9.53533359663561, -6.5443335068412125, -7.382000043522567], "steps": [33, 500, 500, 444, 500], "results": [1, 0, 0, 0, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7576666576787829], "steps": [36], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7483333265408874], "steps": [35], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.712333326227963], "steps": [34], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-1.7280000178143382], "steps": [181], "results": [0]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [-1.4120000395923853], "steps": [102], "results": [0]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.6950000254437327], "steps": [75], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [-1.0960000613704324], "steps": [23], "results": [0]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8449999820441008], "steps": [36], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.1963333855383098], "steps": [107], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8429999840445817], "steps": [37], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.6516666547395289], "steps": [66], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.6276666512712836], "steps": [48], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.7120000370778143, 1.3879999998025596, 1.8500000275671482, 1.6540000410750508, 1.6099999845027924, 1.5879999860189855, 1.6400001016445458, 1.6520001008175313, 1.6980000380426645, -1.0019999309442937], "steps": [142, 304, 73, 171, 193, 204, 178, 172, 149, 500], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 1.610000035725534, 1.0060000773519278, 1.413999930024147, 1.4900000439956784, -0.004999926313757896, -0.004999926313757896, 1.6099999761208892, -0.004999985918402672], "steps": [249, 250, 96, 247, 145, 126, 250, 250, 96, 250], "results": [0, 0, 1, 1, 1, 1, 0.5, 0.5, 1, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.6270000301301479, -1.003999930806458, 0.7910000188276172, 0.9110000105574727, 0.7589999614283442, 0.47900004032999277, 0.4389999834820628, 0.8869999526068568, 0.7909999592229724, 0.14700006321072578], "steps": [92, 250, 51, 21, 59, 129, 139, 27, 51, 212], "results": [1, 0, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.19900000002235174, 0.8350000157952309, -1.003999930806458, 0.9350000089034438, -1.003999930806458, 0.17500000167638063, 0.8509999550879002, -1.003999930806458, 0.8629999542608857, 0.9030000111088157], "steps": [199, 40, 250, 15, 250, 205, 36, 250, 33, 23], "results": [1, 1, 0, 1, 0, 1, 1, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.792333347722888, 0.7590000135824084, 0.805666621774435, 0.6723333448171616, 0.7990000145509839, 0.7390000130981207, 0.5856666760519147, 0.7390000130981207, 0.4923333404585719, 0.7723333472386003], "steps": [30, 35, 28, 48, 29, 38, 61, 38, 75, 33], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.7790000271052122, 0.37900003604590893, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.3990000355988741, -1.0099999774247408, 0.8490000255405903, -1.0099999774247408, -1.0099999774247408], "steps": [21, 61, 100, 100, 100, 59, 100, 14, 100, 100], "results": [1, 1, 0, 0, 0, 1, 0, 1, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8709999537095428], "steps": [31], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [0.7469999622553587], "steps": [62], "results": [1]}, "forcedChoice_5.yaml": {"rewards": [0.8909999523311853], "steps": [26], "results": [0]}}}, "level_01_food": 0.7380952380952381, "level_02_preferences": 1.0, "level_03_obstacles": 0.8318181818181819, "level_04_avoidance": 0.4842105263157894, "level_05_spatial_reasoning": 0.9, "level_06_generalization": 0.65, "level_07_internal_memory": 0.75, "level_09_advanced_preferences": 0.4, "mean_score": 0.7192654932786512}