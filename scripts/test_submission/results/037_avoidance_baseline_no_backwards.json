{"elapsed_time": 447.67368602752686, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, 0.423500033095479, -0.13249992858618498], "steps": [249, 250, 250, 18, 157], "results": [0, 0, 0, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8789999531581998, -1.003999930806458, 0.8469999553635716, -1.003999930806458, 0.04300007037818432], "steps": [29, 250, 37, 250, 238], "results": [1, 0, 1, 0, 1]}, "GoodGoal_size2.yaml": {"rewards": [-0.9999999310821295, 1.8419999685138464, 1.1740001337602735, 1.190000013448298, 1.3180001238361], "steps": [249, 38, 205, 201, 169], "results": [0, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.2250000834465027, -1.003999930806458, 2.4450003067031503, 2.845000279136002, 2.9090000363066792], "steps": [192, 250, 137, 37, 21], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [-0.9999999310821295, 3.868000111542642, 3.7000001231208444, 3.776000117883086, -1.003999930806458], "steps": [249, 31, 73, 54, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.479000210762024, 4.843000185675919, 4.71099971793592, 4.126999758183956], "steps": [249, 128, 37, 70, 216], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.7950000185519457, -1.003999930806458, -1.003999930806458, 0.6470000287517905], "steps": [249, 50, 250, 250, 87], "results": [0, 1, 0, 0, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7940000910311937, 1.4620001139119267, 1.7219999767839909, 1.8419999685138464, 1.7980000907555223], "steps": [50, 133, 68, 38, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.677000052295625, 2.805000043474138, 2.4770000660791993, 2.9090000363066792, 2.877000038512051], "steps": [79, 47, 129, 21, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [-0.9999999310821295, 3.9320001071318984, 3.6760001247748733, -1.003999930806458, 3.5400003725662827], "steps": [249, 15, 79, 250, 113], "results": [0, 1, 1, 0, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.0629997625947, -1.003999930806458, -1.003999930806458, 4.547000206075609, 4.527000207453966], "steps": [232, 250, 250, 111, 116], "results": [1, 0, 0, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.6470000287517905, -1.003999930806458, -1.003999930806458, 0.16700006183236837], "steps": [249, 87, 250, 250, 207], "results": [0, 1, 0, 0, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.7310001933947206, -1.003999930806458, 4.775000190362334, 4.806999711319804, 4.243000227026641], "steps": [65, 250, 54, 46, 187], "results": [1, 0, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, -0.23249992169439793, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 182, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.5630000345408916, -1.003999930806458, 0.09900006651878357, 0.18700006045401096], "steps": [249, 108, 250, 224, 202], "results": [0, 1, 0, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.86700018402189, -1.003999930806458, 4.927000179886818, 4.983000176027417, 4.851000185124576], "steps": [31, 250, 16, 2, 35], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.1369999181479216, -1.0930000403895974, -1.0409999247640371, -1.0489999242126942, -1.0370000442489982], "steps": [68, 46, 20, 24, 18], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0589999235235155, -1.1029999204911292, -1.070999922696501, -1.0509999240748584, -1.0489999242126942], "steps": [29, 51, 35, 25, 24], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.1129999198019505, -1.0530000431463122, -1.0509999240748584, -1.0370000442489982, -1.1909999144263566], "steps": [56, 26, 25, 18, 95], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.0530000431463122, -1.178999915253371, -1.2009999137371778, -1.0630000424571335, -1.224999912083149], "steps": [26, 89, 100, 31, 112], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.2909999075345695, -0.13599987979978323, -0.10800000093877316, -1.0570000428706408, -1.051000043284148], "steps": [145, 67, 53, 28, 25], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.665000001899898, -1.57299988809973, -1.054999923799187, -1.062999923247844, 0.8089999919757247], "steps": [166, 286, 27, 31, 94], "results": [1, 0, 0, 0, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [-1.070999922696501, -1.105000039562583, -1.1390000372193754, -1.0389999249018729, 0.5770000079646707], "steps": [35, 52, 69, 19, 210], "results": [0, 0, 0, 0, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.054999923799187, -1.0929999211803079, -1.2629999094642699, -1.0769999222829938, -1.0569999236613512], "steps": [27, 46, 131, 38, 28], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.87500004703179, -1.186999914702028, -1.0689999228343368, -1.0649999231100082, -1.0949999210424721], "steps": [61, 93, 34, 32, 47], "results": [1, 0, 0, 0, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-2.061999995727092, -1.0969999209046364, -1.0170000456273556, -1.178999915253371, -1.4789998945780098], "steps": [31, 48, 8, 89, 239], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0229999260045588, -1.2650000285357237, -1.0949999210424721, -1.0690000420436263, -1.0529999239370227], "steps": [11, 132, 47, 34, 26], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-2.0419999971054494], "steps": [21], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-2.0359999975189567], "steps": [18], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.0409999247640371], "steps": [20], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.0429999246262014], "steps": [21], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.03299992531538], "steps": [16], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0170000456273556], "steps": [8], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [-1.0470000435598195], "steps": [23], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.037999997381121], "steps": [19], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.038999831303954], "steps": [20], "results": [0]}, "RedWall_1.yaml": {"rewards": [-1.0609999233856797], "steps": [30], "results": [0]}, "RedWall_2.yaml": {"rewards": [-1.0569999236613512], "steps": [28], "results": [0]}, "RedWall_3.yaml": {"rewards": [-2.0579999960027635], "steps": [29], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.0630000424571335], "steps": [31], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.0630000424571335], "steps": [31], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0729999225586653], "steps": [36], "results": [0]}, "RedWall_7.yaml": {"rewards": [-1.0530000431463122], "steps": [26], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-2.2519999826326966, -1.0490000434219837, -1.1529999170452356, -1.054999923799187, -1.0729999225586653], "steps": [126, 24, 76, 27, 36], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.8359999689273536], "steps": [80], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [-0.000999892596155405], "steps": [499], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [1.6900000385940075], "steps": [153], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7340000355616212], "steps": [131], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.2040000124834478], "steps": [396], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.5220000501722097], "steps": [237], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.968000172637403], "steps": [14], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.7679999736137688], "steps": [114], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9700001724995673], "steps": [13], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, 0.937000042758882, 0.9310000431723893, 0.4390000174753368, -1.0019999309442937, -1.0019999309442937, 0.9569999817758799, 0.3970000799745321], "steps": [499, 500, 500, 30, 33, 279, 500, 500, 20, 300], "results": [0, 0, 0, 1, 1, 1, 0, 0, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.3070000265724957, -1.0019999309442937, 0.7070000586099923, -1.0019999309442937, -1.0019999309442937, 0.16100009623914957, -1.0019999309442937, -1.0019999309442937, 0.7930000526830554, 0.2870000875554979], "steps": [345, 500, 145, 500, 500, 418, 500, 500, 102, 355], "results": [1, 0, 1, 0, 0, 1, 0, 0, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8509999890811741], "steps": [73], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8369999900460243], "steps": [80], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7849999936297536], "steps": [106], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.36300002271309495], "steps": [317], "results": [1]}, "Ring_1.yaml": {"rewards": [0.8229999910108745], "steps": [87], "results": [1]}, "Ring_2.yaml": {"rewards": [-1.1439998452551663], "steps": [71], "results": [0]}, "Ring_3.yaml": {"rewards": [0.595000006724149], "steps": [201], "results": [1]}, "Ring_4.yaml": {"rewards": [-1.1279998463578522], "steps": [63], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.2279999586753547], "steps": [113], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.1106665688566864], "steps": [82], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.2760000196285546], "steps": [206], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.45499999611638486], "steps": [407], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.48966666241176426], "steps": [381], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.8029999923892319, 0.8489999892190099, 0.4630000158213079, -1.0019999309442937, 0.8070000517182052], "steps": [97, 74, 267, 500, 95], "results": [1, 1, 1, 0, 1]}, "ChessBoard_2.yaml": {"rewards": [0.657000002451241, -1.0019999309442937, 0.12700009858235717, 0.2770000882446766, 0.7890000529587269], "steps": [170, 500, 435, 360, 104], "results": [1, 0, 1, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [0.8349999901838601, 0.8169999914243817, 0.509000055026263, 0.7549999956972897, 0.7089999988675117], "steps": [81, 90, 124, 121, 144], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.4796666717156768, 0.35233335429802537, 0.8430000492371619, -1.3553332681767642, 0.5690000681206584], "steps": [202, 309, 77, 500, 214], "results": [1, 1, 1, 0, 1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 1.5659999875351787], "steps": [499, 500, 500, 500, 500, 500, 500, 500, 500, 215], "results": [0.5, 0.5, 0.5, 0, 0, 0.5, 0, 0, 0, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -0.004999985918402672, -1.003999930806458, -0.004999926313757896, -1.003999930806458, -1.003999930806458, -0.004999926313757896, 1.858000018633902, -0.004999985918402672, -1.003999930806458], "steps": [249, 250, 250, 250, 250, 250, 250, 34, 250, 250], "results": [0, 0.5, 0, 0.5, 0, 0, 0.5, 1, 0.5, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, 0.40300004556775093, 0.4189999848604202, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.8910000119358301, -1.003999930806458], "steps": [249, 250, 250, 148, 144, 250, 250, 250, 26, 250], "results": [0, 0, 0, 1, 1, 0, 0, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.9030000111088157, 0.370999988168478, 0.934999949298799, -1.003999930806458, -1.003999930806458, 0.9470000080764294, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [23, 156, 15, 250, 250, 12, 250, 250, 250, 250], "results": [1, 1, 1, 0, 0, 1, 0, 0, 0, 0]}, "InternalMemory_3.yaml": {"rewards": [0.8456666823476553, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, 0.2256666673347354, -1.0066666910424829, -1.0066666910424829], "steps": [22, 150, 150, 150, 150, 150, 150, 115, 150, 150], "results": [1, 0, 0, 0, 0, 0, 0, 1, 0, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, -1.0099999774247408, 0.42900003492832184, -1.0099999774247408, 0.19900004006922245, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.5890000313520432], "steps": [99, 100, 100, 56, 100, 79, 100, 100, 100, 40], "results": [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8430000152438879], "steps": [38], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-1.6509999763220549], "steps": [162], "results": [0]}}}, "level_01_food": 0.273015873015873, "level_03_obstacles": 0.5, "level_04_avoidance": 0.5700000000000001, "level_05_spatial_reasoning": 0.3, "level_06_generalization": 0.3, "level_07_internal_memory": 0.3, "level_09_advanced_preferences": 0.2, "mean_score": 0.3490022675736962}