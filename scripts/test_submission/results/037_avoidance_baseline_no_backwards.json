{"elapsed_time": 681.000661611557, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, 0.423500033095479, -0.13249992858618498], "steps": [249, 250, 250, 18, 157], "results": [0, 0, 0, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8789999531581998, -1.003999930806458, 0.8469999553635716, -1.003999930806458, 0.04300007037818432], "steps": [29, 250, 37, 250, 238], "results": [1, 0, 1, 0, 1]}, "GoodGoal_size2.yaml": {"rewards": [-0.9999999310821295, 1.8419999685138464, 1.1740001337602735, 1.190000013448298, 1.3180001238361], "steps": [249, 38, 205, 201, 169], "results": [0, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.2250000834465027, -1.003999930806458, 2.4450003067031503, 2.845000279136002, 2.9090000363066792], "steps": [192, 250, 137, 37, 21], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [-0.9999999310821295, 3.868000111542642, 3.7000001231208444, 3.776000117883086, -1.003999930806458], "steps": [249, 31, 73, 54, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.479000210762024, 4.843000185675919, 4.71099971793592, 4.126999758183956], "steps": [249, 128, 37, 70, 216], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.7950000185519457, -1.003999930806458, -1.003999930806458, 0.6470000287517905], "steps": [249, 50, 250, 250, 87], "results": [0, 1, 0, 0, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7940000910311937, 1.4620001139119267, 1.7219999767839909, 1.8419999685138464, 1.7980000907555223], "steps": [50, 133, 68, 38, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.677000052295625, 2.805000043474138, 2.4770000660791993, 2.9090000363066792, 2.877000038512051], "steps": [79, 47, 129, 21, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [-0.9999999310821295, 3.9320001071318984, 3.6760001247748733, -1.003999930806458, 3.5400003725662827], "steps": [249, 15, 79, 250, 113], "results": [0, 1, 1, 0, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.0629997625947, -1.003999930806458, -1.003999930806458, 4.547000206075609, 4.527000207453966], "steps": [232, 250, 250, 111, 116], "results": [1, 0, 0, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.6470000287517905, -1.003999930806458, -1.003999930806458, 0.16700006183236837], "steps": [249, 87, 250, 250, 207], "results": [0, 1, 0, 0, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.7310001933947206, -1.003999930806458, 4.775000190362334, 4.806999711319804, 4.243000227026641], "steps": [65, 250, 54, 46, 187], "results": [1, 0, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, -0.23249992169439793, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 182, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.5630000345408916, -1.003999930806458, 0.09900006651878357, 0.18700006045401096], "steps": [249, 108, 250, 224, 202], "results": [0, 1, 0, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.86700018402189, -1.003999930806458, 4.927000179886818, 4.983000176027417, 4.851000185124576], "steps": [31, 250, 16, 2, 35], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.1369999181479216, -1.0930000403895974, -1.0409999247640371, -1.0489999242126942, -1.0370000442489982], "steps": [68, 46, 20, 24, 18], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0589999235235155, -1.1029999204911292, -1.070999922696501, -1.0509999240748584, -1.0489999242126942], "steps": [29, 51, 35, 25, 24], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.1129999198019505, -1.0530000431463122, -1.0509999240748584, -1.0370000442489982, -1.1909999144263566], "steps": [56, 26, 25, 18, 95], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.0530000431463122, -1.178999915253371, -1.2009999137371778, -1.0630000424571335, -1.224999912083149], "steps": [26, 89, 100, 31, 112], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.2909999075345695, -0.13599987979978323, -0.10800000093877316, -1.0570000428706408, -1.051000043284148], "steps": [145, 67, 53, 28, 25], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.665000001899898, -1.57299988809973, -1.054999923799187, -1.062999923247844, 0.8089999919757247], "steps": [166, 286, 27, 31, 94], "results": [1, 0, 0, 0, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [-1.070999922696501, -1.105000039562583, -1.1390000372193754, -1.0389999249018729, 0.5770000079646707], "steps": [35, 52, 69, 19, 210], "results": [0, 0, 0, 0, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.054999923799187, -1.0929999211803079, -1.2629999094642699, -1.0769999222829938, -1.0569999236613512], "steps": [27, 46, 131, 38, 28], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.87500004703179, -1.186999914702028, -1.0689999228343368, -1.0649999231100082, -1.0949999210424721], "steps": [61, 93, 34, 32, 47], "results": [1, 0, 0, 0, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-2.061999995727092, -1.0969999209046364, -1.0170000456273556, -1.178999915253371, -1.4789998945780098], "steps": [31, 48, 8, 89, 239], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0229999260045588, -1.2650000285357237, -1.0949999210424721, -1.0690000420436263, -1.0529999239370227], "steps": [11, 132, 47, 34, 26], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-2.0419999971054494], "steps": [21], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-2.0359999975189567], "steps": [18], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.0409999247640371], "steps": [20], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.0429999246262014], "steps": [21], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.03299992531538], "steps": [16], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0170000456273556], "steps": [8], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [-1.0470000435598195], "steps": [23], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.037999997381121], "steps": [19], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.038999831303954], "steps": [20], "results": [0]}, "RedWall_1.yaml": {"rewards": [-1.0609999233856797], "steps": [30], "results": [0]}, "RedWall_2.yaml": {"rewards": [-1.0569999236613512], "steps": [28], "results": [0]}, "RedWall_3.yaml": {"rewards": [-2.0579999960027635], "steps": [29], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.0630000424571335], "steps": [31], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.0630000424571335], "steps": [31], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0729999225586653], "steps": [36], "results": [0]}, "RedWall_7.yaml": {"rewards": [-1.0530000431463122], "steps": [26], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-2.2519999826326966, -1.0490000434219837, -1.1529999170452356, -1.054999923799187, -1.0729999225586653], "steps": [126, 24, 76, 27, 36], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.8359999689273536], "steps": [80], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [-0.000999892596155405], "steps": [499], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [1.6900000385940075], "steps": [153], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7340000355616212], "steps": [131], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.2040000124834478], "steps": [396], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.5220000501722097], "steps": [237], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.968000172637403], "steps": [14], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.7679999736137688], "steps": [114], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9700001724995673], "steps": [13], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9169999845325947], "steps": [40], "results": [0]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.6640001935884356], "steps": [166], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9660001727752388], "steps": [15], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [2.9690001257695258], "steps": [13], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [0.9710000404156744], "steps": [13], "results": [0]}, "Green_sizes12_9.yaml": {"rewards": [0.9710000404156744], "steps": [13], "results": [0]}, "Green_sizes12_10.yaml": {"rewards": [0.9450000422075391], "steps": [26], "results": [0]}, "Green_sizes12_11.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9409999828785658, 0.9229999841190875, 0.4950000732205808, 0.8869999866001308, 0.9190000439994037, -1.0019999309442937, 0.8369999900460243, 0.9549999819137156, 0.7589999954216182, 0.996999979019165], "steps": [28, 37, 251, 55, 39, 500, 80, 21, 119, 0], "results": [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, 0.9529999820515513, 0.9469999824650586, -1.0019999309442937, 0.8289999905973673, 0.2670000293292105, 0.8589999885298312, 0.3550000828690827], "steps": [499, 500, 500, 22, 25, 500, 84, 365, 69, 321], "results": [0, 0, 0, 1, 1, 0, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8570000482723117], "steps": [70], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.826999990735203], "steps": [85], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7589999954216182], "steps": [119], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.41100001940503716], "steps": [293], "results": [1]}, "Ring_1.yaml": {"rewards": [0.7389999967999756], "steps": [129], "results": [1]}, "Ring_2.yaml": {"rewards": [-1.3479998311959207], "steps": [173], "results": [0]}, "Ring_3.yaml": {"rewards": [0.718999998178333], "steps": [139], "results": [1]}, "Ring_4.yaml": {"rewards": [-1.1679998436011374], "steps": [83], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.1519998447038233], "steps": [75], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.0919999023899436], "steps": [68], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [0.7029999934602529], "steps": [221], "results": [1]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.6763333270791918], "steps": [241], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.6629999342840165], "steps": [251], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.8009999925270677, 0.6290000639855862, 0.6930000595748425, -1.0019999309442937, 0.8470000489614904], "steps": [98, 184, 152, 500, 75], "results": [1, 1, 1, 0, 1]}, "ChessBoard_2.yaml": {"rewards": [-1.0399998524226248, -1.083999968599528, 0.5590000092051923, 0.7770000537857413, 0.7110000583343208], "steps": [19, 41, 219, 110, 143], "results": [0, 0, 1, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [-0.025666651781648397, 0.843000044580549, 0.9089999850839376, 0.8549999827519059, 0.6263333349488676], "steps": [338, 47, 44, 41, 172], "results": [0, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.48900001402944326, 0.7756666564382613, 0.1716666971333325, 0.7216666559688747, -1.0486665982753038], "steps": [254, 84, 386, 91, 500], "results": [1, 1, 1, 1, 0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -0.002999892458319664, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937, -0.0029999520629644394], "steps": [499, 500, 500, 500, 500, 500, 500, 500, 500, 500], "results": [0.5, 0.5, 0.5, 0, 0, 0, 0, 0.5, 0, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [1.6740000313147902, -1.003999930806458, -0.004999985918402672, -0.004999926313757896, -1.003999930806458, -0.004999985918402672, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [80, 250, 250, 250, 250, 250, 250, 250, 250, 250], "results": [1, 0, 0.5, 0.5, 0, 0.5, 0, 0, 0, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.2829999942332506, -1.003999930806458, 0.11100000608712435, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.10700000636279583, -1.003999930806458], "steps": [249, 250, 178, 250, 221, 250, 250, 250, 222, 250], "results": [0, 0, 1, 0, 1, 0, 0, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.9350000089034438, 0.9110000105574727, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.9949999451637268, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 15, 21, 250, 250, 250, 0, 250, 250], "results": [0, 0, 1, 1, 0, 0, 0, 1, 0, 0]}, "InternalMemory_3.yaml": {"rewards": [-1.000000024214387, -1.0066666910424829, 0.2856666687875986, -1.0066666910424829, 0.5123333409428596, 0.7189999530091882, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829], "steps": [149, 150, 106, 150, 72, 41, 150, 150, 150, 150], "results": [0, 0, 1, 0, 1, 1, 0, 0, 0, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.8290000259876251, -1.0099999774247408, -1.0099999774247408, 0.7190000284463167, 0.6290000304579735, -1.0099999774247408], "steps": [99, 100, 100, 100, 16, 100, 100, 27, 36, 100], "results": [0, 0, 0, 0, 1, 0, 0, 1, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8789999531581998], "steps": [29], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.8709999537095428], "steps": [31], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.273015873015873, "level_02_preferences": 0.5454545454545454, "level_03_obstacles": 0.75, "level_04_avoidance": 0.6000000000000001, "level_05_spatial_reasoning": 0.25, "level_06_generalization": 0.25, "level_07_internal_memory": 0.3, "level_09_advanced_preferences": 0.4, "mean_score": 0.4210588023088023}