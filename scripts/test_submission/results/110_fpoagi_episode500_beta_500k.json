{"elapsed_time": 1170.854442358017, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2915000421926379, 0.11550005432218313, 0.20350004825741053, 0.415500033646822, 0.27150004357099533], "steps": [51, 95, 73, 20, 56], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6869999663904309, 0.8390000155195594, 0.859000014141202, 0.9030000111088157, 0.7750000199303031], "steps": [77, 39, 34, 23, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7700000926852226, 1.850000087171793, 1.629999983124435, 1.8739999663084745, 1.7339999759569764], "steps": [56, 36, 91, 30, 65], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.737000048160553, 2.861000039614737, 2.721000049263239, 2.6730000525712967, 2.9090000363066792], "steps": [64, 33, 68, 80, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7560001192614436, 3.876000110991299, 3.7400003587827086, 3.804000115953386, 3.7560001192614436], "steps": [59, 29, 63, 47, 59], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.658999721519649, 4.855000184848905, 4.779000190086663, 4.503000209107995], "steps": [249, 83, 34, 53, 122], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.13550005294382572, 0.20750004798173904, 0.4435000317171216, 0.3075000112876296, -0.07649993244558573], "steps": [90, 72, 13, 47, 143], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.7069999650120735, 0.6629999680444598, 0.702999965287745, 0.6910000257194042, 0.8069999581202865], "steps": [72, 83, 73, 76, 47], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.6499999817460775, 1.9139999635517597, 1.753999974578619, 1.845999968238175, 1.8460000874474645], "steps": [86, 20, 60, 37, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.7490002857521176, 2.8170000426471233, 2.9050000365823507, 2.9170000357553363, 2.8890002761036158], "steps": [61, 44, 22, 19, 26], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.804000115953386, 3.936000106856227, 3.8200001148507, 3.7320001209154725, 3.9000001093372703], "steps": [47, 14, 43, 65, 23], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.806999711319804, 4.907000181265175, 4.75900019146502, 4.67900019697845, 4.735000193119049], "steps": [46, 21, 58, 78, 64], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.3164999159052968, -0.3204999156296253, 0.1955000488087535, 0.16350002121180296, 0.2675000438466668], "steps": [203, 204, 75, 83, 57], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.5710000339895487, 0.5390000361949205, 0.5509999757632613, 0.7710000202059746, 0.44700004253536463], "steps": [106, 114, 111, 56, 137], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.747000192292035, 4.702999718487263, 4.518999731168151, 4.259000225923955, 4.943000178784132], "steps": [61, 72, 118, 183, 12], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.03950005955994129, 0.07550005707889795, -0.012499966658651829, 0.23150004632771015, 0.13150002341717482], "steps": [114, 105, 127, 66, 91], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7710000202059746, 0.7349999630823731, 0.7310000229626894, 0.2790000541135669, 0.519000037573278], "steps": [56, 65, 66, 179, 119], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.86700018402189, 4.663000198081136, 4.959000177681446, 4.983000176027417, 4.119000235572457], "steps": [31, 82, 8, 2, 218], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8529999889433384, 0.7930000526830554, 0.4230000185780227, 0.9190000439994037, 0.9109999849461019], "steps": [72, 102, 287, 39, 43], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8950000456534326, 0.7489999961107969, 0.2530000302940607, 0.9050000449642539, -1.0649999231100082], "steps": [51, 124, 372, 46, 32], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.3590000825934112, 0.7969999928027391, 0.7789999940432608, -1.6089998856186867, 0.5570000689476728], "steps": [319, 100, 109, 304, 220], "results": [1, 1, 1, 0, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.299000026192516, 0.8609999883919954, 0.5150000122375786, 0.7129999985918403, 0.2930000275373459], "steps": [149, 68, 241, 142, 352], "results": [0, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.7059999951161444, 3.28600002406165, 3.4740000111050904, 1.2240001815371215, -1.0569999236613512], "steps": [144, 354, 260, 386, 28], "results": [1, 1, 1, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9250000435858965, 0.9130000444129109, 0.921000043861568, 0.9229999841190875, 0.9209999842569232], "steps": [36, 42, 38, 37, 38], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.7709999945946038, 0.8069999921135604, 0.8030000519938767, 0.864999988116324, -1.059000042732805], "steps": [113, 95, 97, 66, 29], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.7489999961107969, -1.0470000435598195, 0.9069999852217734, -1.0429999246262014, 0.810999991837889], "steps": [124, 23, 45, 21, 93], "results": [1, 0, 1, 0, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8890000460669398, 0.9030000451020896, 0.9249999839812517, 0.9189999843947589, 0.9230000437237322], "steps": [54, 47, 36, 39, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.8009999925270677, 0.9029999854974449, 0.7769999941810966, 0.8209999911487103, 0.7829999937675893], "steps": [98, 47, 110, 88, 107], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.6410000631585717, 0.6929999999701977, 0.7949999929405749, 0.9149999846704304, 0.7789999940432608], "steps": [178, 152, 101, 41, 109], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [0.6090000057592988], "steps": [194], "results": [1]}, "RedHouse_2.yaml": {"rewards": [0.5210000118240714], "steps": [238], "results": [1]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.5929998867213726], "steps": [296], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.5009998930618167], "steps": [250], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8070000517182052], "steps": [95], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.8170000510290265], "steps": [90], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.8209999911487103], "steps": [88], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.7929999930784106], "steps": [102], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.8449999894946814], "steps": [76], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [1.1960001066327095], "steps": [400], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.7089999988675117], "steps": [144], "results": [1]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.813000051304698, 0.24500003084540367, 0.8190000508911908, -1.0019999309442937, -1.0019999309442937], "steps": [92, 376, 89, 500, 500], "results": [1, 1, 1, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.7579999743029475], "steps": [119], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.877999966032803], "steps": [59], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.831999969203025], "steps": [82], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.8199999700300395], "steps": [88], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.8399999686516821], "steps": [78], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8519999678246677], "steps": [72], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.853999967686832], "steps": [71], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.8420000281184912], "steps": [77], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [1.8279999694786966], "steps": [84], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540001736022532], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9630000409670174], "steps": [17], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9690000405535102], "steps": [14], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9690000405535102], "steps": [14], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9610000411048532], "steps": [18], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.9770000400021672], "steps": [10], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [-0.9999999310821295, 0.867000047583133, 0.8389999899081886, 0.8829999868758023, 0.7849999936297536, 0.9489999823272228, 0.8709999877028167, 0.8549999888055027, 0.9569999817758799, 0.8709999877028167], "steps": [499, 65, 79, 57, 106, 24, 63, 71, 20, 63], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.9829999799840152, 0.697000059299171, 0.6910000001080334, -1.0019999309442937, 0.6450000628829002, -1.0019999309442937, 0.7909999932162464, 0.9710000404156744, 0.8369999900460243, 0.8629999882541597], "steps": [7, 150, 153, 500, 176, 500, 103, 13, 80, 67], "results": [1, 1, 1, 0, 1, 0, 1, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, 0.7270000232383609, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 67, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [0.7469999622553587, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [62, 250, 250, 250, 250], "results": [1, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.7310000229626894, 0.5349999768659472, 0.535000036470592], "steps": [249, 250, 66, 115, 115], "results": [0, 0, 1, 1, 1]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, 0.6550000282004476, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 85, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9230000437237322], "steps": [37], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Navigation_1.yaml": {"rewards": [1.7060000374913216, 1.7820000322535634, 1.330000003799796, -0.0029999520629644394, 1.5779999867081642], "steps": [145, 107, 333, 500, 209], "results": [1, 1, 1, 0.5, 1]}, "Navigation_2.yaml": {"rewards": [1.3060000650584698, 1.516000050585717, 1.7639999738894403, 1.446000055409968, 1.831999969203025], "steps": [345, 240, 116, 275, 82], "results": [1, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [-0.9999999310821295, 1.8259999696165323, -0.002999892458319664, -1.0019999309442937, 1.2420000098645687], "steps": [499, 85, 500, 500, 377], "results": [0, 1, 0.5, 0, 1]}, "Navigation_4.yaml": {"rewards": [1.8320000288076699, 1.8359999689273536, -0.0029999520629644394, -1.0019999309442937, 1.7760000922717154], "steps": [82, 80, 500, 500, 110], "results": [1, 1, 0.5, 0, 1]}, "Navigation_5.yaml": {"rewards": [-0.000999892596155405, 1.6680000401102006, 1.2300001299008727, 1.7439999752677977, -0.0029999520629644394], "steps": [499, 164, 383, 126, 500], "results": [0.5, 1, 1, 1, 0.5]}, "Navigation_6.yaml": {"rewards": [1.6739999800920486, 1.8019999712705612, 1.6140000438317657, 1.8220000294968486, 1.772000032942742], "steps": [161, 97, 191, 87, 112], "results": [1, 1, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.3360000629909337, 1.4659999944269657, 1.7719999733380973, 1.418000116944313, 1.6720000398345292], "steps": [330, 265, 112, 289, 162], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.6260000430047512, -0.002999892458319664, 1.5060000512748957, 1.2760000671260059, 1.3040000055916607], "steps": [185, 500, 245, 360, 346], "results": [1, 0.5, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [1.764000033494085, -1.0019999309442937, 1.8000000310130417, 1.6599999810568988, 1.8279999694786966], "steps": [116, 500, 98, 168, 84], "results": [1, 0, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -0.002999892458319664, 1.9380000215023756, -1.0019999309442937, 1.7180000366643071], "steps": [499, 500, 29, 500, 139], "results": [0, 0.5, 1, 0, 1]}, "Navigation_on_platform_3.yaml": {"rewards": [1.0640000221319497, 1.4660001136362553, 1.052000022958964, 1.786000031977892, 1.8039999711327255], "steps": [466, 265, 472, 105, 96], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.0009999522008001804, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937, -0.002999892458319664], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0.5, 0, 0, 0.5]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [1.3500000620260835, 1.8119999705813825, -0.002999892458319664, 1.588000105228275, 1.799999971408397], "steps": [323, 92, 500, 204, 98], "results": [1, 1, 0.5, 1, 1]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [1.840000028256327, -1.0830000410787761, -1.0019999309442937, 1.0060001453384757, -1.0019999309442937], "steps": [78, 41, 500, 495, 500], "results": [1, 0, 0, 1, 0]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, -1.0019999309442937, -0.0029999520629644394, -0.002999892458319664], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0.5, 0, 0.5, 0.5]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [1.2720000674016774, -1.0019999309442937, 1.888000084552914, 1.864000026602298, -1.0019999309442937], "steps": [362, 500, 54, 66, 500], "results": [1, 0, 1, 1, 0]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, 1.1400000764988363, -0.002999892458319664, 1.7019999781623483], "steps": [499, 500, 428, 500, 147], "results": [0.5, 0, 1, 0.5, 1]}, "Center_Blocked_1.yaml": {"rewards": [-0.9999999310821295, -0.002999892458319664, 1.082000020891428, 1.7399999755434692, -0.0029999520629644394], "steps": [499, 500, 457, 128, 500], "results": [0, 0, 1, 1, 0]}, "Center_Blocked_2.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, 1.8200000296346843, -1.0019999309442937, 1.6699999803677201], "steps": [499, 500, 88, 500, 163], "results": [0, 0, 1, 0, 1]}, "Center_Blocked_3.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -0.0029999520629644394, -0.0029999520629644394, -0.002999892458319664], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Center_Blocked_4.yaml": {"rewards": [1.8179999701678753, 1.4100000578910112, -0.002999892458319664, 1.3780000004917383, -0.0029999520629644394], "steps": [89, 293, 500, 309, 500], "results": [1, 1, 0, 1, 0]}, "Borders_Blocked_1.yaml": {"rewards": [1.802000030875206, 1.823999969754368, 1.7760000326670706, 1.853999967686832, 1.6820000987499952], "steps": [97, 86, 110, 71, 157], "results": [1, 1, 1, 1, 1]}, "Borders_Blocked_2.yaml": {"rewards": [1.5420000487938523, 1.3380000032484531, 1.6099999845027924, 1.6359999827109277, 1.2580000683665276], "steps": [227, 329, 193, 180, 369], "results": [1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.533000010997057], "steps": [232], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.32300002546980977], "steps": [337], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-1.0719999694265425], "steps": [35], "results": [0]}, "Ring_2.yaml": {"rewards": [-1.0159999732859433], "steps": [7], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.0159999732859433], "steps": [7], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.0080000224988908], "steps": [5], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.0093333558179438], "steps": [6], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-1.017999853938818, -1.0159998540766537, -1.0159999732859433, -1.013999973423779, -1.013999973423779], "steps": [8, 7, 7, 6, 6], "results": [0, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [0.7976666507311165, -0.5403333678841591, 0.6716666300781071, -0.32966662757098675, -0.19633336458355188], "steps": [43, 92, 36, 160, 150], "results": [1, 0, 1, 0, 0]}, "ChessBoard_4.yaml": {"rewards": [-0.8716667061671615, 0.21566667594015598, 0.055666626896709204, 0.9009999856352806, 0.8143333764746785], "steps": [171, 64, 164, 48, 38], "results": [0, 1, 1, 1, 1]}, "Labyrinth_1.yaml": {"rewards": [0.6087776951026171, -0.7796667956281453, 0.565222138306126, 0.2305555222555995, 0.25411108299158514], "steps": [45, 193, 51, 112, 161], "results": [1, 0, 1, 1, 1]}, "Labyrinth_2.yaml": {"rewards": [-1.0080000224988908, -1.0093333558179438, -1.0093333558179438, -1.0093333558179438, -1.0106666891369969], "steps": [5, 6, 6, 6, 7], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-1.013999973423779, -1.0159999732859433, -1.0159998540766537, -1.013999973423779, -1.013999973423779], "steps": [6, 7, 7, 6, 6], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.019000044092535973, 0.5423333123326302, 0.32766664726659656, -1.5316666695289314, -2.827000227291137], "steps": [59, 34, 48, 211, 172], "results": [1, 1, 1, 0, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.780333386734128], "steps": [37], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7403333270922303], "steps": [37], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.7123333858326077], "steps": [34], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.6269999705255032], "steps": [92], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.586999973282218], "steps": [102], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.49099997989833355], "steps": [126], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8363333167508245], "steps": [37], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.5636667255312204], "steps": [160], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8256667107343674], "steps": [39], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.2630000179633498], "steps": [287], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [-1.3733332655392587], "steps": [499], "results": [0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.9999999310821295, 1.4920000522397459, -0.002999892458319664, 1.4920001118443906, -1.0019999309442937, 1.6220001028850675, -1.0019999309442937, -1.0019999309442937, 1.4580000545829535, 1.3680000607855618], "steps": [499, 252, 500, 252, 500, 187, 500, 500, 269, 314], "results": [0, 1, 0.5, 1, 0, 1, 0, 0, 1, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.000999986194074154, -0.004999926313757896, -0.004999985918402672, -1.003999930806458, 1.1060000704601407, -0.004999985918402672, 1.1980000045150518, -0.004999985918402672, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 222, 250, 199, 250, 250, 250], "results": [0.5, 0.5, 0.5, 0, 1, 0.5, 1, 0.5, 0, 0]}, "Navigation_1.yaml": {"rewards": [1.5600000475533307, -0.0029999520629644394, 1.81800002977252, 1.8879999653436244, 1.0260000247508287], "steps": [218, 500, 89, 54, 485], "results": [1, 0.5, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [-0.0009999522008001804, 1.060000082012266, 1.0060001453384757, 1.8520000274293125, 1.40000005858019], "steps": [499, 468, 495, 72, 298], "results": [0.5, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [1.8780000256374478, 1.7179999770596623, 1.68399997940287, -0.0029999520629644394, 1.5119999912567437], "steps": [59, 139, 156, 500, 242], "results": [1, 1, 1, 0.5, 1]}, "Navigation_4.yaml": {"rewards": [1.7080000969581306, -0.0029999520629644394, 1.168000074569136, 1.7099999776110053, 1.8500000275671482], "steps": [144, 500, 414, 143, 73], "results": [1, 0.5, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, 0.08700006734579802, -1.003999930806458], "steps": [249, 250, 250, 227, 250], "results": [0, 0, 0, 1, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Navigation_on_platform_1.yaml": {"rewards": [1.8080000304616988, 1.7980000311508775, 1.8060000305995345, 1.88599996548146, -0.002999892458319664], "steps": [94, 99, 95, 55, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.000999892596155405, -0.002999892458319664, -1.0019999309442937, -0.0029999520629644394, -0.0029999520629644394], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0.5, 0, 0.5, 0.5]}, "Navigation_on_platform_3.yaml": {"rewards": [1.1000000196509063, 1.346000062301755, 1.8900000248104334, -1.0019999309442937, 1.5520000481046736], "steps": [448, 325, 53, 500, 222], "results": [1, 1, 1, 0, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.0009999522008001804, 1.7219999767839909, -0.0029999520629644394, 1.5540000479668379, -1.0019999309442937], "steps": [499, 137, 500, 221, 500], "results": [0.5, 1, 0.5, 1, 0]}}}, "level_01_food": 0.7285714285714284, "level_02_preferences": 0.6, "level_03_obstacles": 0.41200000000000003, "level_04_avoidance": 0.46315789473684216, "level_05_spatial_reasoning": 0.55, "level_06_generalization": 0.5791666666666667, "mean_score": 0.5554826649958229}