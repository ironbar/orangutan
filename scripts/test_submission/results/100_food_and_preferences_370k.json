{"elapsed_time": 300.9889483451843, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2595000443980098, 0.3475000085309148, 0.18750004936009645, 0.40750003419816494, 0.29950004164129496], "steps": [59, 37, 77, 22, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6469999691471457, 0.7749999603256583, 0.8149999575689435, 0.8390000155195594, 0.7349999630823731], "steps": [87, 55, 45, 39, 65], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.761999974027276, 1.853999967686832, 1.3180000046268106, 1.874000085517764, 1.5859999861568213], "steps": [58, 35, 169, 30, 102], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.7890000445768237, 2.8410000409930944, 2.74500004760921, 2.861000039614737, 2.9050000365823507], "steps": [51, 38, 62, 33, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7400001203641295, 3.8720001112669706, 3.6480003651231527, 3.8080003540962934, 3.7840001173317432], "steps": [63, 30, 86, 46, 52], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.803000188432634, 4.683000196702778, 4.854999708011746, 4.775000190362334, 4.935000179335475], "steps": [47, 77, 34, 54, 14], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.07649996224790812, 0.1075000548735261, 0.40750003419816494, 0.3115000408142805, 0.06750005763024092], "steps": [143, 97, 22, 46, 107], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9230000097304583, 0.643000029027462, 0.8389999559149146, 0.6310000298544765, 0.6070000315085053], "steps": [18, 88, 39, 91, 97], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.6259999834001064, 1.88599996548146, 1.7300000954419374, 1.8380000879988074, 1.8299999693408608], "steps": [92, 27, 66, 39, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.745000286027789, 2.821000042371452, 2.861000039614737, 2.913000274449587, 2.861000278033316], "steps": [62, 43, 33, 20, 33], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.8400003518909216, 3.936000106856227, 3.844000113196671, 3.720000360161066, 3.8640001118183136], "steps": [38, 14, 37, 68, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.794999712146819, 4.875000183470547, 4.811000187881291, 4.687000196427107, -1.003999930806458], "steps": [49, 29, 45, 76, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.020499966107308865, 0.13550005294382572, 0.22350004687905312, 0.09150005597621202, -0.06449996307492256], "steps": [129, 90, 68, 101, 140], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.6790000265464187, 0.37899998761713505, 0.6670000273734331, 0.7429999625310302, 0.7309999633580446], "steps": [79, 154, 82, 63, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.734999716281891, 4.8230001870542765, 4.519000208005309, -1.003999930806458, 4.915000180713832], "steps": [64, 42, 118, 250, 19], "results": [1, 1, 1, 0, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.15550002176314592, 0.2435000455006957, 0.20750004798173904, 0.16750002093613148, 0.25150004494935274], "steps": [85, 63, 72, 82, 61], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.751000021584332, 0.7030000248923898, 0.6189999710768461, 0.6070000315085053, 0.7469999622553587], "steps": [61, 73, 94, 97, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.862999707460403, -1.003999930806458, 4.307000222615898, 4.983000176027417, 4.8789997063577175], "steps": [32, 250, 171, 2, 28], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8169999914243817, 0.7969999928027391, 0.12300003925338387, 0.8949999860487878, 0.6670000613667071], "steps": [90, 100, 437, 51, 165], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.888999986462295, 0.8250000504776835, 0.4090000195428729, 0.26100002974271774, 0.8609999883919954], "steps": [54, 86, 294, 368, 68], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8090000515803695, 0.8529999889433384, 0.5970000065863132, 0.3050000863149762, 0.7209999980404973], "steps": [94, 72, 200, 346, 138], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.28100002836436033, 0.6630000020377338, 0.5310000111348927, 0.2690000291913748, 0.38700002105906606], "steps": [358, 167, 233, 364, 305], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.6979999956674874, 1.9950000056996942, 1.9950000056996942, -0.34399992506951094, -1.0910000405274332], "steps": [148, 500, 500, 171, 45], "results": [1, 0.5, 0.5, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.8950000456534326, 0.9009999856352806, 0.821000050753355, 0.7989999926649034, 0.7989999926649034], "steps": [51, 48, 88, 99, 99], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8669999879784882, 0.9030000451020896, -1.14099991787225, 0.6090000057592988, 0.8489999892190099], "steps": [65, 47, 70, 194, 74], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.8450000490993261, 0.8410000493749976, -1.0729999225586653, 0.7089999988675117, -1.0749999224208295], "steps": [76, 78, 36, 144, 37], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8770000468939543, 0.8789999871514738, 0.9029999854974449, 0.8990000453777611, -1.0810000412166119], "steps": [60, 59, 47, 49, 40], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.8229999910108745, 0.5150000122375786, 0.5770000079646707, 0.8609999883919954, -1.0389999249018729], "steps": [87, 241, 210, 68, 19], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7009999994188547, 0.8529999889433384, 0.7629999951459467, -1.1589999166317284, 0.7730000540614128], "steps": [148, 72, 117, 79, 112], "results": [1, 1, 1, 0, 1]}, "RedHouse_1.yaml": {"rewards": [0.11500009940937161], "steps": [441], "results": [1]}, "RedHouse_2.yaml": {"rewards": [0.5310000111348927], "steps": [233], "results": [1]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [0.34300002409145236], "steps": [327], "results": [1]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [1.0660001155920327], "steps": [465], "results": [1]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.6470000031404197], "steps": [175], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.7929999930784106], "steps": [102], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.7689999947324395], "steps": [114], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.7789999940432608], "steps": [109], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-0.6059999326243997], "steps": [302], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [0.7949999929405749], "steps": [101], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.8709999877028167], "steps": [63], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-0.9999999310821295, 0.6230000643990934, 0.6190000050701201, -1.0019999309442937, -1.0019999309442937], "steps": [499, 187, 189, 500, 500], "results": [0, 1, 1, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9190000439994037], "steps": [39], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [2.837000041268766], "steps": [79], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [0.9529999820515513], "steps": [22], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.9509999821893871], "steps": [23], "results": [0]}, "YellowOverGreen_5.yaml": {"rewards": [1.8960000243969262], "steps": [50], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8820000253617764], "steps": [57], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [1.8300000289455056], "steps": [83], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9009999856352806], "steps": [48], "results": [0]}, "Green_sizes12_2.yaml": {"rewards": [1.9220000565983355], "steps": [37], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.952000173740089], "steps": [22], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.9720001723617315], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9720001723617315], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9690000405535102], "steps": [14], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9730000402778387], "steps": [12], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.975000040140003], "steps": [11], "results": [0]}}}, "level_01_food": 0.6507936507936508, "level_02_preferences": 0.5333333333333333, "mean_score": 0.5920634920634921}