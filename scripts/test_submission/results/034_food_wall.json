{"elapsed_time": 358.9568452835083, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.24750004522502422, -0.008499937132000923, 0.29550004191696644, 0.38750000577419996, 0.20350001845508814], "steps": [62, 126, 50, 27, 73], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8630000138655305, 0.6950000254437327, 0.5950000323355198, 0.6150000309571624, 0.7909999592229724], "steps": [33, 75, 100, 95, 51], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7659999737516046, 1.8540000868961215, 1.9739999594166875, 1.5500001078471541, 1.8620000863447785], "steps": [57, 35, 5, 111, 33], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.8330002799630165, 2.7090000500902534, 2.8890000376850367, 2.877000038512051, 2.9050000365823507], "steps": [40, 71, 26, 29, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.744000120088458, 3.868000111542642, 3.736000120639801, 3.744000120088458, 3.6600003642961383], "steps": [62, 31, 64, 62, 83], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.827000186778605, 4.834999709390104, 4.603000202216208, 4.814999710768461, 4.9789996994659305], "steps": [41, 39, 97, 44, 3], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.0924999313428998, 0.29950004164129496, -0.05249996390193701, -0.24449992086738348, 0.05150002893060446], "steps": [147, 49, 137, 185, 111], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.5069999787956476, 0.8349999561905861, 0.8630000138655305, 0.7829999597743154, 0.867000013589859], "steps": [122, 40, 33, 53, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7899999720975757, 1.4659999944269657, 1.7179999770596623, 1.845999968238175, 1.5899999858811498], "steps": [51, 132, 69, 37, 101], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.6410000547766685, 2.6570000536739826, 2.621000056155026, 2.9170000357553363, 2.861000039614737], "steps": [88, 84, 93, 19, 33], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.6160001289099455, 3.928000345826149, 3.6480001267045736, 3.7800001176074147, 3.5400003725662827], "steps": [94, 16, 86, 53, 113], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.595000202767551, 4.575000204145908, 4.791000189259648, 4.923000180162489, 4.879000183194876], "steps": [99, 104, 50, 17, 28], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.051500058732926846, -0.2084999531507492, 0.2635000143200159, 0.3035000413656235, 0.05550005845725536], "steps": [111, 176, 58, 48, 110], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.6310000298544765, -1.003999930806458, 0.6989999655634165, 0.7829999597743154, 0.6390000293031335], "steps": [91, 250, 74, 53, 89], "results": [1, 0, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.455000212416053, 4.8310001865029335, 4.815000187605619, 4.835000186227262, 4.46300021186471], "steps": [134, 40, 44, 39, 132], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.06849993299692869, -1.003999930806458, 0.1755000203847885, -0.15649992693215609, -0.21249992307275534], "steps": [141, 250, 80, 163, 177], "results": [1, 0, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.7629999611526728, 0.7110000243410468, 0.5069999787956476, 0.6109999716281891], "steps": [249, 58, 71, 122, 96], "results": [0, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.843000185675919, 4.843000185675919, 4.346999743022025, 4.983000176027417, 4.843000185675919], "steps": [37, 37, 161, 2, 37], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.5790000674314797, -1.0770000414922833, 0.8149999915622175, 0.9089999850839376, -1.2509999102912843], "steps": [209, 38, 91, 44, 125], "results": [1, 0, 1, 1, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9030000451020896, 0.5150000122375786, 0.641000003553927, 0.6270000045187771, -1.1069999202154577], "steps": [47, 241, 178, 185, 53], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8549999888055027, 0.8689999878406525, 0.5630000685341656, 0.7949999929405749, -1.0450000436976552], "steps": [71, 64, 217, 101, 22], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.7769999941810966, 0.759000055026263, -1.2749999086372554, -1.2589999097399414, 0.3650000225752592], "steps": [110, 119, 137, 129, 316], "results": [1, 1, 0, 0, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [0.63700005505234, 3.3740000179968774, 3.7059999355114996, 1.6460000332444906, 0.629000055603683], "steps": [180, 310, 144, 175, 184], "results": [0, 1, 1, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9170000441372395, 0.9070000448264182, 0.9190000439994037, 0.9169999845325947, 0.8850000463426113], "steps": [40, 45, 39, 40, 56], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8629999882541597, 0.8769999872893095, 0.8969999859109521, 0.8389999899081886, 0.8470000489614904], "steps": [67, 60, 50, 79, 75], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.7829999937675893, -1.0849999217316508, 0.8989999857731164, -1.1189999193884432, 0.8929999861866236], "steps": [107, 42, 49, 59, 52], "results": [1, 0, 1, 0, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.6370000038295984, 0.8970000455155969, 0.9110000445507467, 0.9189999843947589, 0.9090000446885824], "steps": [180, 50, 43, 39, 44], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.8289999905973673, 0.9050000449642539, -1.1110000391490757, 0.8609999883919954, -1.035000044386834], "steps": [84, 46, 55, 68, 17], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0290000448003411, 0.8509999890811741, 0.8389999899081886, 0.9009999856352806, -1.1569999167695642], "steps": [14, 73, 79, 48, 78], "results": [0, 1, 1, 1, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-2.139999990351498], "steps": [70], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.7070000586099923], "steps": [145], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.751000055577606], "steps": [123], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.6890000002458692], "steps": [154], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.8589999885298312], "steps": [69], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.9170000441372395], "steps": [40], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [0.7669999948702753], "steps": [115], "results": [1]}, "RedWall_4.yaml": {"rewards": [0.8450000490993261], "steps": [76], "results": [1]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [1.861999967135489], "steps": [67], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.6900000385940075], "steps": [153], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.7739999732002616], "steps": [111], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.7899999720975757], "steps": [103], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7039999780245125], "steps": [146], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8080000304616988], "steps": [94], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.9040000238455832], "steps": [46], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.952000173740089], "steps": [22], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9170000441372395, 0.7790000536479056, 0.4490000167861581, 0.8609999883919954, 0.8629999882541597, 0.8250000504776835, 0.7549999956972897, 0.8909999863244593, -1.0019999309442937, 0.6770000010728836], "steps": [40, 109, 274, 68, 67, 86, 121, 53, 500, 160], "results": [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]}, "objectManipulation.yaml": {"rewards": [0.929000043310225, 0.9270000434480608, 0.764999995008111, 0.8149999915622175, 0.8949999860487878, 0.7549999956972897, 0.6770000606775284, 0.975000040140003, 0.888999986462295, 0.5670000682584941], "steps": [34, 35, 116, 91, 51, 121, 160, 11, 54, 215], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.43700001761317253], "steps": [280], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [-1.3099999530240893], "steps": [154], "results": [0]}, "CenterMoat_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-1.0379999717697501], "steps": [18], "results": [0]}, "Ring_2.yaml": {"rewards": [-1.0239999727346003], "steps": [11], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.0219998536631465], "steps": [10], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.013999973423779], "steps": [6], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.0080000224988908], "steps": [5], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.0093333558179438], "steps": [6], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-1.2400000200141221], "steps": [179], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-1.857333346735686], "steps": [642], "results": [0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.9999999310821295, 1.5559999882243574, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 220, 500, 500, 500, 500, 500, 500, 500, 500], "results": [0, 1, 0, 0, 0.5, 0, 0, 0, 0.5, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -0.004999926313757896, -1.003999930806458, -1.003999930806458, -0.004999926313757896, -0.004999985918402672, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250, 250, 250, 250, 250, 250], "results": [0, 0, 0.5, 0, 0, 0.5, 0.5, 0, 0, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.6030000317841768, -1.003999930806458, 0.8470000149682164, 0.2630000552162528, 0.49900003895163536, 0.6310000298544765, 0.6110000312328339, 0.1310000643134117, 0.11100000608712435, -1.003999930806458], "steps": [98, 250, 37, 183, 124, 91, 96, 216, 221, 250], "results": [1, 0, 1, 1, 1, 1, 1, 1, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.9950000047683716, 0.9149999506771564, 0.9550000075250864, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.3950000461190939, 0.19500000029802322, -1.003999930806458, -1.003999930806458], "steps": [0, 20, 10, 250, 250, 250, 150, 200, 250, 250], "results": [1, 1, 1, 0, 0, 0, 1, 1, 0, 0]}, "InternalMemory_3.yaml": {"rewards": [-1.000000024214387, -1.0066666910424829, 0.6923333453014493, 0.7790000140666962, 0.7856666808947921, 0.5856666760519147, 0.13899993896484375, 0.712333345785737, 0.7256666794419289, 0.8790000164881349], "steps": [149, 150, 45, 32, 31, 61, 128, 42, 40, 17], "results": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.569000031799078, 0.7090000286698341, 0.29900003783404827, 0.1690000407397747, -1.0099999774247408, 0.7190000284463167, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408], "steps": [42, 28, 69, 82, 100, 27, 100, 100, 100, 100], "results": [1, 1, 1, 1, 0, 1, 0, 0, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.6532258064516129, "level_03_obstacles": 0.95, "level_04_avoidance": 0.0625, "level_05_spatial_reasoning": 0.2, "level_06_generalization": 0.15, "level_07_internal_memory": 0.65, "level_09_advanced_preferences": 0.0, "mean_score": 0.3808179723502304}