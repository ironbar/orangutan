{"elapsed_time": 1835.768441438675, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.08350005652755499, 0.13550002314150333, -0.26449991948902607, 0.415500033646822, 0.16750005073845387], "steps": [103, 90, 190, 20, 82], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8709999537095428, 0.4910000395029783, 0.8470000149682164, 0.594999972730875, 0.27100005466490984], "steps": [31, 126, 37, 100, 181], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.6540001006796956, 1.853999967686832, 1.2780000073835254, 1.6179999839514494, 1.3740001199766994], "steps": [85, 35, 179, 94, 155], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.3450003135949373, -1.003999930806458, 2.5410003000870347, 2.421000308357179, 2.897000275552273], "steps": [162, 250, 113, 143, 24], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.688000123947859, -1.003999930806458, 3.6920001236721873, 3.3080001501366496, 3.396000144071877], "steps": [76, 250, 75, 171, 149], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.395000216551125, -1.003999930806458, -1.003999930806458, 4.675000197254121], "steps": [249, 149, 250, 250, 79], "results": [0, 1, 0, 0, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.8550000144168735, 0.019000012427568436, -1.003999930806458, 0.810999957844615], "steps": [249, 35, 244, 250, 46], "results": [0, 1, 1, 0, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7939999718219042, 1.877999966032803, 1.745999975129962, 1.8259999696165323, 1.5579999880865216], "steps": [50, 29, 62, 42, 109], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.6170002948492765, 2.0690003326162696, -1.003999930806458, 2.90500027500093, 2.885000037960708], "steps": [94, 231, 250, 22, 27], "results": [1, 1, 0, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.320000149309635, 3.9320003455504775, 3.752000119537115, 3.628000128082931, 3.404000143520534], "steps": [168, 15, 60, 91, 147], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.791000189259648, 4.4389997366815805, 4.359000219032168, 4.099000236950815, 4.559000205248594], "steps": [50, 138, 158, 223, 108], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -0.028499935753643513, -1.003999930806458, -0.30849991645663977], "steps": [249, 250, 131, 250, 201], "results": [0, 0, 1, 0, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.2150000585243106, 0.6869999663904309, 0.38299998734146357, 0.3909999867901206, 0.2150000585243106], "steps": [195, 77, 153, 151, 195], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 4.302999746054411, 4.531000207178295, 4.943000178784132], "steps": [249, 250, 172, 115, 12], "results": [0, 0, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.37649994157254696, -1.003999930806458, 0.24750004522502422, -1.003999930806458, -1.003999930806458], "steps": [218, 250, 62, 250, 250], "results": [1, 0, 1, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.4870000397786498, 0.3310000505298376, -1.003999930806458, -1.003999930806458, 0.36300004832446575], "steps": [127, 166, 250, 250, 158], "results": [1, 1, 0, 0, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.855000184848905, 4.007000243291259, 4.502999732270837, 4.983000176027417, 4.158999755978584], "steps": [34, 246, 122, 2, 208], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.2390000303275883, -1.0370000442489982, -1.1029999204911292, -1.3390000234358013, -1.3509999033994973], "steps": [119, 18, 51, 169, 175], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8909999863244593, -1.4149998989887536, -1.1070000394247472, -1.1530000362545252, -1.1289999186992645], "steps": [53, 207, 53, 76, 64], "results": [1, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.5469998898915946, -1.2529999101534486, -1.0410000439733267, -1.129000037908554, -1.7289998773485422], "steps": [273, 126, 20, 64, 364], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.259000028949231, -1.0019999309442937, -1.1690000351518393, -1.100999920628965, -1.4870000132359564], "steps": [129, 500, 84, 50, 243], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-0.3079999275505543, -0.2919999286532402, -0.4079999206587672, -1.5209998916834593, -1.1809999151155353], "steps": [153, 145, 203, 260, 90], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9230000437237322, 0.9209999842569232, -1.062999923247844, 0.9109999849461019, 0.9149999846704304], "steps": [37, 38, 31, 43, 41], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8690000474452972, -1.291000026743859, 0.7990000522695482, -1.1149999196641147, -1.0589999235235155], "steps": [64, 145, 99, 57, 29], "results": [1, 0, 1, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0790000413544476, -1.105000039562583, 0.8329999903216958, -1.1569999167695642, -1.0689999228343368], "steps": [39, 52, 82, 78, 34], "results": [0, 0, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [-1.0829999218694866, 0.9010000452399254, 0.9209999842569232, 0.9090000446885824, -1.0949999210424721], "steps": [41, 48, 38, 44, 47], "results": [0, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-1.2529999101534486, -1.0449999244883657, -1.1110000391490757, -1.0749999224208295, -1.0870000408031046], "steps": [126, 22, 55, 37, 43], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0390000441111624, -1.1170000387355685, -1.116999919526279, -1.1129999198019505, -1.35699990298599], "steps": [19, 58, 58, 56, 178], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-1.3769999016076326], "steps": [188], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.46499989554286], "steps": [232], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.9189999843947589], "steps": [39], "results": [1]}, "DeadComing_2.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.9149999846704304], "steps": [41], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-1.5589998890645802], "steps": [279], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.039999997243285], "steps": [20], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.0350000699982047], "steps": [18], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.9130000444129109], "steps": [42], "results": [1]}, "RedWall_2.yaml": {"rewards": [-1.6869998802430928], "steps": [343], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.2810000274330378], "steps": [140], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.3209999054670334], "steps": [160], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.059000042732805], "steps": [29], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0489999242126942], "steps": [24], "results": [0]}, "RedWall_7.yaml": {"rewards": [-2.903999937698245], "steps": [452], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8690000474452972, -1.1410000370815396, -1.0019999309442937, -1.448999896645546, 0.8009999925270677], "steps": [64, 70, 500, 224, 98], "results": [1, 0, 0, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.4539999952539802], "steps": [271], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8519999678246677], "steps": [72], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.6579999811947346], "steps": [169], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [0.9549999819137156], "steps": [21], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [0.9669999810867012], "steps": [15], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.7090000500902534], "steps": [143], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.918000056874007], "steps": [39], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9509999821893871], "steps": [23], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9640001729130745], "steps": [16], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9549999819137156, 0.9169999845325947, -1.0019999309442937, 0.9109999849461019, 0.6870000599883497, 0.7209999980404973, 0.8190000508911908, 0.9570000413805246, -1.0019999309442937, 0.996999979019165], "steps": [21, 40, 500, 43, 155, 138, 89, 20, 500, 0], "results": [1, 1, 0, 1, 1, 1, 1, 1, 0, 1]}, "objectManipulation.yaml": {"rewards": [-0.9999999310821295, 0.5930000068619847, 0.8569999886676669, 0.9509999821893871, 0.9449999826028943, 0.5570000689476728, 0.7989999926649034, 0.549000009894371, 0.8570000482723117, 0.6850000601261854], "steps": [499, 202, 70, 23, 26, 220, 99, 224, 70, 156], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9189999843947589], "steps": [39], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.7089999988675117], "steps": [144], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Navigation_1.yaml": {"rewards": [-0.0009999522008001804, 1.607999984640628, 1.7879999722354114, -1.0019999309442937, 1.5259999902918935], "steps": [499, 194, 104, 500, 235], "results": [0.5, 1, 1, 0, 1]}, "Navigation_2.yaml": {"rewards": [-0.000999892596155405, 1.5239999904297292, -0.002999892458319664, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 236, 500, 500, 500], "results": [0.5, 1, 0.5, 0.5, 0]}, "Navigation_3.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, 1.290000006556511, 1.8300000289455056, -0.002999892458319664], "steps": [499, 500, 353, 83, 500], "results": [0.5, 0.5, 1, 1, 0.5]}, "Navigation_4.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -0.0029999520629644394, 1.6259999834001064, -1.0019999309442937], "steps": [499, 500, 500, 185, 500], "results": [0.5, 0, 0.5, 1, 0]}, "Navigation_5.yaml": {"rewards": [-0.9999999310821295, -0.0029999520629644394, -0.0029999520629644394, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0.5, 0.5, 0.5, 0]}, "Navigation_6.yaml": {"rewards": [1.826000029221177, 1.405999998562038, -0.0029999520629644394, -1.0019999309442937, -0.0029999520629644394], "steps": [85, 295, 500, 500, 500], "results": [1, 1, 0.5, 0, 0.5]}, "Navigation_7.yaml": {"rewards": [1.7659999737516046, 1.7900000317022204, 1.282000007107854, 1.8359999689273536, 1.8679999667219818], "steps": [115, 103, 357, 80, 64], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [-0.9999999310821295, 1.68399997940287, 1.6159999840892851, 1.6740000396966934, -0.0029999520629644394], "steps": [499, 156, 190, 161, 500], "results": [0, 1, 1, 1, 0.5]}, "Navigation_on_platform_1.yaml": {"rewards": [-0.000999892596155405, 1.4499999955296516, -0.002999892458319664, 1.4920000522397459, -0.0029999520629644394], "steps": [499, 273, 500, 252, 500], "results": [0.5, 1, 0.5, 1, 0.5]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [-0.40599992079660296, -1.0019999309442937, -0.12399994023144245, -1.0530000431463122, -1.0019999309442937], "steps": [202, 500, 61, 26, 500], "results": [0, 0, 0, 0, 0]}, "Navigation_on_platform_4.yaml": {"rewards": [-1.3010000260546803, -1.0669999229721725, -1.0019999309442937, -1.0019999309442937, -1.205000032670796], "steps": [150, 33, 500, 500, 102], "results": [0, 0, 0, 0, 0]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8569999886676669], "steps": [70], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8409999897703528], "steps": [78], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7530000554397702], "steps": [122], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [0.8509999890811741], "steps": [73], "results": [1]}, "Ring_2.yaml": {"rewards": [0.8489999892190099], "steps": [74], "results": [1]}, "Ring_3.yaml": {"rewards": [0.8049999922513962], "steps": [96], "results": [1]}, "Ring_4.yaml": {"rewards": [-1.3719998295418918], "steps": [185], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.2079999600537121], "steps": [103], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [0.4930000137537718], "steps": [252], "results": [1]}, "RingBlocked_3.yaml": {"rewards": [0.8669999917037785], "steps": [98], "results": [1]}, "RingBlocked_4.yaml": {"rewards": [-1.2520000198855996], "steps": [188], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.656333327293396], "steps": [256], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.8410000493749976, 0.7969999928027391, 0.6030000657774508, 0.8490000488236547, 0.8549999888055027], "steps": [78, 100, 197, 74, 71], "results": [1, 1, 1, 1, 1]}, "ChessBoard_2.yaml": {"rewards": [0.7889999933540821, 0.5770000079646707, 0.7710000541992486, 0.4630000158213079, 0.87500004703179], "steps": [104, 210, 113, 267, 61], "results": [1, 1, 1, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [0.7796666496433318, 0.7383333221077919, 0.8336666487157345, 0.8203333159908652, 0.6783333066850901], "steps": [42, 76, 35, 35, 66], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.012333229184150696, 0.8816666495986283, 0.6696666488423944, 0.639000023715198, 0.5256666541099548], "steps": [49, 41, 37, 49, 119], "results": [1, 1, 1, 1, 1]}, "Labyrinth_1.yaml": {"rewards": [0.6141110912431031, 0.6856666475068778, 0.6185554759576917, 0.5989999193698168, 0.5585555324796587], "steps": [81, 44, 71, 69, 56], "results": [1, 1, 1, 1, 1]}, "Labyrinth_2.yaml": {"rewards": [0.6216666013933718, -1.0013333226088434, -1.5426666834391654, 0.7096666600555182, -1.0013333226088434], "steps": [282, 750, 406, 216, 750], "results": [1, 0, 0, 1, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, 0.6370000634342432, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 180, 500, 500], "results": [0, 0, 1, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.31899999361485243, 0.4543333160690963, 0.5130000412464142, 0.39699998451396823, 0.4250000440515578], "steps": [119, 48, 42, 60, 66], "results": [1, 1, 1, 1, 1]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7709999931976199], "steps": [36], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7483333265408874], "steps": [35], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.6736666578799486], "steps": [37], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-1.923999885097146], "steps": [230], "results": [0]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-1.483999915421009], "steps": [120], "results": [0]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.7990000182762742], "steps": [49], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.8230000166222453], "steps": [43], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.8310000160709023], "steps": [41], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.7816667119041085], "steps": [61], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.8216667091473937], "steps": [41], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8516666507348418], "steps": [36], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.6376666547730565], "steps": [73], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.6576667102053761], "steps": [43], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, 1.5220000501722097, -0.0029999520629644394, -0.0029999520629644394, -1.0019999309442937, -1.0019999309442937, 1.4439999959431589, -0.0029999520629644394, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 237, 500, 500, 500, 500, 276, 500, 500, 500], "results": [0.5, 1, 0.5, 0.5, 0, 0, 1, 0.5, 0.5, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.000999986194074154, -1.003999930806458, -0.004999926313757896, 1.006000017747283, -1.003999930806458, -0.004999985918402672, -1.003999930806458, -0.004999926313757896, -0.004999926313757896, -1.003999930806458], "steps": [249, 250, 250, 247, 250, 250, 250, 250, 250, 250], "results": [0.5, 0, 0.5, 1, 0, 0.5, 0, 0.5, 0.5, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.7390000224113464, 0.759000021032989, 0.9309999495744705, -1.003999930806458, 0.9430000083521008, -1.003999930806458, 0.9430000083521008, -1.003999930806458, 0.9029999515041709, -1.003999930806458], "steps": [64, 59, 16, 250, 13, 250, 13, 250, 23, 250], "results": [1, 1, 1, 0, 1, 0, 1, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.6230000304058194, 0.8389999559149146, 0.1750000612810254, -1.003999930806458, 0.8870000122115016, 0.8909999523311853, 0.5070000384002924, -1.003999930806458, -1.003999930806458, 0.859000014141202], "steps": [93, 39, 205, 250, 27, 26, 122, 250, 250, 34], "results": [1, 1, 1, 0, 1, 1, 1, 0, 0, 1]}, "InternalMemory_3.yaml": {"rewards": [-1.000000024214387, 0.6923332856968045, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, 0.35233333706855774, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, 0.658999951556325], "steps": [149, 45, 150, 150, 150, 96, 150, 150, 150, 50], "results": [0, 1, 0, 0, 0, 1, 0, 0, 0, 1]}, "InternalMemory_4.yaml": {"rewards": [0.19900004006922245, -1.0099999774247408, 0.879000024870038, 0.6090000309050083, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.2290000393986702], "steps": [79, 100, 11, 38, 100, 100, 100, 100, 100, 76], "results": [1, 0, 1, 1, 0, 0, 0, 0, 0, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [0.8910000119358301], "steps": [26], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.47619047619047616, "level_02_preferences": 1.0, "level_03_obstacles": 0.241025641025641, "level_04_avoidance": 0.7263157894736842, "level_05_spatial_reasoning": 0.45, "level_06_generalization": 0.35, "level_07_internal_memory": 0.5, "level_09_advanced_preferences": 0.2, "mean_score": 0.4929414883362252}