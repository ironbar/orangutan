{"elapsed_time": 440.9893071651459, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.08350005652755499, 0.13550002314150333, -0.26449991948902607, 0.415500033646822, 0.16750005073845387], "steps": [103, 90, 190, 20, 82], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8709999537095428, 0.4910000395029783, 0.8470000149682164, 0.594999972730875, 0.27100005466490984], "steps": [31, 126, 37, 100, 181], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.6540001006796956, 1.853999967686832, 1.2780000073835254, 1.6179999839514494, 1.3740001199766994], "steps": [85, 35, 179, 94, 155], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.3450003135949373, -1.003999930806458, 2.5410003000870347, 2.421000308357179, 2.897000275552273], "steps": [162, 250, 113, 143, 24], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.688000123947859, -1.003999930806458, 3.6920001236721873, 3.3080001501366496, 3.396000144071877], "steps": [76, 250, 75, 171, 149], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.395000216551125, -1.003999930806458, -1.003999930806458, 4.675000197254121], "steps": [249, 149, 250, 250, 79], "results": [0, 1, 0, 0, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.8550000144168735, 0.019000012427568436, -1.003999930806458, 0.810999957844615], "steps": [249, 35, 244, 250, 46], "results": [0, 1, 1, 0, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7939999718219042, 1.877999966032803, 1.745999975129962, 1.8259999696165323, 1.5579999880865216], "steps": [50, 29, 62, 42, 109], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.6170002948492765, 2.0690003326162696, -1.003999930806458, 2.90500027500093, 2.885000037960708], "steps": [94, 231, 250, 22, 27], "results": [1, 1, 0, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.320000149309635, 3.9320003455504775, 3.752000119537115, 3.628000128082931, 3.404000143520534], "steps": [168, 15, 60, 91, 147], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.791000189259648, 4.4389997366815805, 4.359000219032168, 4.099000236950815, 4.559000205248594], "steps": [50, 138, 158, 223, 108], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -0.028499935753643513, -1.003999930806458, -0.30849991645663977], "steps": [249, 250, 131, 250, 201], "results": [0, 0, 1, 0, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.2150000585243106, 0.6869999663904309, 0.38299998734146357, 0.3909999867901206, 0.2150000585243106], "steps": [195, 77, 153, 151, 195], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 4.302999746054411, 4.531000207178295, 4.943000178784132], "steps": [249, 250, 172, 115, 12], "results": [0, 0, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.37649994157254696, -1.003999930806458, 0.24750004522502422, -1.003999930806458, -1.003999930806458], "steps": [218, 250, 62, 250, 250], "results": [1, 0, 1, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.4870000397786498, 0.3310000505298376, -1.003999930806458, -1.003999930806458, 0.36300004832446575], "steps": [127, 166, 250, 250, 158], "results": [1, 1, 0, 0, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.855000184848905, 4.007000243291259, 4.502999732270837, 4.983000176027417, 4.158999755978584], "steps": [34, 246, 122, 2, 208], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.2390000303275883, -1.0370000442489982, -1.1029999204911292, -1.3390000234358013, -1.3509999033994973], "steps": [119, 18, 51, 169, 175], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8909999863244593, -1.4149998989887536, -1.1070000394247472, -1.1530000362545252, -1.1289999186992645], "steps": [53, 207, 53, 76, 64], "results": [1, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.5469998898915946, -1.2529999101534486, -1.0410000439733267, -1.129000037908554, -1.7289998773485422], "steps": [273, 126, 20, 64, 364], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.259000028949231, -1.0019999309442937, -1.1690000351518393, -1.100999920628965, -1.4870000132359564], "steps": [129, 500, 84, 50, 243], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-0.3079999275505543, -0.2919999286532402, -0.4079999206587672, -1.5209998916834593, -1.1809999151155353], "steps": [153, 145, 203, 260, 90], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9230000437237322, 0.9209999842569232, -1.062999923247844, 0.9109999849461019, 0.9149999846704304], "steps": [37, 38, 31, 43, 41], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8690000474452972, -1.291000026743859, 0.7990000522695482, -1.1149999196641147, -1.0589999235235155], "steps": [64, 145, 99, 57, 29], "results": [1, 0, 1, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0790000413544476, -1.105000039562583, 0.8329999903216958, -1.1569999167695642, -1.0689999228343368], "steps": [39, 52, 82, 78, 34], "results": [0, 0, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [-1.0829999218694866, 0.9010000452399254, 0.9209999842569232, 0.9090000446885824, -1.0949999210424721], "steps": [41, 48, 38, 44, 47], "results": [0, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-1.2529999101534486, -1.0449999244883657, -1.1110000391490757, -1.0749999224208295, -1.0870000408031046], "steps": [126, 22, 55, 37, 43], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0390000441111624, -1.1170000387355685, -1.116999919526279, -1.1129999198019505, -1.35699990298599], "steps": [19, 58, 58, 56, 178], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-1.3769999016076326], "steps": [188], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.46499989554286], "steps": [232], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.9189999843947589], "steps": [39], "results": [1]}, "DeadComing_2.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0269999257288873], "steps": [13], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.9149999846704304], "steps": [41], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-1.5589998890645802], "steps": [279], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.039999997243285], "steps": [20], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.0350000699982047], "steps": [18], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.9130000444129109], "steps": [42], "results": [1]}, "RedWall_2.yaml": {"rewards": [-1.6869998802430928], "steps": [343], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.2810000274330378], "steps": [140], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.3209999054670334], "steps": [160], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.059000042732805], "steps": [29], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0489999242126942], "steps": [24], "results": [0]}, "RedWall_7.yaml": {"rewards": [-2.903999937698245], "steps": [452], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8690000474452972, -1.1410000370815396, -1.0019999309442937, -1.448999896645546, 0.8009999925270677], "steps": [64, 70, 500, 224, 98], "results": [1, 0, 0, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.4539999952539802], "steps": [271], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8519999678246677], "steps": [72], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.6579999811947346], "steps": [169], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [0.9549999819137156], "steps": [21], "results": [0]}, "YellowOverGreen_5.yaml": {"rewards": [0.9669999810867012], "steps": [15], "results": [0]}, "YellowOverGreen_6.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}, "YellowOverGreen_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [2.7090000500902534], "steps": [143], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.918000056874007], "steps": [39], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9509999821893871], "steps": [23], "results": [0]}, "Green_sizes12_4.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "Green_sizes12_6.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "Green_sizes12_7.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9640001729130745], "steps": [16], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9549999819137156, 0.9169999845325947, -1.0019999309442937, 0.9109999849461019, 0.6870000599883497, 0.7209999980404973, 0.8190000508911908, 0.9570000413805246, -1.0019999309442937, 0.996999979019165], "steps": [21, 40, 500, 43, 155, 138, 89, 20, 500, 0], "results": [1, 1, 0, 1, 1, 1, 1, 1, 0, 1]}, "objectManipulation.yaml": {"rewards": [-0.9999999310821295, 0.5930000068619847, 0.8569999886676669, 0.9509999821893871, 0.9449999826028943, 0.5570000689476728, 0.7989999926649034, 0.549000009894371, 0.8570000482723117, 0.6850000601261854], "steps": [499, 202, 70, 23, 26, 220, 99, 224, 70, 156], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8650000477209687], "steps": [66], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8309999904595315], "steps": [83], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7609999952837825], "steps": [118], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [0.8430000492371619], "steps": [77], "results": [1]}, "Ring_2.yaml": {"rewards": [0.8529999889433384], "steps": [72], "results": [1]}, "Ring_3.yaml": {"rewards": [0.5470000696368515], "steps": [225], "results": [1]}, "Ring_4.yaml": {"rewards": [0.6190000050701201], "steps": [189], "results": [1]}, "RingBlocked_1.yaml": {"rewards": [-1.2039999603293836], "steps": [101], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.7959999195300043], "steps": [397], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.5053333505056798], "steps": [378], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.1666666874662042], "steps": [124], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.285666664596647], "steps": [534], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.8509999890811741, 0.8409999897703528, 0.7769999941810966, 0.8870000462047756, 0.8469999893568456], "steps": [73, 78, 110, 55, 75], "results": [1, 1, 1, 1, 1]}, "ChessBoard_2.yaml": {"rewards": [-1.1639998438768089, 0.6450000628829002, 0.6969999996945262, 0.7789999940432608, 0.6130000054836273], "steps": [81, 176, 150, 109, 192], "results": [0, 1, 1, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [0.685666642151773, 0.9189999843947589, 0.9209999842569232, 0.9310000431723893, 0.7050000480376184], "steps": [49, 39, 38, 33, 76], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.25233333045616746, 0.7796666505746543, 0.5450000227428973, 0.5916667003184557, 0.7330000316724181], "steps": [69, 42, 66, 56, 42], "results": [1, 1, 1, 1, 1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, 1.4719999940134585, 1.3700000010430813, -1.0019999309442937, 1.3280000635422766, 1.61600004369393, -0.0029999520629644394, -1.0019999309442937, 1.686000038869679], "steps": [499, 500, 262, 313, 500, 334, 190, 500, 500, 155], "results": [0.5, 0.5, 1, 1, 0, 1, 1, 0.5, 0, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -0.004999926313757896, -1.003999930806458, -0.004999926313757896, -0.004999926313757896, -0.004999926313757896, -0.004999926313757896, -0.004999926313757896, -0.004999926313757896], "steps": [249, 250, 250, 250, 250, 250, 250, 250, 250, 250], "results": [0, 0, 0.5, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.7549999617040157, -1.003999930806458, 0.7589999614283442, 0.27099999506026506, 0.7550000213086605, -1.003999930806458, -1.003999930806458, 0.751000021584332, 0.5750000337138772, -1.003999930806458], "steps": [60, 250, 59, 181, 60, 250, 250, 61, 105, 250], "results": [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.9350000089034438, 0.9109999509528279, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.9949999451637268, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 15, 21, 250, 250, 250, 0, 250, 250], "results": [0, 0, 1, 1, 0, 0, 0, 1, 0, 0]}, "InternalMemory_3.yaml": {"rewards": [0.45233327988535166, 0.3789999447762966, -1.0066666910424829, -1.0066666910424829, 0.5390000082552433, 0.6923333453014493, 0.45900000631809235, -1.0066666910424829, 0.24566666781902313, -1.0066666910424829], "steps": [81, 92, 150, 150, 68, 45, 80, 150, 112, 150], "results": [1, 1, 0, 0, 1, 1, 1, 0, 1, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, -1.0099999774247408, 0.30900003761053085, 0.8390000257641077, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.6490000300109386, 0.3390000369399786], "steps": [99, 100, 100, 68, 15, 100, 100, 100, 34, 65], "results": [0, 0, 0, 1, 1, 0, 0, 0, 1, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [0.8870000122115016], "steps": [27], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.36507936507936506, "level_02_preferences": 0.5454545454545454, "level_03_obstacles": 0.8500000000000001, "level_04_avoidance": 0.5900000000000001, "level_05_spatial_reasoning": 0.65, "level_06_generalization": 0.35, "level_07_internal_memory": 0.475, "level_09_advanced_preferences": 0.2, "mean_score": 0.5031917388167388}