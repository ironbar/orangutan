{"elapsed_time": 1044.1134786605835, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2395000457763672, -0.30449991673231125, 0.17950004991143942, 0.423500033095479, 0.12350002396851778], "steps": [64, 200, 79, 18, 93], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6670000273734331, 0.810999957844615, 0.8549999548122287, 0.9030000111088157, 0.6790000265464187], "steps": [82, 46, 35, 23, 79], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7059999778866768, 1.845999968238175, 1.7460000943392515, 1.753999974578619, 1.6860000984743237], "steps": [72, 37, 62, 60, 77], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.1850000862032175, 2.8330002799630165, 2.7010000506415963, 2.837000041268766, 2.8890000376850367], "steps": [202, 40, 73, 39, 26], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.6400003656744957, 3.8560001123696566, 3.736000120639801, 3.7920001167804003, 3.644000365398824], "steps": [88, 34, 64, 50, 87], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.726999716833234, 4.634999723173678, 4.767000190913677, 4.49499973282218, 4.743000192567706], "steps": [66, 89, 56, 124, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.29950001183897257, 0.09950002562254667, 0.4395000319927931, -0.48049990460276604, 0.07150002755224705], "steps": [49, 99, 14, 244, 106], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.6830000262707472, 0.5429999763146043, 0.6110000312328339, 0.635000029578805, 0.5470000356435776], "steps": [78, 113, 96, 90, 112], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.6059999847784638, 1.8979999646544456, 1.7139999773353338, 1.8380000879988074, 1.8499999679625034], "steps": [97, 24, 70, 39, 36], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.869000039063394, 2.813000281341374, 2.9090000363066792, 2.9130000360310078, 2.877000038512051], "steps": [31, 45, 21, 20, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.768000118434429, 3.936000106856227, 3.564000370912254, 3.6720001250505447, 3.6560003645718098], "steps": [56, 14, 107, 80, 84], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.798999711871147, 4.899000181816518, 4.647000199183822, 4.594999725930393, 4.743000192567706], "steps": [48, 23, 86, 99, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.25550004467368126, 0.2875000424683094, 0.20350004825741053, 0.11550002451986074, 0.1515000518411398], "steps": [60, 52, 73, 95, 86], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.49900003895163536, 0.45100004225969315, 0.6710000270977616, -1.003999930806458], "steps": [249, 124, 136, 81, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.915000180713832, 4.114999759010971, 4.727000193670392, 4.834999709390104, 4.911000180989504], "steps": [19, 219, 66, 39, 20], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.4044999396428466, 0.10350005514919758, 0.2435000455006957, -1.003999930806458, 0.08350005652755499], "steps": [225, 98, 63, 250, 103], "results": [1, 1, 1, 0, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.743000022135675, 0.6270000301301479, 0.7230000235140324, 0.6470000287517905, 0.3990000458434224], "steps": [63, 92, 68, 87, 149], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.395000216551125, 4.32700022123754, 4.927000179886818, 4.983000176027417, 4.458999735303223], "steps": [149, 166, 16, 2, 133], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.7669999948702753, 0.6810000604018569, -1.2110000322572887, 0.9049999853596091, 0.6210000645369291], "steps": [115, 158, 105, 46, 188], "results": [1, 1, 0, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, 0.6530000027269125, 0.8510000486858189, 0.6150000053457916, 0.8789999871514738], "steps": [47, 172, 73, 191, 59], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8089999919757247, 0.049000044353306293, 0.5650000087916851, -1.2770000277087092, 0.533000010997057], "steps": [94, 474, 216, 138, 232], "results": [1, 1, 1, 0, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.4950000732205808, 0.8570000482723117, -1.2909999075345695, 0.5450000697746873, 0.2730000289157033], "steps": [251, 70, 145, 226, 362], "results": [1, 1, 0, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.804000047966838, 3.342000079806894, -0.2099999343045056, 0.7810001643374562, 1.7200000281445682], "steps": [95, 326, 104, 108, 138], "results": [1, 1, 0, 0, 0.5]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9110000445507467, 0.9149999846704304, -1.0449999244883657, 0.9069999852217734, 0.7069999990053475], "steps": [43, 41, 22, 45, 145], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.7690000543370843, 0.9130000444129109, 0.8970000455155969, 0.6750000608153641, 0.6250000642612576], "steps": [114, 42, 50, 161, 186], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.7449999963864684, 0.9069999852217734, -1.062999923247844, 0.6910000597126782, 0.9049999853596091], "steps": [126, 45, 31, 153, 46], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8630000478588045, 0.8989999857731164, 0.9149999846704304, 0.9189999843947589, 0.9209999842569232], "steps": [67, 49, 41, 39, 38], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.7309999973513186, 0.9109999849461019, 0.5710000679828227, 0.872999987564981, 0.888999986462295], "steps": [133, 43, 213, 62, 54], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.086999921593815, -1.170999915804714, -1.0529999239370227, 0.8990000453777611, 0.7449999963864684], "steps": [43, 85, 26, 49, 126], "results": [0, 0, 0, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.756999995559454], "steps": [120], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.7030000588856637], "steps": [147], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.7049999991431832], "steps": [146], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.756999995559454], "steps": [120], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-1.224999912083149], "steps": [112], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [0.6310000638477504], "steps": [183], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.7629999951459467], "steps": [117], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9070000448264182], "steps": [45], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.240999910980463], "steps": [120], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.6870000003837049, 0.603000006172806, -1.0019999309442937, -1.0019999309442937, 0.3310000249184668], "steps": [155, 197, 500, 500, 333], "results": [1, 1, 0, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.7319999760948122], "steps": [132], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [1.8060000902041793], "steps": [95], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [0.9489999823272228], "steps": [24], "results": [0]}, "YellowOverGreen_5.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_6.yaml": {"rewards": [1.7819999726489186], "steps": [107], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8359999689273536], "steps": [80], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.807000043336302], "steps": [94], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8119999705813825], "steps": [92], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.9220000565983355], "steps": [37], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [0.76700005447492], "steps": [115], "results": [0]}, "Green_sizes12_3.yaml": {"rewards": [1.9240001756697893], "steps": [36], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.934000055771321], "steps": [31], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9700000532902777], "steps": [13], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "Green_sizes12_9.yaml": {"rewards": [0.9690000405535102], "steps": [14], "results": [0]}, "Green_sizes12_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9730000402778387], "steps": [12], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.975000040140003], "steps": [11], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9649999812245369], "steps": [16], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.9749999805353582], "steps": [11], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [-0.9999999310821295, 1.5900000794790685, 0.8289999905973673, 0.8469999893568456, 0.8849999867379665, 0.9509999821893871, 0.8290000502020121, 0.94299998274073, 0.9589999816380441, 0.8609999883919954], "steps": [499, 203, 84, 75, 56, 23, 84, 27, 19, 68], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.9869999797083437, 0.7949999929405749, 0.6170000052079558, -1.0019999309442937, 0.7349999970756471, 0.7810000535100698, 0.12500003911554813, 0.9610000411048532, 0.8170000510290265, 0.8309999904595315], "steps": [5, 101, 190, 500, 131, 108, 436, 18, 90, 83], "results": [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [0.027000071480870247, -1.003999930806458, -1.003999930806458, 0.36700004804879427, -1.003999930806458], "steps": [242, 250, 250, 157, 250], "results": [1, 0, 0, 1, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.07500010216608644], "steps": [461], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.6090000653639436], "steps": [194], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [0.4710000748746097], "steps": [263], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Navigation_1.yaml": {"rewards": [1.8959999647922814, 1.6540000410750508, 1.0320000839419663, 1.7939999718219042, 1.6460000416263938], "steps": [50, 171, 482, 101, 175], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [-0.000999892596155405, -0.002999892458319664, 1.3600000613369048, 1.5560000478290021, 1.691999978851527], "steps": [499, 500, 318, 220, 152], "results": [0.5, 0.5, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [-0.9999999310821295, 1.6420000419020653, -0.0029999520629644394, -1.0019999309442937, -0.002999892458319664], "steps": [499, 177, 500, 500, 500], "results": [0, 1, 0.5, 0, 0.5]}, "Navigation_4.yaml": {"rewards": [1.85800008662045, 1.8140000896528363, 1.691999978851527, 1.7760000326670706, 1.7800000323913991], "steps": [69, 91, 152, 110, 108], "results": [1, 1, 1, 1, 1]}, "Navigation_5.yaml": {"rewards": [1.1800000737421215, 1.5980000449344516, 1.5380000490695238, 1.3420000029727817, 1.3180000642314553], "steps": [408, 199, 229, 327, 339], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.8420000281184912, -0.0029999520629644394, 1.7119999774731696, 1.6939999787136912, 1.298000006005168], "steps": [77, 500, 142, 151, 349], "results": [1, 0.5, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.5439999890513718, 1.6640000403858721, 1.7439999752677977, 1.3080000053159893, 1.4200000572018325], "steps": [226, 166, 126, 344, 288], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.737999975681305, 1.2700000675395131, 1.729999976232648, 1.6640000403858721, 1.7420000350102782], "steps": [129, 363, 133, 166, 127], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [1.7679999736137688, -1.0019999309442937, 1.5659999875351787, -0.002999892458319664, 1.802000030875206], "steps": [114, 500, 215, 500, 97], "results": [1, 0, 1, 0.5, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -0.0029999520629644394, 1.8399999686516821, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 78, 500, 500], "results": [0, 0.5, 1, 0, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [-0.9999999310821295, 1.6720000398345292, 1.352000002283603, 1.6579999811947346, -0.0029999520629644394], "steps": [499, 162, 322, 169, 500], "results": [0, 1, 1, 1, 0.5]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, -1.0019999309442937, -1.6490000020712614, -1.0019999309442937], "steps": [499, 500, 500, 324, 500], "results": [0.5, 0.5, 0, 0, 0]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [1.4939999924972653, 1.8000000310130417, 1.4099999982863665, -0.0029999520629644394, 1.7440000348724425], "steps": [251, 98, 293, 500, 126], "results": [1, 1, 1, 0.5, 1]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [1.8460000278428197, 1.1120000784285367, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937], "steps": [75, 442, 500, 500, 500], "results": [1, 1, 0, 0.5, 0]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [-0.000999892596155405, -0.0029999520629644394, -1.0019999309442937, -0.0029999520629644394, -0.002999892458319664], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0.5, 0, 0.5, 0.5]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [1.1180000184103847, -1.0019999309442937, 1.8460000278428197, 1.7360000354237854, -1.0019999309442937], "steps": [439, 500, 75, 130, 500], "results": [1, 0, 1, 1, 0]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937, 1.5799999865703285], "steps": [499, 500, 500, 500, 208], "results": [0.5, 0, 0.5, 0, 1]}, "Center_Blocked_1.yaml": {"rewards": [1.4420000556856394, 1.6280001024715602, 1.344000002834946, 1.840000028256327, 1.6799999796785414], "steps": [277, 184, 326, 78, 158], "results": [1, 1, 1, 1, 1]}, "Center_Blocked_2.yaml": {"rewards": [1.5599999879486859, -0.0029999520629644394, -0.0029999520629644394, -1.0019999309442937, -0.0029999520629644394], "steps": [218, 500, 500, 500, 500], "results": [1, 0, 0, 0, 0]}, "Center_Blocked_3.yaml": {"rewards": [1.7360000354237854, -1.0019999309442937, 1.0420000832527876, -0.0029999520629644394, -0.0029999520629644394], "steps": [130, 500, 477, 500, 500], "results": [1, 0, 1, 0, 0]}, "Center_Blocked_4.yaml": {"rewards": [1.810000030323863, 1.4880000525154173, -0.0029999520629644394, -0.0029999520629644394, -0.002999892458319664], "steps": [93, 254, 500, 500, 500], "results": [1, 1, 0, 0, 0]}, "Borders_Blocked_1.yaml": {"rewards": [1.8420000281184912, 1.8119999705813825, 1.7440000348724425, 1.8399999686516821, 1.8460000278428197], "steps": [77, 92, 126, 78, 75], "results": [1, 1, 1, 1, 1]}, "Borders_Blocked_2.yaml": {"rewards": [-0.000999892596155405, 1.8579999674111605, 1.7980000311508775, 1.7439999752677977, 1.8120000301860273], "steps": [499, 69, 99, 126, 92], "results": [0, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.5630000089295208], "steps": [217], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-1.0239998535253108], "steps": [11], "results": [0]}, "Ring_2.yaml": {"rewards": [-1.0159999732859433], "steps": [7], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.021999972872436], "steps": [10], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.013999973423779], "steps": [6], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.0179999731481075], "steps": [8], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.0119999735616148], "steps": [5], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.0106665699277073], "steps": [7], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.0106666891369969], "steps": [7], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-1.9986666785553098], "steps": [748], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-1.0899998489767313, -1.3059999532997608, -1.3119999528862536, -1.0159999732859433, -1.0159998540766537], "steps": [44, 152, 155, 7, 7], "results": [0, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [0.9090000432915986, 0.6023333733901381, 0.5956666306592524, 0.806999983265996, 0.6003332999534905], "steps": [34, 34, 34, 35, 35], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.18633329635486007, 0.42633330449461937, 0.0869999872520566, 0.9169999845325947, 0.7056666505523026], "steps": [62, 42, 45, 40, 39], "results": [1, 1, 1, 1, 1]}, "Labyrinth_1.yaml": {"rewards": [-0.3565556106623262, 0.4478888015728444, 0.27055552578531206, 0.4469999747816473, 0.4336665791925043], "steps": [119, 69, 82, 73, 73], "results": [0, 1, 1, 1, 1]}, "Labyrinth_2.yaml": {"rewards": [-1.0106666891369969, -1.0106665699277073, -1.0106665699277073, -1.01200002245605, -1.0093333558179438], "steps": [7, 7, 7, 8, 6], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-1.0119999735616148, -1.013999973423779, -1.013999973423779, -1.013999973423779, -1.013999973423779], "steps": [5, 6, 6, 6, 6], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.49366670986637473, 0.15233332011848688, 0.5443333135917783, -0.29500001296401024, -0.1329999528825283], "steps": [35, 79, 33, 86, 95], "results": [1, 1, 1, 0, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7669999785721302], "steps": [37], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7416667183861136], "steps": [40], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.7056666584685445], "steps": [39], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.743000022135675], "steps": [63], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.7750000199303031], "steps": [55], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.23500005714595318], "steps": [190], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8283333769068122], "steps": [41], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.8149999845772982], "steps": [41], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8410000437870622], "steps": [38], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.7436666511930525], "steps": [40], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.5009999861940742], "steps": [68], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.9999999310821295, 1.8360000285319984, -0.0029999520629644394, 1.4940000521019101, 1.5659999875351787, 1.7059999778866768, 1.691999978851527, -1.0019999309442937, -0.0029999520629644394, -0.002999892458319664], "steps": [499, 80, 500, 251, 215, 145, 152, 500, 500, 500], "results": [0, 1, 0.5, 1, 1, 1, 1, 0, 0.5, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -0.004999985918402672, 1.23000000230968, -1.003999930806458, -0.004999985918402672, -0.004999985918402672, 1.5500000398606062, -1.003999930806458, -1.003999930806458, -0.004999926313757896], "steps": [249, 250, 191, 250, 250, 250, 111, 250, 250, 250], "results": [0, 0.5, 1, 0, 0.5, 0.5, 1, 0, 0, 0.5]}, "Navigation_1.yaml": {"rewards": [1.4220000570639968, -0.0029999520629644394, 1.2480000094510615, 1.8819999657571316, -0.002999892458319664], "steps": [287, 500, 374, 57, 500], "results": [1, 0.5, 1, 1, 0.5]}, "Navigation_2.yaml": {"rewards": [-0.0009999522008001804, -0.0029999520629644394, 1.6220000432804227, 1.8380000283941627, 1.68399997940287], "steps": [499, 500, 187, 79, 156], "results": [0.5, 0.5, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [1.902000023983419, 1.7000000379048288, -0.002999892458319664, -0.0029999520629644394, 1.7119999774731696], "steps": [47, 148, 500, 500, 142], "results": [1, 1, 0.5, 0.5, 1]}, "Navigation_4.yaml": {"rewards": [1.702000037766993, 1.6440000417642295, 1.3859999999403954, 1.3240000042133033, -0.0029999520629644394], "steps": [147, 176, 305, 336, 500], "results": [1, 1, 1, 1, 0.5]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, 0.4149999851360917, -1.003999930806458], "steps": [249, 250, 250, 145, 250], "results": [0, 0, 0, 1, 0]}, "Navigation_on_platform_1.yaml": {"rewards": [1.8120000301860273, 1.756000034045428, 1.290000006556511, -0.0029999520629644394, 1.5199999907054007], "steps": [92, 120, 353, 500, 238], "results": [1, 1, 1, 0.5, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [1.8420000281184912, -1.0019999309442937, 1.9040000238455832, -1.0019999309442937, 1.004000026267022], "steps": [77, 500, 46, 500, 496], "results": [1, 0, 1, 0, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.0009999522008001804, 1.7240000362508, -0.0029999520629644394, -1.0019999309442937, -1.0019999309442937], "steps": [499, 136, 500, 500, 500], "results": [0.5, 1, 0.5, 0, 0]}}}, "level_01_food": 0.6333333333333333, "level_02_preferences": 0.4666666666666667, "level_03_obstacles": 0.456, "level_04_avoidance": 0.4842105263157894, "level_05_spatial_reasoning": 0.65, "level_06_generalization": 0.5000000000000001, "mean_score": 0.5317017543859649}