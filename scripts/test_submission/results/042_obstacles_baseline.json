{"elapsed_time": 1796.1362266540527, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.29950004164129496, 0.3915000054985285, 0.22750001680105925, 0.4235000032931566, 0.3515000380575657], "steps": [49, 26, 67, 18, 36], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.7149999644607306, 0.8310000160709023, 0.8550000144168735, 0.8870000122115016, 0.7670000204816461], "steps": [70, 41, 35, 27, 57], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7859999723732471, 1.845999968238175, 1.8739999663084745, 1.8579999674111605, 1.753999974578619], "steps": [52, 37, 30, 34, 60], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.8010000437498093, 2.8570000398904085, 2.8010000437498093, 2.673000290989876, 2.9050000365823507], "steps": [48, 34, 48, 80, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7480001198127866, 3.7800001176074147, 3.7320001209154725, 3.8160001151263714, 3.420000142417848], "steps": [61, 53, 65, 44, 143], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.802999711595476, 4.711000194773078, 4.838999709114432, 4.771000190638006, 4.6549997217953205], "steps": [47, 70, 38, 55, 84], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.004499937407672405, 0.18350001983344555, 0.43150003254413605, 0.3315000096336007, 0.29150001239031553], "steps": [125, 78, 16, 41, 51], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9309999495744705, 0.826999956741929, 0.6270000301301479, 0.6830000262707472, 0.5990000320598483], "steps": [16, 42, 92, 78, 99], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7939999718219042, 1.9019999643787742, 1.753999974578619, 1.842000087723136, 1.845999968238175], "steps": [50, 23, 60, 38, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.8890000376850367, 2.6850000517442822, 2.9010002752766013, 2.9090000363066792, 2.7690002843737602], "steps": [26, 77, 23, 21, 56], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.860000350512564, 3.936000106856227, 3.5480001335963607, 3.744000120088458, 3.9080001087859273], "steps": [33, 14, 111, 62, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.766999714076519, 4.903000181540847, 4.8230001870542765, 4.539000206626952, 4.8230001870542765], "steps": [56, 22, 42, 113, 42], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.29950004164129496, 0.17150005046278238, 0.2395000457763672, -0.21649992279708385, -0.384499941021204], "steps": [49, 81, 64, 178, 220], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.26699999533593655, 0.36700004804879427, 0.8430000152438879, 0.8350000157952309, 0.4349999837577343], "steps": [182, 157, 38, 40, 140], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.798999711871147, 4.751000192016363, 4.6070002019405365, 4.767000190913677, 4.719000194221735], "steps": [48, 60, 96, 56, 68], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.25150004494935274, 0.10350005514919758, 0.04350002948194742, 0.25550004467368126, 0.14350002259016037], "steps": [61, 98, 113, 60, 88], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7669999608770013, 0.5550000350922346, 0.7389999628067017, 0.7070000246167183, 0.7990000182762742], "steps": [57, 110, 64, 72, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.735000193119049, 4.587000203318894, 4.935000179335475, 4.983000176027417, 4.851000185124576], "steps": [64, 101, 14, 2, 35], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8509999890811741, 0.6929999999701977, 0.7949999929405749, 0.6969999996945262, 0.665000001899898], "steps": [73, 152, 101, 150, 166], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9049999853596091, 0.8129999917000532, 0.8710000473074615, 0.2190000326372683, 0.8549999888055027], "steps": [46, 92, 63, 389, 71], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 0.7309999973513186], "steps": [499, 500, 500, 500, 133], "results": [0, 0, 0, 0, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.4230000781826675, -1.0019999309442937, 0.6989999995566905, -1.4169998988509178, -1.0019999309442937], "steps": [287, 500, 149, 208, 500], "results": [1, 0, 1, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.423999988939613, 1.9950000056996942, 0.63700005505234, 0.9960000864230096, -1.089000040665269], "steps": [286, 500, 180, 500, 44], "results": [0.5, 0.5, 0, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.9149999846704304, 0.9170000441372395, 0.9049999853596091, 0.7789999940432608], "steps": [36, 41, 40, 46, 109], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.7529999958351254, 0.8070000517182052, 0.8870000462047756, 0.8650000477209687, -1.0569999236613512], "steps": [122, 95, 55, 66, 28], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.8929999861866236, 0.9009999856352806, -1.0730000417679548, -1.1190000385977328, -1.2089999131858349], "steps": [52, 48, 36, 59, 104], "results": [1, 1, 0, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8970000455155969, 0.6450000032782555, 0.9249999839812517, 0.9170000441372395, 0.921000043861568], "steps": [50, 176, 36, 40, 38], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.4950000732205808, 0.9129999848082662, 0.487000014167279, 0.8629999882541597, -1.03299992531538], "steps": [251, 42, 255, 67, 16], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7769999941810966, 0.4630000158213079, 0.7370000565424562, 0.9169999845325947, -1.1310000377707183], "steps": [110, 267, 130, 40, 65], "results": [1, 1, 1, 1, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8049999922513962], "steps": [96], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.8989999857731164], "steps": [49], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.9009999856352806], "steps": [48], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.8049999922513962], "steps": [96], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [0.9089999850839376], "steps": [44], "results": [1]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8749999874271452, 0.8009999925270677, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [61, 98, 500, 500, 500], "results": [1, 1, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.8320000288076699], "steps": [82], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8719999664463103], "steps": [62], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8780000256374478], "steps": [59], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.9019999643787742], "steps": [47], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.907999963965267], "steps": [44], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.877999966032803], "steps": [59], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8980000242590904], "steps": [49], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.8620001799426973], "steps": [67], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.8940001777373254], "steps": [51], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.968000172637403], "steps": [14], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.7990000522695482, 0.9229999841190875, 0.8469999893568456, 0.7429999965243042, 0.9250000435858965, 0.8969999859109521, 0.665000001899898, 0.9549999819137156, 0.6910000001080334, 0.996999979019165], "steps": [99, 37, 75, 127, 36, 50, 166, 21, 153, 0], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.7909999932162464, 0.8629999882541597, 0.8069999921135604, 0.9509999821893871, 0.9489999823272228, 0.8309999904595315, 0.7690000543370843, 0.6790000009350479, 0.8769999872893095, 0.8429999896325171], "steps": [103, 67, 95, 23, 24, 83, 114, 159, 60, 77], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, 0.15900006238371134, 0.5029999790713191, 0.818999957293272, -1.003999930806458], "steps": [249, 209, 123, 44, 250], "results": [0, 1, 1, 1, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.3470000494271517], "steps": [249, 250, 250, 250, 162], "results": [0, 0, 0, 0, 1]}, "Goal_on_platform_3.yaml": {"rewards": [0.5829999735578895, 0.7630000207573175, 0.7350000226870179, 0.6310000298544765, 0.7589999614283442], "steps": [103, 58, 65, 91, 59], "results": [1, 1, 1, 1, 1]}, "Goal_on_platform_4.yaml": {"rewards": [0.2843333682976663, 0.5883333650417626, 0.3883333671838045, 0.772333363071084, 0.4576666997745633], "steps": [267, 153, 228, 84, 202], "results": [1, 1, 1, 1, 1]}, "Goal_on_platform_5.yaml": {"rewards": [0.22500003222376108, 0.5270000114105642, 0.379000021610409, 0.641000003553927, -1.0019999309442937], "steps": [386, 235, 309, 178, 500], "results": [1, 1, 1, 1, 0]}, "Goal_on_platform_6.yaml": {"rewards": [0.7949999589473009, 0.7790000196546316, -1.003999930806458, 0.643000029027462, -1.003999930806458], "steps": [50, 54, 250, 88, 250], "results": [1, 1, 0, 1, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [0.8610000479966402], "steps": [68], "results": [1]}, "Wall_with_ramp_2.yaml": {"rewards": [0.6870000259950757], "steps": [77], "results": [1]}, "Wall_with_obstacle_1.yaml": {"rewards": [0.6370000634342432], "steps": [180], "results": [1]}, "Wall_with_obstacle_2.yaml": {"rewards": [0.01700004655867815], "steps": [490], "results": [1]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [0.3650000225752592], "steps": [316], "results": [1]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [0.5930000068619847], "steps": [202], "results": [1]}, "Wall_with_tunnel_4.yaml": {"rewards": [0.2590000298805535], "steps": [369], "results": [1]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.4770000744611025], "steps": [260], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_2.yaml": {"rewards": [0.4910000138916075], "steps": [253], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [0.20300003373995423], "steps": [397], "results": [1]}, "Navigation_1.yaml": {"rewards": [1.861999967135489, 1.491999992635101, 1.5660000471398234, 1.7759999730624259, 1.8579999674111605], "steps": [67, 252, 215, 110, 69], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [1.5200000503100455, 1.7060000374913216, 1.7080000373534858, 1.60200004465878, 1.4100000578910112], "steps": [238, 145, 144, 197, 293], "results": [1, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [1.5899999858811498, 1.8500000275671482, 1.8659999668598175, 1.4339999966323376, 1.9120000232942402], "steps": [203, 73, 65, 281, 42], "results": [1, 1, 1, 1, 1]}, "Navigation_4.yaml": {"rewards": [1.7140000369399786, 1.6000000447966158, 1.8499999679625034, 1.6920000384561718, 1.799999971408397], "steps": [141, 198, 73, 152, 98], "results": [1, 1, 1, 1, 1]}, "Navigation_5.yaml": {"rewards": [1.8379999687895179, 1.8899999652057886, 1.8479999681003392, 1.3360000629909337, 1.491999992635101], "steps": [79, 53, 74, 330, 252], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.8799999658949673, 1.4859999930486083, 1.570000046864152, 1.6819999795407057, 1.1460000164806843], "steps": [58, 255, 213, 157, 425], "results": [1, 1, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.7240000362508, 1.308000064920634, 1.6739999800920486, 1.8940000841394067, 1.2780000669881701], "steps": [136, 344, 161, 51, 359], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.6159999840892851, 1.8280000290833414, 1.7320000953041017, 1.5560000478290021, 1.5399999893270433], "steps": [190, 84, 132, 220, 228], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [1.6640000403858721, 1.8399999686516821, 1.7499999748542905, 1.75000009406358, 1.758000093512237], "steps": [166, 78, 123, 123, 119], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [1.772000032942742, 1.7439999752677977, 1.7720000925473869, 1.7440000348724425, 1.6740000396966934], "steps": [112, 126, 112, 126, 161], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_3.yaml": {"rewards": [1.6280000428669155, 1.6460001012310386, 1.8940000841394067, 1.7759999730624259, 1.4399999962188303], "steps": [184, 175, 51, 110, 278], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [1.014000085182488, 1.53400010894984, 1.8939999649301171, 1.176000074017793, 1.2840000069700181], "steps": [491, 231, 51, 410, 356], "results": [1, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [-1.1589999166317284, 1.872000026050955, -0.002999892458319664, 1.562000047415495, 1.2700000675395131], "steps": [79, 62, 500, 217, 363], "results": [0, 1, 0.5, 1, 1]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [-0.9999999310821295, 1.3280000039376318, -0.34600004414096475, 1.6639999807812274, -0.0029999520629644394], "steps": [499, 334, 172, 166, 500], "results": [0, 1, 0, 1, 0.5]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [-0.0009999522008001804, 1.5779999867081642, 1.6060000443831086, 1.2720000077970326, 1.7080000373534858], "steps": [499, 209, 195, 362, 144], "results": [0.5, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [-0.000999892596155405, -1.0019999309442937, 1.3260000636801124, 1.3260000636801124, 1.7579999743029475], "steps": [499, 500, 335, 335, 119], "results": [0.5, 0, 1, 1, 1]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [1.6019999850541353, 1.8180000893771648, 1.5220000501722097, -1.2790000275708735, 1.872000026050955], "steps": [197, 89, 237, 139, 62], "results": [1, 1, 1, 0, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8709999877028167], "steps": [63], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.713000058196485], "steps": [142], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7329999972134829], "steps": [132], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-1.5099998200312257], "steps": [254], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.3259999519214034], "steps": [162], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-1.7973333473782986], "steps": [597], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.19300003442913294, -1.183999961707741, -1.0559999705292284, -1.0019999309442937, -1.545999936759472], "steps": [402, 91, 27, 500, 272], "results": [1, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-1.1639998438768089, -1.3739999486133456, -1.1379998456686735, -2.5799998152069747, -1.2859999546781182], "steps": [81, 186, 68, 289, 142], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [-0.05566670931875706, -1.5263334172777832, 0.39099998539313674, -0.4283334366045892, -4.801000020001084], "steps": [73, 135, 53, 76, 319], "results": [1, 0, 1, 0, 0]}, "ChessBoard_4.yaml": {"rewards": [-4.823000168893486, -0.3543333695270121, 0.18433331977576017, -0.5890000336803496, -0.36366666201502085], "steps": [370, 109, 83, 103, 97], "results": [0, 0, 1, 0, 0]}, "Labyrinth_1.yaml": {"rewards": [0.029666625196114182, 0.5581110278144479, 0.4118888608645648, -9.179111166391522, 0.40877774939872324], "steps": [126, 53, 76, 750, 75], "results": [1, 1, 1, 0, 1]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [-0.8176666214130819, 0.24233337631449103, 0.048333320301026106, 0.39300004160031676, 0.33566664904356003], "steps": [104, 54, 61, 42, 44], "results": [0, 1, 1, 1, 1]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7536666579544544], "steps": [37], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7269999934360385], "steps": [37], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.712333326227963], "steps": [34], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-1.1440000580623746], "steps": [35], "results": [0]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-1.140000058338046], "steps": [34], "results": [0]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-1.132000058889389], "steps": [32], "results": [0]}, "Goal_in_DeathZone_4.yaml": {"rewards": [-1.0760000627487898], "steps": [18], "results": [0]}, "Goal_in_DeathZone_5.yaml": {"rewards": [-1.0800000624731183], "steps": [19], "results": [0]}, "Goal_in_DeathZone_6.yaml": {"rewards": [-1.0840000621974468], "steps": [20], "results": [0]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.6756666521541774], "steps": [54], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [-2.924333323724568], "steps": [254], "results": [0]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8343333168886602], "steps": [38], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [-1.6143333334475756], "steps": [179], "results": [0]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.21033332217484713], "steps": [80], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.6280000428669155, 1.4699999941512942, 1.826000029221177, 1.1180000780150294, 1.6420000419020653, 1.2200000113807619, 1.8419999685138464, -0.0029999520629644394, 1.6359999827109277, -1.0019999309442937], "steps": [184, 263, 85, 439, 177, 388, 77, 500, 180, 500], "results": [1, 1, 1, 1, 1, 1, 1, 0.5, 1, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 1.8739999579265714, 1.3100000564008951, 1.585999977774918, 1.677999971434474, -1.003999930806458, -1.003999930806458, 1.6019999766722322, -0.004999926313757896], "steps": [249, 250, 30, 171, 102, 79, 250, 250, 98, 250], "results": [0, 0, 1, 1, 1, 1, 0, 0, 1, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, 0.7470000218600035, 0.6189999710768461, 0.9029999515041709, 0.11500006541609764, 0.7470000218600035, 0.4230000441893935, 0.8910000119358301, 0.9470000080764294, -1.003999930806458], "steps": [249, 62, 94, 23, 220, 62, 143, 26, 12, 250], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.802999958395958, 0.27500005438923836, -1.003999930806458, 0.6150000309571624, -1.003999930806458, 0.8510000146925449, 0.5710000339895487, -1.003999930806458, 0.49500003922730684, 0.7750000199303031], "steps": [48, 180, 250, 95, 250, 36, 106, 250, 125, 55], "results": [1, 1, 0, 1, 0, 1, 1, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.8523333491757512, 0.792333347722888, 0.4456666726619005, 0.1589999394491315, 0.7990000145509839, 0.7656666804105043, 0.6323332842439413, 0.7523333467543125, -1.0066666910424829, 0.8123333482071757], "steps": [21, 30, 82, 125, 29, 34, 54, 36, 150, 27], "results": [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]}, "InternalMemory_4.yaml": {"rewards": [0.7690000273287296, 0.6390000302344561, -1.0099999774247408, 0.4390000347048044, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.3990000355988741, 0.6290000304579735, 0.5190000329166651], "steps": [22, 35, 100, 55, 100, 100, 100, 59, 36, 47], "results": [1, 1, 0, 1, 0, 0, 0, 1, 1, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8869999526068568], "steps": [27], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.7069999650120735], "steps": [72], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [0.7670000204816461], "steps": [57], "results": [1]}, "forcedChoice_4.yaml": {"rewards": [0.8309999564662576], "steps": [41], "results": [1]}, "forcedChoice_5.yaml": {"rewards": [0.8829999528825283], "steps": [28], "results": [0]}}}, "level_01_food": 0.6682539682539683, "level_02_preferences": 1.0, "level_03_obstacles": 0.7681818181818181, "level_04_avoidance": 0.3, "level_05_spatial_reasoning": 0.85, "level_06_generalization": 0.55, "level_07_internal_memory": 0.75, "level_09_advanced_preferences": 0.8, "mean_score": 0.7108044733044734}