{"elapsed_time": 2032.6302626132965, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2635000441223383, 0.39150003530085087, 0.25550004467368126, 0.42750000301748514, 0.3475000085309148], "steps": [58, 26, 60, 17, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6630000276491046, 0.8350000157952309, 0.859000014141202, 0.9030000111088157, 0.7310000229626894], "steps": [83, 40, 34, 23, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.745999975129962, 1.85800008662045, 1.8059999709948897, 1.877999966032803, 1.7259999765083194], "steps": [62, 34, 47, 29, 67], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.813000042922795, 2.853000278584659, 2.7850002832710743, 2.661000053398311, 2.90500027500093], "steps": [45, 35, 52, 83, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.728000359609723, 3.8720003496855497, 3.720000360161066, 3.8160001151263714, 3.8560001123696566], "steps": [66, 30, 68, 44, 34], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.799000188708305, 4.718999717384577, 4.850999708287418, 4.771000190638006, 4.835000186227262], "steps": [48, 68, 35, 55, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.31950004026293755, 0.17150002066046, 0.4355000024661422, 0.33950003888458014, 0.2915000421926379], "steps": [44, 81, 15, 39, 51], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9350000089034438, 0.6670000273734331, 0.7349999630823731, 0.6830000262707472, 0.7990000182762742], "steps": [15, 82, 65, 78, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.6620001001283526, 1.9179999632760882, 1.7540000937879086, 1.8380000879988074, 1.8419999685138464], "steps": [83, 19, 60, 39, 38], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.8890000376850367, 2.813000042922795, 2.913000274449587, 2.9170000357553363, 2.893000037409365], "steps": [26, 45, 20, 19, 25], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.868000111542642, 3.9320001071318984, 3.8400001134723425, 3.7160001220181584, 3.9040001090615988], "steps": [31, 15, 38, 69, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.811000187881291, 4.915000180713832, 4.827000186778605, 4.743000192567706, 4.803000188432634], "steps": [45, 19, 41, 62, 47], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.12350005377084017, 0.1275000236928463, 0.23150004632771015, 0.09150005597621202, 0.09150005597621202], "steps": [93, 92, 66, 101, 101], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.6389999696984887, 0.8669999539852142, 0.8389999559149146, 0.8310000160709023, 0.8469999553635716], "steps": [89, 32, 39, 41, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.795000188983977, 4.67900019697845, 4.743000192567706, 4.838999709114432, 4.78700018953532], "steps": [49, 78, 62, 38, 51], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.2395000159740448, 0.38350003585219383, 0.24750004522502422, 0.2395000159740448, 0.17950004991143942], "steps": [64, 28, 62, 64, 79], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7549999617040157, 0.41100004501640797, 0.7270000232383609, 0.7150000240653753, 0.7830000193789601], "steps": [60, 146, 67, 70, 53], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.871000183746219, 4.7070001950487494, 4.874999706633389, 4.983000176027417, 4.879000183194876], "steps": [30, 71, 29, 2, 28], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8530000485479832, 0.6670000017620623, 0.8969999859109521, 0.9189999843947589, 0.9110000445507467], "steps": [72, 165, 50, 39, 43], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, 0.8589999885298312, 0.7549999956972897, 0.8989999857731164, 0.6050000060349703], "steps": [47, 69, 121, 49, 196], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.7929999930784106, 0.7230000575073063, 0.6470000031404197, 0.7989999926649034, 0.7810000535100698], "steps": [102, 137, 175, 99, 108], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.5610000090673566, 0.6929999999701977, 0.9009999856352806, 0.7169999983161688, 0.8149999915622175], "steps": [218, 152, 48, 140, 91], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.7960001421160996, 3.6899999962188303, 0.3590001338161528, 1.4099999899044633, -1.0609999233856797], "steps": [100, 152, 319, 293, 30], "results": [0.5, 1, 0, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9270000434480608, 0.9189999843947589, 0.9169999845325947, 0.9189999843947589, 0.7909999932162464], "steps": [35, 39, 40, 39, 103], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8690000474452972, -1.216999912634492, 0.9169999845325947, -1.0569999236613512, 0.8009999925270677], "steps": [64, 108, 40, 28, 98], "results": [1, 0, 1, 0, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.04699992435053, 0.9049999853596091, 0.751000055577606, -1.1109999199397862, 0.8909999863244593], "steps": [23, 46, 123, 55, 53], "results": [0, 1, 1, 0, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9009999856352806, 0.9089999850839376, 0.9229999841190875, 0.9229999841190875, 0.9189999843947589], "steps": [48, 44, 37, 37, 39], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.7889999933540821, -1.051000043284148, 0.7710000541992486, -1.0749999224208295, -1.0449999244883657], "steps": [104, 25, 113, 37, 22], "results": [1, 0, 1, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.6610000617802143, 0.8129999917000532, -1.0389999249018729, -1.0409999247640371, -1.0229999260045588], "steps": [168, 92, 19, 20, 11], "results": [1, 1, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [0.263000029604882], "steps": [367], "results": [1]}, "RedHouse_2.yaml": {"rewards": [-1.6509998827241361], "steps": [325], "results": [0]}, "RedHouse_3.yaml": {"rewards": [0.8070000517182052], "steps": [95], "results": [1]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.8320000628009439], "steps": [82], "results": [1]}, "RedHouse_6.yaml": {"rewards": [1.8200000636279583], "steps": [88], "results": [1]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8209999911487103], "steps": [88], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.7210000576451421], "steps": [138], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.8309999904595315], "steps": [83], "results": [1]}, "DeadComing_4.yaml": {"rewards": [-1.0450000436976552], "steps": [22], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.8090000515803695], "steps": [94], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.8570000482723117], "steps": [70], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.8450000490993261], "steps": [76], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9189999843947589], "steps": [39], "results": [1]}, "RedWall_2.yaml": {"rewards": [0.317000025883317], "steps": [340], "results": [1]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8850000463426113, 0.8570000482723117, 0.6590000023134053, -1.0019999309442937, 0.6210000049322844], "steps": [56, 70, 169, 500, 188], "results": [1, 1, 1, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.8840000252239406], "steps": [56], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8819999657571316], "steps": [57], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.907999963965267], "steps": [44], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.8879999653436244], "steps": [54], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.9279999625869095], "steps": [34], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8599999672733247], "steps": [68], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.864000026602298], "steps": [66], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.805000043474138], "steps": [95], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.815999970305711], "steps": [90], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.850000087171793], "steps": [73], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9489999823272228], "steps": [24], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540001736022532], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.859000048134476, 0.9230000437237322, 0.3410000242292881, 0.8510000486858189, 0.9250000435858965, 0.9129999848082662, 0.7489999961107969, 0.9569999817758799, 0.8629999882541597, 0.996999979019165], "steps": [69, 37, 328, 73, 36, 42, 124, 20, 67, 0], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.6850000005215406, 0.6530000027269125, 0.5010000132024288, 0.9529999820515513, 0.9510000417940319, 0.12500003911554813, 0.6450000032782555, 0.05900004366412759, 0.8810000466182828, -1.0019999309442937], "steps": [156, 172, 248, 22, 23, 436, 176, 469, 58, 500], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_2.yaml": {"rewards": [0.21500009251758456], "steps": [391], "results": [1]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.8669999879784882], "steps": [65], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.8709999877028167], "steps": [63], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [0.7689999947324395], "steps": [114], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "Navigation_1.yaml": {"rewards": [1.8819999657571316, 1.8240000293590128, 1.732000035699457, 1.8060000902041793, 1.840000028256327], "steps": [57, 86, 132, 95, 78], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [1.5339999897405505, 1.6760000395588577, 1.7099999776110053, -0.0029999520629644394, 1.4040000583045185], "steps": [231, 160, 143, 500, 296], "results": [1, 1, 1, 0.5, 1]}, "Navigation_3.yaml": {"rewards": [1.5199999907054007, 1.8580000270158052, 1.869999966584146, 1.88599996548146, 1.6679999805055559], "steps": [238, 69, 63, 55, 164], "results": [1, 1, 1, 1, 1]}, "Navigation_4.yaml": {"rewards": [1.7519999747164547, 1.6239999835379422, 1.640000042039901, 1.8199999700300395, -0.0029999520629644394], "steps": [122, 186, 178, 88, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_5.yaml": {"rewards": [1.2040000720880926, 1.89999996451661, 1.6880000387318432, 1.462000054307282, 1.8939999649301171], "steps": [396, 48, 154, 267, 51], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.6519999816082418, 1.8580000270158052, 1.542000108398497, 1.815999970305711, -0.0029999520629644394], "steps": [172, 69, 227, 90, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_7.yaml": {"rewards": [1.7620000336319208, 1.8499999679625034, 1.7139999773353338, 1.9040000238455832, 1.7879999722354114], "steps": [117, 73, 141, 46, 104], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.4600001140497625, 1.8439999683760107, 1.6120000439696014, 1.475999993737787, 1.4620001139119267], "steps": [268, 76, 192, 260, 267], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [-0.000999892596155405, -0.0029999520629644394, 1.6900000385940075, 1.8460000278428197, 1.8360000285319984], "steps": [499, 500, 153, 75, 80], "results": [0.5, 0.5, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -0.002999892458319664, -0.002999892458319664, -0.0029999520629644394, 1.262000068090856], "steps": [499, 500, 500, 500, 367], "results": [0, 0.5, 0.5, 0.5, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.3969999002292752], "steps": [499, 500, 500, 500, 198], "results": [0, 0, 0, 0, 0]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [-1.186999914702028, 1.8939999649301171, 1.9460000209510326, 1.7160000368021429, -0.0029999520629644394], "steps": [93, 51, 25, 140, 500], "results": [0, 1, 1, 1, 0.5]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [-1.3009999068453908, -0.0029999520629644394, 1.6840000390075147, 1.6120000439696014, -0.0029999520629644394], "steps": [150, 500, 156, 192, 500], "results": [0, 0.5, 1, 1, 0.5]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [1.3740000007674098, 1.872000026050955, 1.772000032942742, 1.9140000231564045, 1.5279999901540577], "steps": [311, 62, 112, 41, 234], "results": [1, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, 1.7660000333562493], "steps": [499, 500, 500, 500, 115], "results": [0.5, 0, 0, 0.5, 1]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [-0.9999999310821295, 1.8360000285319984, -1.0019999309442937, -1.1109999199397862, 1.8620000267401338], "steps": [499, 80, 500, 55, 67], "results": [0, 1, 0, 0, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8589999885298312], "steps": [69], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8270000503398478], "steps": [85], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.772999994456768], "steps": [112], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.6910000597126782], "steps": [153], "results": [1]}, "Ring_1.yaml": {"rewards": [0.657000002451241], "steps": [170], "results": [1]}, "Ring_2.yaml": {"rewards": [-1.3719999487511814], "steps": [185], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.7119998061098158], "steps": [355], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.6379999304190278], "steps": [318], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.7739999210461974], "steps": [386], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.4059998271986842], "steps": [202], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.178666568128392], "steps": [133], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.210666686994955], "steps": [157], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.7923333258368075], "steps": [154], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.4149999369401485], "steps": [437], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-1.0799999688751996, 0.8749999874271452, -1.0019999309442937, -1.7379998043179512, 0.7449999963864684], "steps": [39, 61, 500, 368, 126], "results": [0, 1, 0, 0, 1]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [0.1163332974538207, -2.012333430815488, -0.20433340361341834, -4.117666852660477, -0.6709999674931169], "steps": [77, 208, 84, 364, 164], "results": [1, 0, 0, 0, 0]}, "ChessBoard_4.yaml": {"rewards": [-1.7456667814403772, 0.10033338749781251, -5.268666740041226, 0.20099995099008083, -5.255333409179002], "steps": [208, 145, 500, 118, 500], "results": [0, 1, 0, 1, 0]}, "Labyrinth_1.yaml": {"rewards": [-5.559666820568964, 0.06788884941488504, -3.5316667784936726, -4.071666778298095, -7.761333586182445], "steps": [658, 124, 467, 422, 750], "results": [0, 1, 0, 0, 0]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.7319998047314584, -1.0019999309442937], "steps": [499, 500, 500, 365, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [-2.8196666561998427, -0.5550000104121864, -7.9420000477693975, -7.742000042460859, 0.2736666537821293], "steps": [295, 116, 500, 500, 75], "results": [0, 0, 0, 0, 1]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.2790000019595027], "steps": [69], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [-0.7809998961165547], "steps": [224], "results": [0]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.3750000037252903], "steps": [75], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.8070000177249312], "steps": [47], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.8030000180006027], "steps": [48], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.7870000191032887], "steps": [52], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.6709999954327941], "steps": [123], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.6143333236686885], "steps": [88], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.15766666876152158], "steps": [183], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [-0.50899992370978], "steps": [293], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [-1.5829999768175185], "steps": [350], "results": [0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.8360000285319984, 1.732000035699457, 1.8120000301860273, -0.002999892458319664, 1.7220000363886356, 1.3200000044889748, 1.869999966584146, 1.4579999949783087, 1.7119999774731696, 1.5720000467263162], "steps": [80, 132, 92, 500, 137, 338, 63, 269, 142, 212], "results": [1, 1, 1, 0.5, 1, 1, 1, 1, 1, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [1.5579999797046185, -0.004999926313757896, 1.8339999606832862, 1.2859999984502792, -0.004999926313757896, 1.7659999057650566, -0.004999926313757896, -0.004999926313757896, 1.418000048957765, -0.004999985918402672], "steps": [109, 250, 40, 177, 250, 57, 250, 250, 144, 250], "results": [1, 0.5, 1, 1, 0.5, 1, 0.5, 0.5, 1, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, 0.743000022135675, 0.1070000659674406, 0.9069999512284994, 0.7910000188276172, 0.24699999671429396, -1.003999930806458, 0.8910000119358301, 0.9389999490231276, 0.2630000552162528], "steps": [249, 63, 222, 22, 51, 187, 250, 26, 14, 183], "results": [0, 1, 1, 1, 1, 1, 0, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.23899999726563692, -1.003999930806458, 0.5590000348165631, 0.9350000089034438, 0.818999957293272, 0.5030000386759639, -1.003999930806458, 0.19900005962699652, 0.8910000119358301, 0.9070000108331442], "steps": [189, 250, 109, 15, 44, 123, 250, 199, 26, 22], "results": [1, 0, 1, 1, 1, 1, 0, 1, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.6256666770204902, 0.7789999544620514, 0.45233327988535166, 0.658999951556325, 0.6723333448171616, 0.3856666712090373, 0.5256666745990515, 0.7523333467543125, 0.5389999486505985, 0.8190000150352716], "steps": [55, 32, 81, 50, 48, 91, 70, 36, 68, 26], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.7690000273287296, 0.25900003872811794, 0.19900004006922245, 0.48900003358721733, 0.7190000284463167, 0.2290000393986702, -1.0099999774247408, 0.23900003917515278, -1.0099999774247408, 0.20900003984570503], "steps": [22, 73, 79, 50, 27, 76, 100, 75, 100, 78], "results": [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8870000122115016], "steps": [27], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [0.826999956741929], "steps": [42], "results": [1]}, "forcedChoice_5.yaml": {"rewards": [0.8869999526068568], "steps": [27], "results": [0]}}}, "level_01_food": 0.7968253968253969, "level_02_preferences": 1.0, "level_03_obstacles": 0.4795454545454545, "level_04_avoidance": 0.5368421052631579, "level_05_spatial_reasoning": 0.95, "level_06_generalization": 0.75, "level_07_internal_memory": 0.8500000000000001, "level_09_advanced_preferences": 0.4, "mean_score": 0.7204016195792512}