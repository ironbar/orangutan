{"elapsed_time": 429.97535610198975, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2915000421926379, 0.38750003557652235, 0.23150001652538776, 0.42750000301748514, 0.3475000085309148], "steps": [51, 27, 66, 17, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6389999696984887, 0.8310000160709023, 0.8549999548122287, 0.5910000326111913, 0.7309999633580446], "steps": [89, 41, 35, 101, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.77799997292459, 1.85800008662045, 1.7859999723732471, 1.8820000849664211, 1.729999976232648], "steps": [54, 34, 52, 28, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.813000042922795, 2.8570002783089876, 2.8090000431984663, 2.877000038512051, 2.9090000363066792], "steps": [45, 34, 46, 29, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.736000120639801, 3.876000110991299, 3.720000360161066, 3.8240001145750284, 3.852000351063907], "steps": [64, 29, 68, 42, 35], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.559000205248594, 4.623000200837851, 4.851000185124576, 4.675000197254121, 4.863000184297562], "steps": [108, 92, 35, 79, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.3115000408142805, 0.25550004467368126, 0.4355000024661422, 0.34350003860890865, 0.18350001983344555], "steps": [46, 60, 15, 38, 78], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9350000089034438, 0.419000044465065, 0.5829999735578895, 0.6550000282004476, 0.7749999603256583], "steps": [15, 144, 103, 85, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.661999980919063, 1.9099999638274312, 1.758000093512237, 1.845999968238175, 1.85800008662045], "steps": [83, 21, 59, 37, 34], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.885000037960708, 2.7770002838224173, 2.9130000360310078, 2.9170000357553363, 2.885000037960708], "steps": [27, 54, 20, 19, 27], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.868000111542642, 3.9320001071318984, 3.264000153169036, 3.7400001203641295, 3.9040001090615988], "steps": [31, 15, 182, 63, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.826999709941447, 4.914999703876674, 4.827000186778605, 4.57100020442158, 4.794999712146819], "steps": [41, 19, 41, 105, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.2875000424683094, 0.1075000548735261, 0.23150004632771015, 0.2195000471547246, -1.003999930806458], "steps": [52, 97, 66, 69, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.8669999539852142, 0.8229999570176005, 0.8390000155195594, 0.8350000157952309, 0.8550000144168735], "steps": [32, 43, 39, 40, 35], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.799000188708305, 4.687000196427107, 4.739000192843378, 4.838999709114432, 4.923000180162489], "steps": [48, 76, 63, 38, 17], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.18350001983344555, 0.3795000361278653, 0.24750004522502422, 0.1075000548735261, 0.1275000236928463], "steps": [78, 29, 62, 97, 92], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.6310000298544765, 0.2670000549405813, 0.7390000224113464, 0.6469999691471457, 0.31500005163252354], "steps": [91, 182, 64, 87, 170], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.866999707184732, 4.699000195600092, 4.891000182367861, 4.983000176027417, 4.842999708838761], "steps": [31, 73, 25, 2, 37], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8650000477209687, 0.6070000655017793, 0.7909999932162464, 0.9169999845325947, 0.7710000541992486], "steps": [66, 195, 103, 40, 113], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9089999850839376, 0.859000048134476, 0.8769999872893095, 0.9049999853596091, 0.5730000082403421], "steps": [44, 69, 60, 46, 212], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8430000492371619, 0.8970000455155969, -1.0019999309442937, 0.6830000602640212, -1.2710000281222165], "steps": [77, 50, 500, 157, 135], "results": [1, 1, 0, 1, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.5990000064484775, 0.8369999900460243, 0.8969999859109521, 0.3070000265724957, -1.0019999309442937], "steps": [199, 80, 50, 345, 500], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.796000048518181, 3.191999970935285, 1.9950001249089837, 3.677999997045845, 3.687999996356666], "steps": [99, 401, 500, 158, 153], "results": [1, 1, 0.5, 1, 1]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.864999988116324, 0.9149999846704304, 0.9149999846704304, 0.9150000442750752], "steps": [36, 66, 41, 41, 41], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.859000048134476, 0.8570000482723117, -1.043000043835491, 0.7769999941810966, -1.1069999202154577], "steps": [69, 70, 21, 110, 53], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.04699992435053, 0.9010000452399254, 0.9149999846704304, -1.2010000329464674, -1.1070000394247472], "steps": [23, 48, 41, 100, 53], "results": [0, 1, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9009999856352806, 0.8990000453777611, 0.9189999843947589, 0.9229999841190875, 0.9230000437237322], "steps": [48, 49, 39, 37, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, -1.054999923799187, -1.1489999173209071, -1.0409999247640371, 0.8209999911487103], "steps": [47, 27, 74, 20, 88], "results": [1, 0, 0, 0, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0389999249018729, 0.8390000495128334, -1.0470000435598195, 0.9149999846704304, 0.7689999947324395], "steps": [19, 79, 23, 41, 114], "results": [0, 1, 0, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.2060002251528203], "steps": [395], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.6790000000037253], "steps": [339], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.1030000397004187], "steps": [51], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.04699992435053], "steps": [23], "results": [0]}, "DeadComing_3.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "DeadComing_4.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.7949999929405749], "steps": [101], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.7010000590234995], "steps": [148], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.4670000155456364], "steps": [265], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [1.7760000326670706], "steps": [110], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8800000851042569], "steps": [58], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8140000300481915], "steps": [91], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.902000023983419], "steps": [47], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.934000021778047], "steps": [31], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.745999975129962], "steps": [125], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.9000000241212547], "steps": [48], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.9670000323094428], "steps": [14], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8659999668598175], "steps": [65], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.8690001582726836], "steps": [63], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.748000034596771], "steps": [124], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.8589999885298312, 0.7830000533722341, 0.7949999929405749, 0.8849999867379665, 0.9490000419318676, 0.8529999889433384, 0.6530000623315573, 0.8629999882541597, 0.8990000453777611, 0.7829999937675893], "steps": [69, 107, 101, 56, 24, 72, 172, 67, 49, 107], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.751000021584332, 0.8629999542608857, 0.4349999837577343, 0.6869999663904309, -1.003999930806458, 0.8429999556392431, 0.47099998127669096, 0.9509999481961131, 0.5390000361949205, -1.003999930806458], "steps": [61, 33, 140, 77, 250, 38, 131, 11, 114, 250], "results": [1, 1, 1, 1, 0, 1, 1, 1, 1, 0]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8430000492371619], "steps": [77], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.7929999930784106], "steps": [102], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [0.11766660679131746], "steps": [660], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.3840000596828759, 1.880000025499612, -0.0029999520629644394, 1.694000038318336, 1.3640000014565885, 1.702000037766993, -0.002999892458319664, 1.7140000369399786, 1.7059999778866768, -1.0019999309442937], "steps": [306, 58, 500, 151, 316, 147, 500, 141, 145, 500], "results": [1, 1, 0.5, 1, 1, 1, 0.5, 1, 1, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, 1.2500000009313226, 1.777999964542687, -1.003999930806458, -0.004999926313757896, 1.577999978326261, -0.004999926313757896, -0.004999985918402672, -0.004999926313757896, -0.004999926313757896], "steps": [249, 186, 54, 250, 250, 104, 250, 250, 250, 250], "results": [0.5, 1, 1, 0, 0.5, 1, 0.5, 0.5, 0.5, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.9110000105574727, -1.003999930806458, 0.7270000232383609, -1.003999930806458, -1.003999930806458, 0.4189999848604202, 0.38300004694610834, -1.003999930806458, 0.22700005769729614, 0.2589999958872795], "steps": [21, 250, 67, 250, 250, 144, 153, 250, 192, 184], "results": [1, 0, 1, 0, 0, 1, 1, 0, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, 0.9270000094547868, 0.8390000155195594, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.8589999545365572, 0.9149999506771564, 0.859000014141202], "steps": [249, 17, 39, 250, 250, 250, 250, 34, 20, 34], "results": [0, 1, 1, 0, 0, 0, 0, 1, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.6190000101923943, 0.7590000135824084, 0.7189999530091882, 0.8190000150352716, 0.6123333433642983, 0.6123333433642983, 0.8390000155195594, 0.6856666188687086, 0.41233333852142096, 0.9323333511129022], "steps": [56, 35, 41, 26, 57, 57, 23, 46, 87, 9], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.2690000385046005, -1.0099999774247408, -1.0099999774247408, 0.5990000311285257, 0.5590000320225954, 0.7690000273287296, -1.0099999774247408, -1.0099999774247408, 0.3990000355988741, -1.0099999774247408], "steps": [72, 100, 100, 39, 43, 22, 100, 100, 59, 100], "results": [1, 0, 0, 1, 1, 1, 0, 0, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8709999537095428], "steps": [31], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.8830000124871731], "steps": [28], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.8950000116601586], "steps": [25], "results": [0]}}}, "level_01_food": 0.6951612903225807, "level_03_obstacles": 0.9, "level_04_avoidance": 0.25, "level_05_spatial_reasoning": 0.8, "level_06_generalization": 0.6, "level_07_internal_memory": 0.65, "level_09_advanced_preferences": 0.4, "mean_score": 0.613594470046083}