{"elapsed_time": 1845.8214256763458, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2915000421926379, 0.38750003557652235, 0.23150001652538776, 0.42750000301748514, 0.3475000085309148], "steps": [51, 27, 66, 17, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6389999696984887, 0.8310000160709023, 0.8549999548122287, 0.5910000326111913, 0.7309999633580446], "steps": [89, 41, 35, 101, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.77799997292459, 1.85800008662045, 1.7859999723732471, 1.8820000849664211, 1.729999976232648], "steps": [54, 34, 52, 28, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.813000042922795, 2.8570002783089876, 2.8090000431984663, 2.877000038512051, 2.9090000363066792], "steps": [45, 34, 46, 29, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.736000120639801, 3.876000110991299, 3.720000360161066, 3.8240001145750284, 3.852000351063907], "steps": [64, 29, 68, 42, 35], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.559000205248594, 4.623000200837851, 4.851000185124576, 4.675000197254121, 4.863000184297562], "steps": [108, 92, 35, 79, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.3115000408142805, 0.25550004467368126, 0.4355000024661422, 0.34350003860890865, 0.18350001983344555], "steps": [46, 60, 15, 38, 78], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9350000089034438, 0.419000044465065, 0.5829999735578895, 0.6550000282004476, 0.7749999603256583], "steps": [15, 144, 103, 85, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.661999980919063, 1.9099999638274312, 1.758000093512237, 1.845999968238175, 1.85800008662045], "steps": [83, 21, 59, 37, 34], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.885000037960708, 2.7770002838224173, 2.9130000360310078, 2.9170000357553363, 2.885000037960708], "steps": [27, 54, 20, 19, 27], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.868000111542642, 3.9320001071318984, 3.264000153169036, 3.7400001203641295, 3.9040001090615988], "steps": [31, 15, 182, 63, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.826999709941447, 4.914999703876674, 4.827000186778605, 4.57100020442158, 4.794999712146819], "steps": [41, 19, 41, 105, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.2875000424683094, 0.1075000548735261, 0.23150004632771015, 0.2195000471547246, -1.003999930806458], "steps": [52, 97, 66, 69, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.8669999539852142, 0.8229999570176005, 0.8390000155195594, 0.8350000157952309, 0.8550000144168735], "steps": [32, 43, 39, 40, 35], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.799000188708305, 4.687000196427107, 4.739000192843378, 4.838999709114432, 4.923000180162489], "steps": [48, 76, 63, 38, 17], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.18350001983344555, 0.3795000361278653, 0.24750004522502422, 0.1075000548735261, 0.1275000236928463], "steps": [78, 29, 62, 97, 92], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.6310000298544765, 0.2670000549405813, 0.7390000224113464, 0.6469999691471457, 0.31500005163252354], "steps": [91, 182, 64, 87, 170], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.866999707184732, 4.699000195600092, 4.891000182367861, 4.983000176027417, 4.842999708838761], "steps": [31, 73, 25, 2, 37], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8650000477209687, 0.6070000655017793, 0.7909999932162464, 0.9169999845325947, 0.7710000541992486], "steps": [66, 195, 103, 40, 113], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9089999850839376, 0.859000048134476, 0.8769999872893095, 0.9049999853596091, 0.5730000082403421], "steps": [44, 69, 60, 46, 212], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8430000492371619, 0.8970000455155969, -1.0019999309442937, 0.6830000602640212, -1.2710000281222165], "steps": [77, 50, 500, 157, 135], "results": [1, 1, 0, 1, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.5990000064484775, 0.8369999900460243, 0.8969999859109521, 0.3070000265724957, -1.0019999309442937], "steps": [199, 80, 50, 345, 500], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.796000048518181, 3.191999970935285, 1.9950001249089837, 3.677999997045845, 3.687999996356666], "steps": [99, 401, 500, 158, 153], "results": [1, 1, 0.5, 1, 1]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.864999988116324, 0.9149999846704304, 0.9149999846704304, 0.9150000442750752], "steps": [36, 66, 41, 41, 41], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.859000048134476, 0.8570000482723117, -1.043000043835491, 0.7769999941810966, -1.1069999202154577], "steps": [69, 70, 21, 110, 53], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.04699992435053, 0.9010000452399254, 0.9149999846704304, -1.2010000329464674, -1.1070000394247472], "steps": [23, 48, 41, 100, 53], "results": [0, 1, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9009999856352806, 0.8990000453777611, 0.9189999843947589, 0.9229999841190875, 0.9230000437237322], "steps": [48, 49, 39, 37, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, -1.054999923799187, -1.1489999173209071, -1.0409999247640371, 0.8209999911487103], "steps": [47, 27, 74, 20, 88], "results": [1, 0, 0, 0, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0389999249018729, 0.8390000495128334, -1.0470000435598195, 0.9149999846704304, 0.7689999947324395], "steps": [19, 79, 23, 41, 114], "results": [0, 1, 0, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.2060002251528203], "steps": [395], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.6790000000037253], "steps": [339], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.1030000397004187], "steps": [51], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.04699992435053], "steps": [23], "results": [0]}, "DeadComing_3.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "DeadComing_4.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.7949999929405749], "steps": [101], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.7010000590234995], "steps": [148], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.4670000155456364], "steps": [265], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.5010000728070736, -1.0019999309442937, 0.8090000515803695, 0.14900009706616402, 0.751000055577606], "steps": [248, 500, 94, 424, 123], "results": [1, 0, 1, 1, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.7760000326670706], "steps": [110], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8840000252239406], "steps": [56], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8659999668598175], "steps": [65], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.9099999638274312], "steps": [43], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.915999963413924], "steps": [40], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.6840000390075147], "steps": [156], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8879999653436244], "steps": [54], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.9630002113990486], "steps": [16], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8120000301860273], "steps": [92], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9680000534281135], "steps": [14], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.7819999726489186], "steps": [107], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.9240001756697893], "steps": [36], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9430000423453748], "steps": [27], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540001736022532], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9520000545307994], "steps": [22], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [1.9500000546686351], "steps": [23], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.810999991837889, 0.9229999841190875, 0.17700009513646364, 0.8229999910108745, 0.9250000435858965, 0.8609999883919954, 0.7169999983161688, 0.9590000412426889, 0.665000001899898, 0.996999979019165], "steps": [93, 37, 410, 87, 36, 68, 140, 19, 166, 0], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.6470000031404197, 0.4390000174753368, -1.0019999309442937, 0.9509999821893871, 0.9509999821893871, 0.643000063020736, 0.7330000568181276, -1.0019999309442937, 0.864999988116324, -1.0019999309442937], "steps": [175, 279, 500, 23, 23, 177, 132, 500, 66, 500], "results": [1, 1, 0, 1, 1, 1, 1, 0, 1, 0]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [0.6630000616423786], "steps": [167], "results": [1]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9270000434480608], "steps": [35], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [0.702999999281019], "steps": [147], "results": [1]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.6929999999701977], "steps": [152], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.8549999888055027], "steps": [71], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [0.8009999925270677], "steps": [98], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [0.6630000020377338], "steps": [167], "results": [1]}, "Navigation_1.yaml": {"rewards": [1.7479999749921262, 1.8039999711327255, 1.8200000296346843, 1.7680000332184136, 1.4459999958053231], "steps": [124, 96, 88, 114, 275], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [1.36000000173226, 1.7240000362508, 1.6099999845027924, 1.6779999798163772, 1.7540000341832638], "steps": [318, 136, 193, 159, 121], "results": [1, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [-0.0009999522008001804, 1.8039999711327255, 1.7180000366643071, 1.7719999733380973, -0.002999892458319664], "steps": [499, 96, 139, 112, 500], "results": [0.5, 1, 1, 1, 0.5]}, "Navigation_4.yaml": {"rewards": [1.3660000013187528, 1.2960000061430037, 1.7760000326670706, 1.3040000651963055, 1.8219999698922038], "steps": [315, 350, 110, 346, 87], "results": [1, 1, 1, 1, 1]}, "Navigation_5.yaml": {"rewards": [1.8360000285319984, 1.9039999642409384, 1.8359999689273536, 1.4840000527910888, 1.7759999730624259], "steps": [80, 46, 80, 256, 110], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.699999978300184, 1.5120000508613884, 1.4340000562369823, 1.7900000317022204, 1.0760000213049352], "steps": [148, 242, 281, 103, 460], "results": [1, 1, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.8119999705813825, 1.8320000884123147, 1.5820001056417823, 1.902000023983419, 1.7140000369399786], "steps": [92, 82, 207, 47, 141], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [-0.0009999522008001804, 1.799999971408397, 1.6099999845027924, -0.0029999520629644394, 1.1860000137239695], "steps": [499, 98, 193, 500, 405], "results": [0.5, 1, 1, 0.5, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [-0.000999892596155405, 1.8499999679625034, 1.3400000031106174, 1.8200000296346843, 1.8299999693408608], "steps": [499, 73, 328, 88, 83], "results": [0.5, 1, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [1.5580000476911664, -1.0019999309442937, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937], "steps": [219, 500, 500, 500, 500], "results": [1, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [1.758000093512237, -0.0029999520629644394, -0.0029999520629644394, -0.0029999520629644394, -1.0019999309442937], "steps": [119, 500, 500, 500, 500], "results": [1, 0.5, 0.5, 0.5, 0]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8330000499263406], "steps": [82], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.6870000003837049], "steps": [155], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7789999940432608], "steps": [109], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [0.19633333222009242], "steps": [601], "results": [1]}, "ChessBoard_1.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [-5.119000041857362, -0.3156666769646108, 0.5696666538715363, -1.5023334906436503, 0.03566665668040514], "steps": [358, 103, 87, 113, 104], "results": [0, 0, 1, 0, 1]}, "ChessBoard_4.yaml": {"rewards": [-9.360000541433692, -4.282333598937839, 0.4876667130738497, -1.6196666448377073, -6.322000163141638], "steps": [499, 433, 78, 355, 500], "results": [0, 0, 1, 0, 0]}, "Labyrinth_1.yaml": {"rewards": [-3.628111276542768, -1.4516667590942234, -2.4370001105125993, -1.239222307689488, -0.020111149875447154], "steps": [386, 257, 316, 211, 180], "results": [0, 0, 0, 0, 1]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [-9.166666641831398, -2.2856665975414217, -7.464999971911311, -6.695333283860236, -1.1703333407640457], "steps": [499, 268, 431, 500, 127], "results": [0, 0, 0, 0, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.2883333321660757], "steps": [70], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [-1.0399999311193824], "steps": [249], "results": [0]}, "Goal_in_HotZone_3.yaml": {"rewards": [-1.6533332662656903], "steps": [249], "results": [0]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.8190000168979168], "steps": [44], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.7830000193789601], "steps": [53], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.7830000193789601], "steps": [53], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.2883333289064467], "steps": [131], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.5729999938048422], "steps": [122], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.06966671347618103], "steps": [77], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.1376667283475399], "steps": [183], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [-0.22099997801706195], "steps": [319], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.553999988362193, 1.6640000403858721, -0.0029999520629644394, 1.437999996356666, -0.002999892458319664, 1.7280000359751284, 1.8320000288076699, 1.3980001183226705, 1.799999971408397, 1.4520000549964607], "steps": [221, 166, 500, 279, 500, 134, 82, 299, 98, 272], "results": [1, 1, 0.5, 1, 0.5, 1, 1, 1, 1, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, -0.004999985918402672, 1.1100000701844692, 1.2100000036880374, 1.16200006660074, -0.004999985918402672, 1.5419999808073044, -0.004999926313757896, 1.5979999173432589, 1.4899999843910336], "steps": [249, 250, 221, 196, 208, 250, 113, 250, 99, 126], "results": [0.5, 0.5, 1, 1, 1, 0.5, 1, 0.5, 1, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.7670000204816461, 0.7670000204816461, 0.9149999506771564, 0.40300004556775093, 0.9430000083521008, 0.08700000774115324, 0.9430000083521008, 0.3869999870657921, 0.9030000111088157, 0.8110000174492598], "steps": [57, 57, 20, 148, 13, 227, 13, 152, 23, 46], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.5109999785199761, -1.003999930806458, 0.5389999765902758, 0.0390000706538558, 0.8869999526068568, 0.8910000119358301, 0.8150000171735883, 0.5989999724552035, -1.003999930806458, 0.8630000138655305], "steps": [121, 250, 114, 239, 27, 26, 45, 99, 250, 33], "results": [1, 0, 1, 1, 1, 1, 1, 1, 0, 1]}, "InternalMemory_3.yaml": {"rewards": [0.6389999510720372, 0.7323333462700248, 0.5990000097081065, 0.6923332856968045, 0.7523333467543125, -1.0066666910424829, 0.7923332881182432, 0.4790000068023801, 0.49899994768202305, 0.6656666779890656], "steps": [53, 39, 59, 45, 36, 150, 30, 77, 74, 49], "results": [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.5190000329166651, -1.0099999774247408, 0.8690000250935555, -1.0099999774247408, -1.0099999774247408, 0.329000037163496, 0.23900003917515278, 0.36900003626942635, 0.6190000306814909, -1.0099999774247408], "steps": [47, 100, 12, 100, 100, 66, 75, 62, 37, 100], "results": [1, 0, 1, 0, 0, 1, 1, 1, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8830000124871731], "steps": [28], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.8869999526068568], "steps": [27], "results": [0]}}}, "level_01_food": 0.6968253968253969, "level_02_preferences": 1.0, "level_03_obstacles": 0.48717948717948717, "level_04_avoidance": 0.4421052631578948, "level_05_spatial_reasoning": 0.9, "level_06_generalization": 0.8, "level_07_internal_memory": 0.8250000000000001, "level_09_advanced_preferences": 0.2, "mean_score": 0.6688887683953475}