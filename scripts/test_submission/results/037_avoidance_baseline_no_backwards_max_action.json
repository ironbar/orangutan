{"elapsed_time": 609.5032062530518, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.24750001542270184, -1.003999930806458, -1.003999930806458, 0.4195000035688281, 0.035500030033290386], "steps": [62, 250, 250, 19, 115], "results": [1, 0, 0, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.7910000188276172, 0.6830000262707472, 0.8510000146925449, 0.9030000111088157, 0.6270000301301479], "steps": [51, 78, 36, 23, 92], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.737999975681305, 1.85800008662045, 1.626000102609396, 1.5859999861568213, -1.003999930806458], "steps": [64, 34, 92, 102, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoal_size3.yaml": {"rewards": [2.445000068284571, -1.003999930806458, 2.5090003022924066, -1.003999930806458, 2.8970000371336937], "steps": [137, 250, 121, 250, 24], "results": [1, 0, 1, 0, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.6840001242235303, 3.876000110991299, 3.704000122845173, 3.8080001156777143, 3.5320001346990466], "steps": [77, 29, 72, 46, 115], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.459000212140381, 4.647000199183822, 4.855000184848905, 4.763000191189349, 4.147000233642757], "steps": [133, 86, 34, 57, 211], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.09500000718981028, 0.8110000174492598, 0.027000071480870247, -1.003999930806458, -1.003999930806458], "steps": [225, 46, 242, 250, 250], "results": [1, 1, 1, 0, 0]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7659999737516046, 1.5500001078471541, 1.7419999754056334, 1.8419999685138464, 1.8379999687895179], "steps": [57, 111, 63, 38, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.605000057257712, 2.805000043474138, 2.189000085927546, 2.897000275552273, 2.8930002758279443], "steps": [97, 47, 201, 24, 25], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.2160001564770937, 3.936000106856227, 3.7240001214668155, 3.180000397376716, 3.0920001650229096], "steps": [194, 14, 67, 203, 225], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.811000187881291, 4.2750002248212695, 4.659000198356807, 4.6150002013891935, 4.639000199735165], "steps": [45, 179, 83, 94, 88], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.3124999161809683, -1.003999930806458, -1.003999930806458, 0.07150002755224705, -1.003999930806458], "steps": [202, 250, 250, 106, 250], "results": [1, 0, 0, 1, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.41100004501640797, -1.003999930806458, 0.6189999710768461, -1.003999930806458], "steps": [249, 146, 250, 94, 250], "results": [0, 1, 0, 1, 0]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.235000227577984, 4.455000212416053, 4.811000187881291, 4.595000202767551], "steps": [249, 189, 134, 45, 99], "results": [0, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, 0.11950005404651165, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 94, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.9070000108331442, 0.5830000331625342, -1.003999930806458, 0.751000021584332], "steps": [249, 22, 103, 250, 61], "results": [0, 1, 1, 0, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.866999707184732, 4.603000202216208, 4.954999701119959, 4.983000176027417, 4.851000185124576], "steps": [31, 97, 9, 2, 35], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.1030000397004187, -1.03299992531538, -1.0309999254532158, -1.0389999249018729, -1.0390000441111624], "steps": [51, 16, 15, 19, 19], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0569999236613512, -1.0770000414922833, -1.0509999240748584, -1.0449999244883657, -1.0489999242126942], "steps": [28, 38, 25, 22, 24], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.0930000403895974, -1.0470000435598195, -1.0849999217316508, -1.035000044386834, -1.1449999175965786], "steps": [46, 23, 42, 17, 72], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.0509999240748584, -2.1139999921433628, -1.0489999242126942, -1.03299992531538, -1.1829999149776995], "steps": [25, 57, 24, 16, 91], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.1030000397004187, -1.1729999156668782, -0.10599994147196412, -1.0909999213181436, -1.051000043284148], "steps": [51, 86, 52, 45, 25], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [-1.0689999228343368, 0.8869999866001308, -1.1450000368058681, -1.059000042732805, -1.1209999192506075], "steps": [34, 55, 72, 29, 60], "results": [0, 1, 0, 0, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [-1.0570000428706408, -1.1810000343248248, -1.1269999188371003, -1.0389999249018729, -1.1349999182857573], "steps": [28, 90, 63, 19, 67], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0470000435598195, -1.1029999204911292, -1.0969999209046364, -1.0829999218694866, -1.0550000430084765], "steps": [23, 51, 48, 41, 27], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [-1.121000038459897, -1.1209999192506075, -1.1890000337734818, -1.070999922696501, -1.0909999213181436], "steps": [60, 60, 94, 35, 45], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-2.0639999955892563, -1.170999915804714, -1.016999926418066, -1.2009999137371778, -1.0809999220073223], "steps": [32, 85, 8, 100, 40], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0229999260045588, -1.0849999217316508, -1.1650000354275107, -1.1030000397004187, -1.0769999222829938], "steps": [11, 42, 82, 51, 38], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.0370000442489982], "steps": [18], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.024999925866723], "steps": [12], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0189999262802303], "steps": [9], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-2.0259999982081354], "steps": [13], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [-1.0429999246262014], "steps": [21], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.037999997381121], "steps": [19], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.0409998311661184], "steps": [21], "results": [0]}, "RedWall_1.yaml": {"rewards": [-2.069999995175749], "steps": [35], "results": [0]}, "RedWall_2.yaml": {"rewards": [-1.054999923799187], "steps": [27], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.0589999235235155], "steps": [29], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.0550000430084765], "steps": [27], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.0669999229721725], "steps": [33], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0609999233856797], "steps": [30], "results": [0]}, "RedWall_7.yaml": {"rewards": [-1.0569999236613512], "steps": [28], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-1.1810000343248248, -1.0490000434219837, -1.0989999207668006, -2.0559999961405993, -1.0889999214559793], "steps": [90, 24, 49, 28, 44], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.678000039421022], "steps": [159], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.5820000460371375], "steps": [207], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8300000289455056], "steps": [83], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.376000000629574], "steps": [310], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.446000055409968], "steps": [275], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8219999698922038], "steps": [87], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.7959999716840684], "steps": [100], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.967000211123377], "steps": [14], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [2.709000109694898], "steps": [143], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.6500000753439963], "steps": [173], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [0.921000043861568], "steps": [38], "results": [0]}, "Green_sizes12_3.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [0.9530000416561961], "steps": [22], "results": [0]}, "Green_sizes12_5.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [2.97100012563169], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [0.9690000405535102], "steps": [14], "results": [0]}, "Green_sizes12_9.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9209999842569232, 0.921000043861568, 0.4050000198185444, 0.872999987564981, -1.0019999309442937, -1.0019999309442937, 0.8549999888055027, 0.9569999817758799, 0.7689999947324395, 0.996999979019165], "steps": [38, 38, 296, 62, 500, 500, 71, 20, 114, 0], "results": [1, 1, 1, 1, 0, 0, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.1510000373236835, -1.0019999309442937, -1.0019999309442937, 0.9509999821893871, 0.9449999826028943, -1.0019999309442937, 0.6610000617802143, 0.4090000195428729, 0.8730000471696258, 0.8829999868758023], "steps": [423, 500, 500, 23, 26, 500, 168, 294, 62, 57], "results": [1, 0, 0, 1, 1, 0, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.867000047583133], "steps": [65], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8390000495128334], "steps": [79], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7909999932162464], "steps": [103], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.4130000192672014], "steps": [292], "results": [1]}, "Ring_1.yaml": {"rewards": [0.8330000499263406], "steps": [82], "results": [1]}, "Ring_2.yaml": {"rewards": [0.7409999966621399], "steps": [128], "results": [1]}, "Ring_3.yaml": {"rewards": [0.7630000547505915], "steps": [117], "results": [1]}, "Ring_4.yaml": {"rewards": [-1.3979999469593167], "steps": [198], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.1619999632239342], "steps": [80], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.1000000215135515], "steps": [74], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.3679998994339257], "steps": [275], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.5909999350551516], "steps": [305], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.6469999344553798], "steps": [263], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.7990000522695482, -1.0019999309442937, 0.8529999889433384, 0.8209999911487103, 0.867000047583133], "steps": [99, 500, 72, 88, 65], "results": [1, 0, 1, 1, 1]}, "ChessBoard_2.yaml": {"rewards": [-1.0359999719075859, 0.7350000566802919, -1.175999962259084, 0.7749999943189323, 0.7570000551640987], "steps": [17, 131, 87, 111, 120], "results": [0, 1, 0, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [0.45633340254426, 0.9069999852217734, 0.9049999853596091, 0.3756666607223451, 0.805666655767709], "steps": [227, 45, 46, 114, 79], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.6949999998323619, 0.8909999863244593, 0.6016667173244059, 0.48966673854738474, 0.6070000058971345], "steps": [151, 53, 91, 247, 195], "results": [1, 1, 1, 1, 1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -1.0019999309442937, 1.4439999959431589, -0.0029999520629644394, -1.0019999309442937, 1.707999977748841, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -0.002999892458319664], "steps": [499, 500, 276, 500, 500, 144, 500, 500, 500, 500], "results": [0.5, 0, 1, 0.5, 0, 1, 0, 0, 0, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 1.6740000313147902, -1.003999930806458, 1.6060000360012054, -0.004999985918402672, -0.004999926313757896, -1.003999930806458, -0.004999985918402672, -1.003999930806458], "steps": [249, 250, 80, 250, 97, 250, 250, 250, 250, 250], "results": [0, 0, 1, 0, 1, 0.5, 0.5, 0, 0.5, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.635000029578805, -1.003999930806458, -1.003999930806458, 0.4629999818280339, 0.7669999608770013, 0.5990000320598483, 0.643000029027462, -1.003999930806458, 0.29900005273520947, -1.003999930806458], "steps": [90, 250, 250, 133, 57, 99, 88, 250, 174, 250], "results": [1, 0, 0, 1, 1, 1, 1, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.7469999622553587, 0.8110000174492598, 0.9390000086277723, 0.9150000102818012, -1.003999930806458, 0.5790000334382057, 0.17900006100535393, 0.9949999451637268, -1.003999930806458, -1.003999930806458], "steps": [62, 46, 14, 20, 250, 104, 204, 0, 250, 250], "results": [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]}, "InternalMemory_3.yaml": {"rewards": [0.4856666140258312, 0.1323333317413926, 0.5056666741147637, 0.6856666188687086, -1.0066666910424829, 1.6779999053105712, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829], "steps": [76, 129, 73, 46, 150, 47, 150, 150, 150, 150], "results": [1, 1, 1, 1, 0, 1, 0, 0, 0, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, -1.0099999774247408, 0.2790000382810831, 0.8490000255405903, -1.0099999774247408, -1.0099999774247408, 0.7390000279992819, -1.0099999774247408, -1.0099999774247408], "steps": [99, 100, 100, 71, 14, 100, 100, 25, 100, 100], "results": [0, 0, 0, 1, 1, 0, 0, 1, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [0.8910000119358301], "steps": [26], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-1.8309999639168382], "steps": [207], "results": [0]}}}, "level_01_food": 0.3523809523809524, "level_02_preferences": 0.6363636363636364, "level_03_obstacles": 0.75, "level_04_avoidance": 0.62, "level_05_spatial_reasoning": 0.35, "level_06_generalization": 0.35, "level_07_internal_memory": 0.5249999999999999, "level_09_advanced_preferences": 0.2, "mean_score": 0.4729680735930736}