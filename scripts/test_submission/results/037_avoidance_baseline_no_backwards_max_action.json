{"elapsed_time": 371.69687056541443, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.24750001542270184, -1.003999930806458, -1.003999930806458, 0.4195000035688281, 0.035500030033290386], "steps": [62, 250, 250, 19, 115], "results": [1, 0, 0, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.7910000188276172, 0.6830000262707472, 0.8510000146925449, 0.9030000111088157, 0.6270000301301479], "steps": [51, 78, 36, 23, 92], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.737999975681305, 1.85800008662045, 1.626000102609396, 1.5859999861568213, -1.003999930806458], "steps": [64, 34, 92, 102, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoal_size3.yaml": {"rewards": [2.445000068284571, -1.003999930806458, 2.5090003022924066, -1.003999930806458, 2.8970000371336937], "steps": [137, 250, 121, 250, 24], "results": [1, 0, 1, 0, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.6840001242235303, 3.876000110991299, 3.704000122845173, 3.8080001156777143, 3.5320001346990466], "steps": [77, 29, 72, 46, 115], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.459000212140381, 4.647000199183822, 4.855000184848905, 4.763000191189349, 4.147000233642757], "steps": [133, 86, 34, 57, 211], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.09500000718981028, 0.8110000174492598, 0.027000071480870247, -1.003999930806458, -1.003999930806458], "steps": [225, 46, 242, 250, 250], "results": [1, 1, 1, 0, 0]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7659999737516046, 1.5500001078471541, 1.7419999754056334, 1.8419999685138464, 1.8379999687895179], "steps": [57, 111, 63, 38, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.605000057257712, 2.805000043474138, 2.189000085927546, 2.897000275552273, 2.8930002758279443], "steps": [97, 47, 201, 24, 25], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.2160001564770937, 3.936000106856227, 3.7240001214668155, 3.180000397376716, 3.0920001650229096], "steps": [194, 14, 67, 203, 225], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.811000187881291, 4.2750002248212695, 4.659000198356807, 4.6150002013891935, 4.639000199735165], "steps": [45, 179, 83, 94, 88], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.3124999161809683, -1.003999930806458, -1.003999930806458, 0.07150002755224705, -1.003999930806458], "steps": [202, 250, 250, 106, 250], "results": [1, 0, 0, 1, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.41100004501640797, -1.003999930806458, 0.6189999710768461, -1.003999930806458], "steps": [249, 146, 250, 94, 250], "results": [0, 1, 0, 1, 0]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.235000227577984, 4.455000212416053, 4.811000187881291, 4.595000202767551], "steps": [249, 189, 134, 45, 99], "results": [0, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, 0.11950005404651165, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 94, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.9070000108331442, 0.5830000331625342, -1.003999930806458, 0.751000021584332], "steps": [249, 22, 103, 250, 61], "results": [0, 1, 1, 0, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.866999707184732, 4.603000202216208, 4.954999701119959, 4.983000176027417, 4.851000185124576], "steps": [31, 97, 9, 2, 35], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.1030000397004187, -1.03299992531538, -1.0309999254532158, -1.0389999249018729, -1.0390000441111624], "steps": [51, 16, 15, 19, 19], "results": [0, 0, 0, 0, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0569999236613512, -1.0770000414922833, -1.0509999240748584, -1.0449999244883657, -1.0489999242126942], "steps": [28, 38, 25, 22, 24], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.0930000403895974, -1.0470000435598195, -1.0849999217316508, -1.035000044386834, -1.1449999175965786], "steps": [46, 23, 42, 17, 72], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.0509999240748584, -2.1139999921433628, -1.0489999242126942, -1.03299992531538, -1.1829999149776995], "steps": [25, 57, 24, 16, 91], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.1030000397004187, -1.1729999156668782, -0.10599994147196412, -1.0909999213181436, -1.051000043284148], "steps": [51, 86, 52, 45, 25], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [-1.0689999228343368, 0.8869999866001308, -1.1450000368058681, -1.059000042732805, -1.1209999192506075], "steps": [34, 55, 72, 29, 60], "results": [0, 1, 0, 0, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [-1.0570000428706408, -1.1810000343248248, -1.1269999188371003, -1.0389999249018729, -1.1349999182857573], "steps": [28, 90, 63, 19, 67], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0470000435598195, -1.1029999204911292, -1.0969999209046364, -1.0829999218694866, -1.0550000430084765], "steps": [23, 51, 48, 41, 27], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [-1.121000038459897, -1.1209999192506075, -1.1890000337734818, -1.070999922696501, -1.0909999213181436], "steps": [60, 60, 94, 35, 45], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-2.0639999955892563, -1.170999915804714, -1.016999926418066, -1.2009999137371778, -1.0809999220073223], "steps": [32, 85, 8, 100, 40], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0229999260045588, -1.0849999217316508, -1.1650000354275107, -1.1030000397004187, -1.0769999222829938], "steps": [11, 42, 82, 51, 38], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-1.0449999244883657], "steps": [22], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-1.0390000441111624], "steps": [19], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.0370000442489982], "steps": [18], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-1.0389999249018729], "steps": [19], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.0369999250397086], "steps": [18], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.024999925866723], "steps": [12], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.0189999262802303], "steps": [9], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-2.0259999982081354], "steps": [13], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [-1.0429999246262014], "steps": [21], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.037999997381121], "steps": [19], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.0409998311661184], "steps": [21], "results": [0]}, "RedWall_1.yaml": {"rewards": [-2.069999995175749], "steps": [35], "results": [0]}, "RedWall_2.yaml": {"rewards": [-1.054999923799187], "steps": [27], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.0589999235235155], "steps": [29], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.0550000430084765], "steps": [27], "results": [0]}, "RedWall_5.yaml": {"rewards": [-1.0669999229721725], "steps": [33], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.0609999233856797], "steps": [30], "results": [0]}, "RedWall_7.yaml": {"rewards": [-1.0569999236613512], "steps": [28], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-1.1810000343248248, -1.0490000434219837, -1.0989999207668006, -2.0559999961405993, -1.0889999214559793], "steps": [90, 24, 49, 28, 44], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.678000039421022], "steps": [159], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.5820000460371375], "steps": [207], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8300000289455056], "steps": [83], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.376000000629574], "steps": [310], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.446000055409968], "steps": [275], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8219999698922038], "steps": [87], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.7959999716840684], "steps": [100], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.967000211123377], "steps": [14], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [2.709000109694898], "steps": [143], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.5570000689476728, -1.0019999309442937, -1.0019999309442937, 0.02500010561197996, 0.926999983843416, 0.5890000071376562, 0.7870000530965626, -1.0019999309442937, 0.9610000411048532, 0.7070000586099923], "steps": [220, 500, 500, 486, 35, 204, 105, 500, 18, 145], "results": [1, 0, 0, 1, 1, 1, 1, 0, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.718999998178333, -1.0019999309442937, 0.8409999897703528, 0.9509999821893871, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 0.7410000562667847, 0.8829999868758023, 0.2870000279508531], "steps": [139, 500, 78, 23, 500, 500, 500, 128, 57, 355], "results": [1, 0, 1, 1, 0, 0, 0, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8710000473074615], "steps": [63], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8369999900460243], "steps": [80], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7949999929405749], "steps": [101], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.5030000726692379], "steps": [247], "results": [1]}, "Ring_1.yaml": {"rewards": [0.7409999966621399], "steps": [128], "results": [1]}, "Ring_2.yaml": {"rewards": [0.8390000495128334], "steps": [79], "results": [1]}, "Ring_3.yaml": {"rewards": [0.7169999983161688], "steps": [140], "results": [1]}, "Ring_4.yaml": {"rewards": [-1.195999841671437], "steps": [97], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.1539999637752771], "steps": [76], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.125999846495688], "steps": [62], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.1680000207852572], "steps": [125], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.3213333524763584], "steps": [240], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.60566666116938], "steps": [294], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.6536666606552899], "steps": [258], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.7789999940432608, 0.8449999894946814, 0.8489999892190099, 0.27300008852034807, 0.8589999885298312], "steps": [109, 76, 74, 362, 69], "results": [1, 1, 1, 1, 1]}, "ChessBoard_2.yaml": {"rewards": [-1.029999972321093, 0.28100002836436033, 0.017000106163322926, 0.3450000239536166, 0.7989999926649034], "steps": [14, 358, 490, 326, 99], "results": [0, 1, 1, 1, 1]}, "ChessBoard_3.yaml": {"rewards": [0.8249999908730388, 0.7909999918192625, 0.8789999871514738, 0.7789999940432608, 0.7796666598878801], "steps": [86, 93, 59, 109, 102], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.676999993622303, 0.6223333938978612, 0.6830000602640212, 0.25900001777336, 0.65900006191805], "steps": [120, 164, 157, 299, 169], "results": [1, 1, 1, 1, 1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.000999892596155405, 1.6000000447966158, -0.0029999520629644394, -1.0019999309442937, 1.7500000344589353, 1.586000045761466, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 1.4459999958053231], "steps": [499, 198, 500, 500, 123, 205, 500, 500, 500, 275], "results": [0.5, 1, 0.5, 0, 1, 1, 0, 0, 0, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, -0.004999926313757896, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, 1.8740000175312161, -0.004999985918402672, 1.5980000365525484], "steps": [249, 250, 250, 250, 250, 250, 250, 30, 250, 99], "results": [0.5, 0.5, 0, 0, 0, 0, 0, 1, 0.5, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.45100004225969315, -1.003999930806458, -1.003999930806458, 0.4309999840334058, 0.45100004225969315, 0.10700000636279583, 0.8990000113844872, 0.5870000328868628], "steps": [249, 250, 136, 250, 250, 141, 136, 222, 24, 102], "results": [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.9110000105574727, 0.4910000395029783, 0.926999949850142, -1.003999930806458, -1.003999930806458, 0.9469999484717846, -1.003999930806458, 0.2190000582486391, 0.8789999531581998, 0.24299999698996544], "steps": [21, 126, 17, 250, 250, 12, 250, 194, 29, 188], "results": [1, 1, 1, 0, 0, 1, 0, 1, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.8390000155195594, 0.18566660676151514, 0.15233333222568035, 0.21233333367854357, -1.0066666910424829, -1.0066666910424829, 0.3589999442920089, -1.0066666910424829, 0.09899993799626827, -1.0066666910424829], "steps": [23, 121, 126, 117, 150, 150, 95, 150, 134, 150], "results": [1, 1, 1, 1, 0, 0, 1, 0, 1, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, 0.6090000309050083, 0.42900003492832184, 0.5090000331401825, -1.0099999774247408, -1.0099999774247408, 0.4390000347048044, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408], "steps": [99, 38, 56, 48, 100, 100, 55, 100, 100, 100], "results": [0, 1, 1, 1, 0, 0, 1, 0, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [0.8830000124871731], "steps": [28], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.3523809523809524, "level_03_obstacles": 0.6499999999999999, "level_04_avoidance": 0.64, "level_05_spatial_reasoning": 0.5, "level_06_generalization": 0.35, "level_07_internal_memory": 0.575, "level_09_advanced_preferences": 0.2, "mean_score": 0.46676870748299326}