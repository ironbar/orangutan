{"elapsed_time": 327.7563760280609, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.2835000427439809, 0.38750000577419996, 0.20350004825741053, 0.4195000333711505, -0.12449992913752794], "steps": [53, 27, 73, 19, 155], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.867000013589859, 0.7630000207573175, 0.8509999550879002, 0.8989999517798424, 0.7229999639093876], "steps": [32, 58, 36, 24, 68], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.6859999792650342, 1.853999967686832, 1.7979999715462327, 1.874000085517764, 1.8219999698922038], "steps": [77, 35, 49, 30, 43], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.6730000525712967, 2.7770002838224173, 2.761000046506524, 2.861000039614737, 2.9050000365823507], "steps": [80, 54, 58, 33, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.660000125877559, 3.868000111542642, 3.7400003587827086, 3.536000134423375, 3.2680001528933644], "steps": [83, 31, 63, 114, 181], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.766999714076519, 4.623000200837851, 4.843000185675919, 4.675000197254121, 4.755000191740692], "steps": [56, 92, 37, 79, 59], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.25150004494935274, -0.3404999142512679, 0.4475000314414501, 0.33950000908225775, 0.18350001983344555], "steps": [61, 209, 12, 39, 78], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9310000091791153, 0.7629999611526728, 0.7070000246167183, 0.7790000196546316, 0.6470000287517905], "steps": [16, 58, 72, 54, 87], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.8060000902041793, 1.9060000833123922, 1.637999982573092, 1.845999968238175, 1.842000087723136], "steps": [47, 22, 89, 37, 38], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.8730000387877226, 2.6930000511929393, 2.901000036858022, 2.9130000360310078, 2.8810000382363796], "steps": [30, 75, 23, 20, 28], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.8560001123696566, 3.936000106856227, 3.4840003764256835, 3.6240003667771816, 3.904000347480178], "steps": [34, 14, 127, 92, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [-0.9999999310821295, 4.907000181265175, 4.1670002322643995, 4.3830002173781395, 4.795000188983977], "steps": [249, 21, 206, 152, 49], "results": [0, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.2835000427439809, 0.27550004329532385, 0.1955000190064311, 0.09550005570054054, 0.33950000908225775], "steps": [53, 55, 75, 100, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.4350000433623791, 0.6670000273734331, 0.7350000226870179, 0.6549999685958028, 0.8229999570176005], "steps": [140, 82, 65, 85, 43], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.914999703876674, 4.791000189259648, 4.791000189259648, 4.32700022123754, 4.907000181265175], "steps": [19, 50, 50, 166, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.20750001817941666, -0.4244999084621668, 0.17950002010911703, 0.18750004936009645, 0.2835000129416585], "steps": [72, 230, 79, 77, 53], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7309999633580446, 0.3189999917522073, 0.8230000166222453, 0.859000014141202, 0.18300000112503767], "steps": [66, 169, 43, 34, 203], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.1590002328157425, 4.71099971793592, 4.951000178232789, 4.983000176027417, 4.8709997069090605], "steps": [208, 70, 10, 2, 30], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8489999892190099, 0.8829999868758023, 0.6890000002458692, 0.9130000444129109, 0.7749999943189323], "steps": [74, 57, 154, 42, 111], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9030000451020896, 0.705000058747828, 0.8390000495128334, 0.7929999930784106, 0.8170000510290265], "steps": [47, 146, 79, 102, 90], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.3209999054670334, 0.8789999871514738, 0.5450000697746873, 0.8430000492371619, 0.7950000525452197], "steps": [160, 59, 226, 77, 101], "results": [0, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.8509999890811741, 0.8429999896325171, -1.0769999222829938, 0.7409999966621399, 0.7469999962486327], "steps": [73, 77, 38, 128, 125], "results": [1, 1, 0, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.7720000501722097, 3.48800001014024, 1.9950001249089837, -0.38400004152208567, 1.7179999090731144], "steps": [111, 253, 500, 191, 139], "results": [1, 1, 0.5, 0, 0.5]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9270000434480608, 0.9129999848082662, 0.9070000448264182, 0.8910000459291041, 0.3690000222995877], "steps": [35, 42, 45, 53, 314], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [1.8760000597685575, 0.9030000451020896, 0.8990000453777611, 0.5690000085160136, -1.0569999236613512], "steps": [60, 47, 49, 214, 28], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.9010000452399254, 0.9089999850839376, 0.7049999991431832, 0.6150000053457916, -1.3429999039508402], "steps": [48, 44, 146, 191, 171], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8909999863244593, 0.9070000448264182, 0.9190000439994037, 0.9149999846704304, 0.9230000437237322], "steps": [53, 45, 39, 41, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.6690000016242266, 0.9129999848082662, 0.8369999900460243, -1.1309999185614288, -1.0389999249018729], "steps": [164, 42, 80, 65, 19], "results": [1, 1, 1, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.024999925866723, 0.4870000737719238, -1.0769999222829938, 0.9069999852217734, -1.086999921593815], "steps": [12, 255, 38, 45, 43], "results": [0, 1, 0, 1, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.4160002106800675], "steps": [290], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.9309999835677445], "steps": [33], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.9109999849461019], "steps": [43], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0309999254532158], "steps": [15], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.8429999896325171], "steps": [77], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.6890000002458692], "steps": [154], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.6949999998323619], "steps": [151], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.5710000083781779], "steps": [213], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9130000444129109], "steps": [42], "results": [1]}, "RedWall_2.yaml": {"rewards": [-1.9789998601190746], "steps": [489], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [0.9010000452399254], "steps": [48], "results": [1]}, "RedWall_5.yaml": {"rewards": [0.8890000460669398], "steps": [54], "results": [1]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [1.7959999716840684], "steps": [100], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.3020000057294965], "steps": [347], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8300000289455056], "steps": [83], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.8220000294968486], "steps": [87], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7760000326670706], "steps": [110], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.7559999744407833], "steps": [120], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.807999970857054], "steps": [94], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.7830002238042653], "steps": [106], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8160000299103558], "steps": [90], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.821000042371452], "steps": [87], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.7490000557154417, 0.934999983292073, -1.0019999309442937, 0.8589999885298312, 0.5430000103078783, 0.8909999863244593, 0.8309999904595315, -1.0019999309442937, 0.47900001471862197, 0.3750000218860805], "steps": [124, 31, 500, 69, 227, 53, 83, 500, 259, 311], "results": [1, 1, 0, 1, 1, 1, 1, 0, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.6910000001080334, 0.9309999835677445, 0.9329999834299088, 0.7370000565424562, 0.6110000652261078, 0.9189999843947589, -1.0019999309442937, 0.9729999806731939, 0.8010000521317124, 0.8969999859109521], "steps": [153, 33, 32, 130, 193, 39, 500, 12, 98, 50], "results": [1, 1, 1, 1, 1, 1, 0, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.6310000042431056], "steps": [183], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.7229999979026616], "steps": [137], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7329999972134829], "steps": [132], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-1.0419999714940786], "steps": [20], "results": [0]}, "Ring_1.yaml": {"rewards": [0.6230000047944486], "steps": [187], "results": [1]}, "Ring_2.yaml": {"rewards": [-1.1899999612942338], "steps": [94], "results": [0]}, "Ring_3.yaml": {"rewards": [0.5350000108592212], "steps": [231], "results": [1]}, "Ring_4.yaml": {"rewards": [0.5810000076889992], "steps": [208], "results": [1]}, "RingBlocked_1.yaml": {"rewards": [-1.0199999730102718], "steps": [9], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.449999824166298], "steps": [224], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [0.4803332695737481], "steps": [388], "results": [1]}, "RingBlocked_4.yaml": {"rewards": [-1.13866668776609], "steps": [103], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [0.7363333264365792], "steps": [196], "results": [1]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [0.8056665994226933], "steps": [144], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.7900000317022204, 1.8680000263266265, -0.0029999520629644394, -1.0019999309442937, -0.002999892458319664, 1.0060000261291862, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937, 1.284000066574663], "steps": [103, 64, 500, 500, 500, 495, 500, 500, 500, 356], "results": [1, 1, 0.5, 0, 0.5, 1, 0, 0.5, 0, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [1.3019999377429485, -0.004999926313757896, 1.4659999860450625, -0.004999985918402672, 1.7059999099001288, 1.0260000759735703, -0.004999926313757896, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [173, 250, 132, 250, 72, 242, 250, 250, 250, 250], "results": [1, 0.5, 1, 0.5, 1, 1, 0.5, 0, 0, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, 0.4390000430867076, 0.5989999724552035, 0.6030000317841768, -1.003999930806458, 0.31099999230355024, 0.11500000581145287, 0.7429999625310302, 0.4430000428110361, 0.3990000458434224], "steps": [249, 139, 99, 98, 250, 171, 220, 63, 138, 149], "results": [0, 1, 1, 1, 0, 1, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, 0.9310000091791153, 0.586999973282218, 0.25500005576759577, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.5590000348165631, 0.8629999542608857], "steps": [249, 16, 102, 185, 250, 250, 250, 250, 109, 33], "results": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.5723333423957229, 0.7456666799262166, 0.35900000389665365, 0.8056666813790798, 0.4990000072866678, 0.5390000082552433, 0.5323333414271474, 0.7323333462700248, 0.25900000147521496, 0.9323333511129022], "steps": [63, 37, 95, 28, 74, 68, 69, 39, 110, 9], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, 0.7390000279992819, -1.0099999774247408, 0.5390000324696302, 0.48900003358721733, 0.7790000271052122, 0.6690000295639038, 0.449000034481287, 0.37900003604590893, -1.0099999774247408], "steps": [99, 25, 100, 45, 50, 21, 32, 54, 61, 100], "results": [0, 1, 0, 1, 1, 1, 1, 1, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8790000127628446], "steps": [29], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.8870000122115016], "steps": [27], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.8789999531581998], "steps": [29], "results": [0]}}}, "level_01_food": 0.7516129032258064, "level_03_obstacles": 0.8500000000000001, "level_04_avoidance": 0.5625, "level_05_spatial_reasoning": 0.55, "level_06_generalization": 0.55, "level_07_internal_memory": 0.75, "level_09_advanced_preferences": 0.4, "mean_score": 0.6305875576036867}