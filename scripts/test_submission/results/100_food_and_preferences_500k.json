{"elapsed_time": 227.12605166435242, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.3035000413656235, 0.3795000361278653, 0.27950001321733, 0.4035000344738364, 0.3315000394359231], "steps": [48, 29, 54, 23, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.7350000226870179, 0.810999957844615, 0.8229999570176005, 0.8950000116601586, 0.7230000235140324], "steps": [65, 46, 43, 25, 68], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.8060000902041793, 1.853999967686832, 1.9140000827610493, 1.869999966584146, 1.88599996548146], "steps": [47, 35, 20, 31, 27], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.829000041820109, 2.829000041820109, 2.9090000363066792, 2.85300004016608, 2.9050000365823507], "steps": [41, 41, 21, 35, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.776000117883086, 3.8720001112669706, 3.7480001198127866, 3.8200001148507, 3.7680003568530083], "steps": [54, 30, 61, 43, 56], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.799000188708305, 4.755000191740692, 4.843000185675919, 4.771000190638006, 4.983000176027417], "steps": [48, 59, 37, 55, 2], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.3075000112876296, 0.2195000471547246, 0.4395000319927931, 0.31550004053860903, 0.21550004743039608], "steps": [47, 69, 14, 45, 70], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9150000102818012, 0.6269999705255032, 0.7150000240653753, 0.6070000315085053, 0.8110000174492598], "steps": [20, 92, 70, 97, 46], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7859999723732471, 1.9180000824853778, 1.7419999754056334, 1.8380000879988074, 1.845999968238175], "steps": [52, 19, 63, 39, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.8890000376850367, 2.829000041820109, 2.901000036858022, 2.913000274449587, 2.8970000371336937], "steps": [26, 41, 23, 20, 24], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.8560001123696566, 3.9320001071318984, 3.5760003700852394, 3.720000121742487, 3.860000350512564], "steps": [34, 15, 104, 68, 33], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 4.834999709390104, -1.003999930806458, 4.807000188156962], "steps": [249, 250, 39, 250, 46], "results": [0, 0, 1, 0, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.13550005294382572, 0.13950005266815424, 0.1515000518411398, 0.18750001955777407, 0.25150004494935274], "steps": [90, 89, 86, 77, 61], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.5989999724552035, 0.36700004804879427, 0.7790000196546316, 0.6950000254437327, 0.7749999603256583], "steps": [99, 157, 54, 75, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.559000205248594, -1.003999930806458, -1.003999930806458, 4.922999703325331], "steps": [249, 108, 250, 250, 17], "results": [0, 1, 0, 0, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.020499936304986477, 0.24350001569837332, 0.1955000488087535, 0.23550001624971628, 0.307500041089952], "steps": [129, 63, 75, 65, 47], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7630000207573175, 0.7069999650120735, 0.6270000301301479, 0.7389999628067017, 0.7469999622553587], "steps": [58, 72, 92, 64, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.859000184573233, -1.003999930806458, -1.003999930806458, 4.983000176027417, 4.879000183194876], "steps": [33, 250, 250, 2, 28], "results": [1, 0, 0, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.718999998178333, 0.8669999879784882, 0.7650000546127558, 0.9089999850839376, 0.867000047583133], "steps": [139, 65, 116, 44, 65], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9050000449642539, 0.7009999994188547, 0.6230000047944486, 0.6929999999701977, -1.1669999160803854], "steps": [46, 148, 187, 152, 83], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.5390000105835497, 0.8329999903216958, 0.20100003387778997, 0.7549999956972897, -1.0019999309442937], "steps": [229, 82, 398, 121, 500], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.5970000056549907, 0.8209999911487103, 0.8669999879784882, 0.18700003484264016, -1.0019999309442937], "steps": [298, 88, 65, 405, 500], "results": [0, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.7540000514127314, 3.0980000370182097, 3.28600002406165, 1.483999925199896, 0.6829999326728284], "steps": [120, 448, 354, 256, 157], "results": [1, 1, 1, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9250000435858965, 0.9069999852217734, 0.9150000442750752, 0.9049999853596091, 0.9129999848082662], "steps": [36, 45, 41, 46, 42], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.867000047583133, 0.7030000588856637, 0.8850000463426113, 0.8589999885298312, -1.1070000394247472], "steps": [65, 147, 56, 69, 53], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.7490000557154417, 0.9009999856352806, 0.9109999849461019, -1.1110000391490757, -1.1029999204911292], "steps": [124, 48, 43, 55, 51], "results": [1, 1, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8970000455155969, 0.9050000449642539, 0.9190000439994037, 0.9149999846704304, 0.9169999845325947], "steps": [50, 46, 39, 41, 40], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.7929999930784106, 0.9129999848082662, 0.7589999954216182, -1.0489999242126942, 0.8929999861866236], "steps": [102, 42, 119, 24, 52], "results": [1, 1, 1, 0, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7210000576451421, 0.7529999958351254, 0.8890000460669398, 0.9130000444129109, 0.8769999872893095], "steps": [138, 122, 54, 42, 60], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.4880000865086913], "steps": [254], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [1.1120001124218106], "steps": [442], "results": [1]}, "RedHouse_8.yaml": {"rewards": [1.1400001104921103], "steps": [428], "results": [1]}, "DeadComing_1.yaml": {"rewards": [-1.1229999191127717], "steps": [61], "results": [0]}, "DeadComing_2.yaml": {"rewards": [0.818999991286546], "steps": [89], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0349999251775444], "steps": [17], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.8049999922513962], "steps": [96], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.7689999947324395], "steps": [114], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.433000017888844], "steps": [282], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.6190000050701201], "steps": [189], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9069999852217734], "steps": [45], "results": [1]}, "RedWall_2.yaml": {"rewards": [-1.5509998896159232], "steps": [275], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8229999910108745, -1.2829999080859125, 0.7270000572316349, 0.5450000101700425, -1.0019999309442937], "steps": [87, 141, 135, 226, 500], "results": [1, 0, 1, 1, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.761999974027276], "steps": [117], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.856000027153641], "steps": [70], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.9220000226050615], "steps": [37], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.902000023983419], "steps": [47], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.89999996451661], "steps": [48], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.8740000259131193], "steps": [61], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9629999813623726], "steps": [17], "results": [0]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.9520000545307994], "steps": [22], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9770000400021672], "steps": [10], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9730000402778387], "steps": [12], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9769999803975224], "steps": [10], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}}}, "level_01_food": 0.6523809523809524, "level_02_preferences": 0.6666666666666666, "mean_score": 0.6595238095238095}