{"elapsed_time": 991.8667130470276, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [-0.9999999310821295, 0.015500061213970184, 0.17950004991143942, 0.39150003530085087, -1.003999930806458], "steps": [249, 120, 79, 26, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoal_size1.yaml": {"rewards": [0.4109999854117632, 0.25100005604326725, 0.8150000171735883, 0.1430000038817525, 0.15100000333040953], "steps": [146, 186, 45, 213, 211], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.3859999999403954, 1.850000087171793, 1.098000019788742, 1.8739999663084745, -1.003999930806458], "steps": [152, 36, 224, 30, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoal_size3.yaml": {"rewards": [-0.9999999310821295, 2.629000055603683, 2.2930003171786666, -1.003999930806458, 2.9050000365823507], "steps": [249, 91, 175, 250, 22], "results": [0, 1, 1, 0, 1]}, "GoodGoal_size4.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 3.6760001247748733, -1.003999930806458, 3.328000148758292], "steps": [249, 250, 79, 250, 166], "results": [0, 0, 1, 0, 1]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.41150000412017107, -0.10049993079155684, 0.2155000176280737], "steps": [249, 250, 21, 149, 70], "results": [0, 0, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.7990000182762742, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 49, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7860000915825367, 1.9140000827610493, 1.6659999806433916, 1.8299999693408608, -1.003999930806458], "steps": [52, 20, 82, 41, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.869000039063394, -1.003999930806458, -1.003999930806458, 2.869000277481973, 2.8890000376850367], "steps": [31, 250, 250, 31, 26], "results": [1, 0, 0, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.356000385247171, 3.7880001170560718, -1.003999930806458, 3.6320001278072596, -1.003999930806458], "steps": [159, 51, 250, 90, 250], "results": [1, 1, 0, 1, 0]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.747000192292035, -1.003999930806458, -1.003999930806458, -1.003999930806458, 4.451000212691724], "steps": [61, 250, 250, 250, 135], "results": [1, 0, 0, 0, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.06449993327260017, 0.05950005818158388, -1.003999930806458, -0.12049995921552181, 0.11150005459785461], "steps": [140, 109, 250, 154, 96], "results": [1, 1, 0, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.859000014141202, 0.1270000645890832, -1.003999930806458, 0.8110000174492598], "steps": [249, 34, 217, 250, 46], "results": [0, 1, 1, 0, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, 4.4910002099350095], "steps": [249, 250, 250, 250, 125], "results": [0, 0, 0, 0, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.3315000394359231, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [41, 250, 250, 250, 250], "results": [1, 0, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.011000072583556175, -1.003999930806458, 0.7350000226870179, -1.003999930806458, 0.7830000193789601], "steps": [246, 250, 65, 250, 53], "results": [1, 0, 1, 0, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.819000187329948, -1.003999930806458, 4.783000189810991, 4.983000176027417, 4.8390001859515905], "steps": [43, 250, 52, 2, 38], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8089999919757247, 0.8350000497885048, 0.581000067293644, 0.8610000479966402, 0.7809999939054251], "steps": [94, 81, 208, 68, 108], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9089999850839376, -1.472999894991517, -1.1109999199397862, -1.3669999022968113, 0.4770000148564577], "steps": [44, 236, 55, 183, 260], "results": [1, 0, 0, 0, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.6509998827241361, -1.9729999797418714, -1.0019999309442937, 0.1890000943094492, 0.8030000519938767], "steps": [325, 486, 500, 404, 97], "results": [0, 0, 0, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-0.9999999310821295, 0.1070000403560698, -1.494999893475324, -1.0019999309442937, -1.515000011306256], "steps": [499, 445, 247, 500, 257], "results": [0, 1, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.1850000340491533, 1.995000065304339, 1.9950001249089837, 0.38700013188645244, -1.0769999222829938], "steps": [92, 500, 500, 305, 38], "results": [0, 0.5, 0.5, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9010000452399254, -1.2030000328086317, 0.8989999857731164, 0.8710000473074615, 0.8909999863244593], "steps": [48, 101, 49, 63, 53], "results": [1, 0, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [-1.0509999240748584, 0.9049999853596091, -1.0310000446625054, 0.4770000148564577, 0.8450000490993261], "steps": [25, 46, 15, 260, 76], "results": [0, 1, 0, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.9009999856352806, -1.1229999191127717, 0.8450000490993261, -1.1250000381842256, -1.0949999210424721], "steps": [48, 61, 76, 62, 47], "results": [1, 0, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [-1.2049999134615064, 0.9129999848082662, -1.2609999096021056, -1.0019999309442937, 0.4030000795610249], "steps": [102, 42, 130, 500, 297], "results": [0, 1, 0, 0, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-1.0649999231100082, 0.9029999854974449, -1.4009998999536037, -1.3289999049156904, -1.0349999251775444], "steps": [32, 47, 200, 164, 17], "results": [0, 1, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.0349999251775444, -1.9769998602569103, 0.7429999965243042, -1.1389999180100858, -1.5950000057928264], "steps": [17, 488, 127, 69, 297], "results": [0, 0, 1, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8989999857731164], "steps": [49], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.8669999879784882], "steps": [65], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0290000448003411], "steps": [14], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.9149999846704304], "steps": [41], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.9109999849461019], "steps": [43], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [0.1710000359453261], "steps": [413], "results": [1]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-1.8449999885633588, -1.186999914702028, -1.0019999309442937, -2.0659999954514205, -1.5989998863078654], "steps": [422, 93, 500, 33, 299], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [0.8230000506155193], "steps": [87], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9549999819137156], "steps": [21], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [-0.0009999522008001804], "steps": [499], "results": [0]}, "YellowOverGreen_5.yaml": {"rewards": [1.3180001238361], "steps": [339], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9669999810867012], "steps": [15], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.9540001736022532], "steps": [21], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9540000543929636], "steps": [21], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.5110000721178949, 0.9169999845325947, 0.18900003470480442, -1.0019999309442937, 0.9089999850839376, 0.41100007900968194, 1.8160000639036298, 0.9449999826028943, -1.0019999309442937, 0.996999979019165], "steps": [243, 40, 404, 500, 44, 293, 90, 26, 500, 0], "results": [1, 1, 1, 0, 1, 1, 1, 1, 0, 1]}, "objectManipulation.yaml": {"rewards": [-0.9999999310821295, 0.6330000637099147, -1.0019999309442937, 0.9229999841190875, 0.9209999842569232, -1.0019999309442937, 0.5010000728070736, -1.0019999309442937, 0.5250000115483999, 0.6110000652261078], "steps": [499, 182, 500, 37, 38, 500, 248, 500, 236, 193], "results": [0, 1, 0, 1, 1, 0, 1, 0, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [0.6530000623315573], "steps": [172], "results": [1]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9130000444129109], "steps": [42], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.8370000496506691], "steps": [80], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.8370000496506691], "steps": [80], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Navigation_1.yaml": {"rewards": [-0.0009999522008001804, 1.0220001442357898, -0.0029999520629644394, -0.002999892458319664, 1.1640000748448074], "steps": [499, 487, 500, 500, 416], "results": [0.5, 1, 0.5, 0.5, 1]}, "Navigation_2.yaml": {"rewards": [-0.000999892596155405, 1.2720001270063221, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937], "steps": [499, 362, 500, 500, 500], "results": [0.5, 1, 0, 0.5, 0]}, "Navigation_3.yaml": {"rewards": [-0.0009999522008001804, 1.2480000690557063, 1.7000000975094736, -0.0029999520629644394, -0.0029999520629644394], "steps": [499, 374, 148, 500, 500], "results": [0.5, 1, 1, 0.5, 0.5]}, "Navigation_4.yaml": {"rewards": [1.3000000058673322, -1.0019999309442937, -1.0019999309442937, 1.3600000613369048, -1.0019999309442937], "steps": [348, 500, 500, 318, 500], "results": [1, 0, 0, 1, 0]}, "Navigation_5.yaml": {"rewards": [1.268000008072704, -0.002999892458319664, 1.4380000559613109, -0.002999892458319664, 1.014000085182488], "steps": [364, 500, 279, 500, 491], "results": [1, 0.5, 1, 0.5, 1]}, "Navigation_6.yaml": {"rewards": [1.5239999904297292, 1.5499999886378646, -0.0029999520629644394, -1.0019999309442937, 1.6139999842271209], "steps": [236, 223, 500, 500, 191], "results": [1, 1, 0.5, 0, 1]}, "Navigation_7.yaml": {"rewards": [1.6520000412128866, -0.0029999520629644394, 1.098000019788742, 1.848000027704984, 1.8660000264644623], "steps": [172, 500, 449, 74, 65], "results": [1, 0.5, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.2580000087618828, -0.0029999520629644394, 1.5259999902918935, 1.2680000676773489, -1.0019999309442937], "steps": [369, 500, 235, 364, 500], "results": [1, 0.5, 1, 1, 0]}, "Navigation_on_platform_1.yaml": {"rewards": [-0.0009999522008001804, -0.002999892458319664, -0.0029999520629644394, 1.2440000693313777, -0.002999892458319664], "steps": [499, 500, 500, 376, 500], "results": [0.5, 0.5, 0.5, 1, 0.5]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [-1.8849998665973544, -1.3189999056048691, 1.300000065471977, -0.0029999520629644394, -1.0019999309442937], "steps": [442, 159, 348, 500, 500], "results": [0, 0, 1, 0.5, 0]}, "Navigation_on_platform_4.yaml": {"rewards": [-1.6010000053793192, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [300, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8449999894946814], "steps": [76], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.818999991286546], "steps": [89], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.37700002174824476], "steps": [310], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.55099993548356], "steps": [335], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.5559999360702932, -1.2559998375363648, -1.0019999309442937], "steps": [499, 500, 277, 127, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 0.0050000473856925964], "steps": [499, 500, 500, 500, 496], "results": [0, 0, 0, 0, 1]}, "ChessBoard_3.yaml": {"rewards": [0.6936667086556554, 0.35833328356966376, 0.7516667088493705, 0.9289999837055802, 0.37366660265251994], "steps": [35, 36, 36, 34, 35], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.2776666693389416, 0.7189999902620912, 0.6096666501834989, 0.4716666270978749, 0.24766665790230036], "steps": [193, 39, 37, 56, 98], "results": [1, 1, 1, 1, 1]}, "Labyrinth_1.yaml": {"rewards": [0.7238888705614954, 0.7167777591384947, 0.7078888695687056, 0.7167776993010193, 0.7007777590770274], "steps": [32, 34, 34, 34, 36], "results": [1, 1, 1, 1, 1]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.5616666493006051, 0.5376666476950049, 0.5529999798163772, 0.4876666497439146, 0.5156666473485529], "steps": [31, 33, 32, 38, 34], "results": [1, 1, 1, 1, 1]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.772333387285471], "steps": [39], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7496667178347707], "steps": [38], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.7176667172461748], "steps": [36], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.7310000229626894], "steps": [66], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.7669999608770013], "steps": [57], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [-1.1040000608190894], "steps": [25], "results": [0]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8430000417865813], "steps": [37], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.7903333795256913], "steps": [60], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8496667095459998], "steps": [37], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.7743333168327808], "steps": [38], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.6663333172909915], "steps": [42], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.9999999310821295, 1.7520000343210995, -1.0019999309442937, 1.4319999967701733, -0.002999892458319664, -0.0029999520629644394, 1.637999982573092, -0.0029999520629644394, -0.0029999520629644394, -0.002999892458319664], "steps": [499, 122, 500, 282, 500, 500, 179, 500, 500, 500], "results": [0, 1, 0, 1, 0.5, 0.5, 1, 0.5, 0.5, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -0.004999926313757896, -1.003999930806458, -1.003999930806458, 1.5300000412389636, -0.004999926313757896, -0.004999985918402672, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250, 116, 250, 250, 250, 250], "results": [0, 0, 0.5, 0, 0, 1, 0.5, 0.5, 0, 0]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, 0.5910000326111913, 0.9229999501258135, 0.4069999856874347, 0.9309999495744705, 0.5630000345408916, 0.9109999509528279, -1.003999930806458, 0.24699999671429396, -1.003999930806458], "steps": [249, 101, 18, 147, 16, 108, 21, 250, 187, 250], "results": [0, 1, 1, 1, 1, 1, 1, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.5510000353679061, 0.5310000367462635, -1.003999930806458, -1.003999930806458, 0.8470000149682164, 0.867000013589859, -1.003999930806458, 0.5469999760389328, 0.643000029027462, 0.8430000152438879], "steps": [111, 116, 250, 250, 37, 32, 250, 112, 88, 38], "results": [1, 1, 0, 0, 1, 1, 0, 1, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [-1.000000024214387, -1.0066666910424829, -1.0066666910424829, 0.13899993896484375, 0.11899993848055601, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829, -1.0066666910424829], "steps": [149, 150, 150, 128, 131, 150, 150, 150, 150, 150], "results": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, 0.8590000253170729, -1.0099999774247408, 0.2290000393986702, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.47900003381073475, -1.0099999774247408], "steps": [99, 100, 13, 100, 76, 100, 100, 100, 51, 100], "results": [0, 0, 1, 0, 1, 0, 0, 0, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.875000013038516], "steps": [30], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.6190000306814909], "steps": [94], "results": [0]}}}, "level_01_food": 0.45396825396825397, "level_02_preferences": 1.0, "level_03_obstacles": 0.32564102564102565, "level_04_avoidance": 0.5578947368421052, "level_05_spatial_reasoning": 0.55, "level_06_generalization": 0.25, "level_07_internal_memory": 0.475, "level_09_advanced_preferences": 0.2, "mean_score": 0.4765630020564231}