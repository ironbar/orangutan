{"elapsed_time": 610.5144264698029, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.29950001183897257, 0.395500005222857, 0.25150001514703035, 0.42750000301748514, 0.34350000880658627], "steps": [49, 25, 61, 17, 38], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.6349999699741602, 0.8310000160709023, 0.8549999548122287, 0.8990000113844872, 0.7269999636337161], "steps": [90, 41, 35, 24, 67], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.6779999798163772, 1.8499999679625034, 1.7099999776110053, 1.8820000849664211, 1.8780000852420926], "steps": [79, 36, 71, 28, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.813000042922795, 2.8570002783089876, 2.7970000440254807, 2.8090000431984663, 2.9090000363066792], "steps": [45, 34, 49, 46, 21], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.5840001311153173, 3.876000110991299, 3.544000133872032, 3.8080003540962934, 3.8640001118183136], "steps": [102, 29, 112, 46, 32], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.7310001933947206, 4.7310001933947206, 4.866999707184732, 4.78700018953532, 4.846999708563089], "steps": [65, 65, 31, 51, 36], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.3115000110119581, 0.2835000129416585, 0.4475000314414501, 0.34350003860890865, 0.2395000159740448], "steps": [46, 53, 12, 38, 64], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9310000091791153, 0.810999957844615, 0.7270000232383609, 0.6790000265464187, 0.7710000202059746], "steps": [16, 46, 67, 79, 56], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.6580001004040241, 1.9059999641031027, 1.7099999776110053, 1.845999968238175, 1.85800008662045], "steps": [84, 22, 71, 37, 34], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.885000037960708, 2.753000047057867, 2.901000036858022, 2.9170000357553363, 2.8810002766549587], "steps": [27, 60, 23, 19, 28], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.8640001118183136, 3.9320001071318984, 3.264000153169036, 3.7240003598853946, 3.9040001090615988], "steps": [32, 15, 182, 67, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.819000187329948, 4.914999703876674, 4.8310001865029335, 4.5309997303411365, 4.795000188983977], "steps": [43, 19, 40, 115, 49], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.3364999443292618, 0.07550005707889795, -0.008499937132000923, 0.23550004605203867, -0.09649993106722832], "steps": [208, 105, 126, 65, 148], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.867000013589859, 0.8790000127628446, 0.8310000160709023, 0.8350000157952309, 0.8510000146925449], "steps": [32, 29, 41, 40, 36], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.798999711871147, 4.722999717108905, 4.735000193119049, 4.8310001865029335, 4.922999703325331], "steps": [48, 67, 64, 40, 17], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.3715000366792083, 0.36750003695487976, 0.24750004522502422, 0.21550004743039608, -0.08849996142089367], "steps": [31, 32, 62, 70, 146], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.6830000262707472, 0.2749999947845936, 0.40299998596310616, 0.5750000337138772, 0.7909999592229724], "steps": [78, 180, 148, 105, 51], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.875000183470547, 4.639000199735165, 4.950999701395631, 4.983000176027417, 4.879000183194876], "steps": [29, 88, 10, 2, 28], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8589999885298312, 0.2590000298805535, 0.7709999945946038, 0.9150000442750752, 0.764999995008111], "steps": [69, 369, 113, 41, 116], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9110000445507467, 0.864999988116324, 0.6350000635720789, 0.9009999856352806, 0.9089999850839376], "steps": [43, 66, 181, 48, 44], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.76700005447492, 0.880999987013638, 0.541000010445714, -1.0019999309442937, 0.6830000006593764], "steps": [115, 58, 228, 500, 157], "results": [1, 1, 1, 0, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.24100003112107515, 0.8529999889433384, 0.8929999861866236, 0.5810000076889992, 0.7690000543370843], "steps": [378, 72, 52, 208, 114], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.8019999032840133, 3.5000000093132257, 1.5480001592077315, 3.54200006602332, 1.9950001249089837], "steps": [97, 247, 224, 226, 500], "results": [0.5, 1, 0.5, 1, 0.5]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.8930000457912683, 0.9149999846704304, 0.9149999846704304, -1.1149999196641147], "steps": [36, 52, 41, 41, 57], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8370000496506691, 0.8409999897703528, 0.8710000473074615, 0.8129999917000532, -1.062999923247844], "steps": [80, 78, 63, 92, 31], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.9029999854974449, 0.8289999905973673, -1.070999922696501, 0.8349999901838601, 0.821000050753355], "steps": [47, 84, 35, 81, 88], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8029999923892319, 0.8169999914243817, 0.9169999845325947, 0.9229999841190875, 0.9230000437237322], "steps": [97, 90, 40, 37, 37], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.6130000650882721, -1.0569999236613512, 0.3950000205077231, -1.0409999247640371, -1.0729999225586653], "steps": [192, 28, 301, 20, 36], "results": [1, 0, 1, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.1189999193884432, -1.1069999202154577, -1.0449999244883657, -1.1530000362545252, 0.8930000457912683], "steps": [59, 53, 22, 76, 52], "results": [0, 0, 0, 0, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.3480000961571932], "steps": [324], "results": [1]}, "RedHouse_6.yaml": {"rewards": [1.5400002021342516], "steps": [228], "results": [1]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.7889999933540821], "steps": [104], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.764999995008111], "steps": [116], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0309999254532158], "steps": [15], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-2.053999996278435], "steps": [27], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.8609999883919954], "steps": [68], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.6510000028647482], "steps": [173], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.8450000490993261], "steps": [76], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9149999846704304], "steps": [41], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.8930000457912683, -1.0019999309442937, 0.8090000515803695, -1.0019999309442937, 0.7989999926649034], "steps": [52, 500, 94, 500, 99], "results": [1, 0, 1, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.799999971408397], "steps": [98], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8880000249482691], "steps": [54], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8579999674111605], "steps": [69], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.9060000237077475], "steps": [45], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.9039999642409384], "steps": [46], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.4380000559613109], "steps": [279], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.6639999807812274], "steps": [166], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.875000038649887], "steps": [60], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.869999966584146], "steps": [63], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.863000158686191], "steps": [66], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.7520000939257443], "steps": [122], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.7010000590234995, 0.5470000696368515, 0.8030000519938767, 0.8610000479966402, 0.8069999921135604, 0.9130000444129109, 0.46900007501244545, 0.702999999281019, 0.9610000411048532, 0.9369999831542373], "steps": [148, 225, 97, 68, 95, 42, 264, 147, 18, 30], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.8329999903216958, 0.7850000532343984, 0.9109999849461019, 0.7849999936297536, 0.8890000460669398, 0.888999986462295, 0.8389999899081886, 0.6690000016242266, 0.7489999961107969, 0.929000043310225], "steps": [82, 106, 43, 106, 54, 54, 79, 164, 124, 34], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8250000504776835], "steps": [86], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8250000504776835], "steps": [86], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.7009999994188547], "steps": [148], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [0.3189999379683286], "steps": [509], "results": [1]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [0.16699993959628046], "steps": [623], "results": [1]}, "ChessBoard_1.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [-0.04899994982406497, 0.6809999821707606, 0.09899998363107443, -0.9643333815038204, -7.849667119327933], "steps": [133, 38, 89, 194, 420], "results": [0, 1, 1, 0, 0]}, "ChessBoard_4.yaml": {"rewards": [-0.9523334042169154, -2.870999997947365, 0.7396667115390301, -4.388333592098206, -0.34100000839680433], "steps": [128, 434, 72, 326, 139], "results": [0, 0, 1, 0, 0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.6360000423155725, 1.7759999730624259, 1.5199999907054007, 1.9080000235699117, -0.0029999520629644394, 1.7520000343210995, 1.5460000485181808, 1.0680000218562782, 1.670000039972365, 1.486000052653253], "steps": [180, 110, 238, 44, 500, 122, 225, 464, 163, 255], "results": [1, 1, 1, 1, 0.5, 1, 1, 1, 1, 1]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, 1.33799999486655, 1.6300000343471766, 1.0100000174716115, -1.003999930806458, 1.5259999819099903, -0.004999926313757896, 1.8739999579265714, -0.004999985918402672, 1.1180000696331263], "steps": [249, 164, 91, 246, 250, 117, 250, 30, 250, 219], "results": [0.5, 1, 1, 1, 0, 1, 0.5, 1, 0.5, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.875000013038516, 0.31499999202787876, 0.7350000226870179, -1.003999930806458, 0.14700006321072578, -1.003999930806458, 0.702999965287745, 0.7270000232383609, 0.8909999523311853, 0.5630000345408916], "steps": [30, 170, 65, 250, 212, 250, 73, 67, 26, 108], "results": [1, 1, 1, 0, 1, 0, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.9150000102818012, 0.535000036470592, 0.9310000091791153, -1.003999930806458, 0.8549999548122287, 0.9430000083521008, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.8390000155195594], "steps": [20, 115, 16, 250, 35, 13, 250, 250, 250, 39], "results": [1, 1, 1, 0, 1, 1, 0, 0, 0, 1]}, "InternalMemory_3.yaml": {"rewards": [0.8456666823476553, 0.6656666779890656, 0.5790000092238188, 0.4189999457448721, 0.5656666159629822, 0.6189999505877495, 0.8656666232272983, 0.7323333462700248, 0.6656666183844209, 0.4656666135415435], "steps": [22, 49, 62, 86, 64, 56, 19, 39, 49, 79], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.5990000311285257, -1.0099999774247408, 0.2890000380575657, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.1690000407397747, 0.12900004163384438, 0.25900003872811794, -1.0099999774247408], "steps": [39, 100, 70, 100, 100, 100, 82, 86, 73, 100], "results": [1, 0, 1, 0, 0, 0, 1, 1, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8870000122115016], "steps": [27], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.8749999534338713], "steps": [30], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.8830000124871731], "steps": [28], "results": [0]}}}, "level_01_food": 0.7317460317460318, "level_03_obstacles": 1.0, "level_04_avoidance": 0.28, "level_05_spatial_reasoning": 0.95, "level_06_generalization": 0.75, "level_07_internal_memory": 0.725, "level_09_advanced_preferences": 0.4, "mean_score": 0.6909637188208617}