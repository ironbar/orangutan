{"elapsed_time": 297.8832983970642, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.1955000488087535, 0.3355000391602516, 0.13950005266815424, 0.4035000344738364, 0.23150004632771015], "steps": [75, 40, 89, 23, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.867000013589859, 0.8270000163465738, 0.8510000146925449, 0.7910000188276172, 0.7750000199303031], "steps": [32, 42, 36, 51, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7499999748542905, 1.850000087171793, 1.974000078625977, 1.6779999798163772, 1.745999975129962], "steps": [61, 36, 5, 79, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.761000046506524, 2.845000040717423, 2.7890000445768237, 2.8730000387877226, 2.9010002752766013], "steps": [58, 37, 51, 30, 23], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7400003587827086, 3.868000111542642, 3.7080001225695014, 3.712000360712409, 3.5000003753229976], "steps": [63, 31, 71, 70, 123], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.594999725930393, 4.695000195875764, 4.639000199735165, 4.735000193119049, 4.983000176027417], "steps": [99, 74, 88, 64, 2], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.015500031411647797, 0.34350003860890865, 0.4435000019147992, 0.3315000096336007, -0.1804999252781272], "steps": [120, 38, 13, 41, 169], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9149999506771564, 0.5629999749362469, 0.8710000133141875, 0.5670000342652202, 0.743000022135675], "steps": [20, 108, 31, 107, 63], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.2420000098645687, 1.9060000833123922, 1.4900001119822264, 1.8379999687895179, 1.521999990567565], "steps": [188, 22, 126, 39, 118], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.697000289335847, 2.6810000520199537, 2.653000292368233, 2.7410000478848815, 2.897000275552273], "steps": [74, 78, 85, 63, 24], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.7160001220181584, 3.744000120088458, 3.8320001140236855, 3.5840003695338964, 3.6320001278072596], "steps": [69, 62, 40, 102, 90], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.591000203043222, 4.67900019697845, 4.775000190362334, 4.923000180162489, 4.334999743849039], "steps": [100, 78, 54, 17, 164], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.25550004467368126, 0.20750004798173904, 0.07550005707889795, 0.11950002424418926, 0.13950005266815424], "steps": [60, 72, 105, 94, 89], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.40700004529207945, 0.6750000268220901, 0.8110000174492598, 0.8070000177249312, 0.6550000282004476], "steps": [147, 80, 46, 47, 85], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.747000192292035, 4.627000200562179, 4.802999711595476, 4.7709997138008475, 4.943000178784132], "steps": [61, 91, 47, 55, 12], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.36350003723055124, 0.16350002121180296, 0.1955000190064311, 0.08350005652755499, 0.2835000427439809], "steps": [33, 83, 75, 103, 53], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.635000029578805, 0.7390000224113464, 0.6670000273734331, 0.643000029027462, 0.7309999633580446], "steps": [90, 64, 82, 88, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.642999722622335, 4.598999725654721, 4.951000178232789, 4.983000176027417, 4.8709997069090605], "steps": [87, 98, 10, 2, 30], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.7869999925605953, 0.22700009169057012, 0.7090000584721565, 0.9169999845325947, 0.8689999878406525], "steps": [393, 385, 144, 40, 64], "results": [0, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8989999857731164, 0.4490000167861581, -1.57299988809973, 0.6630000020377338, 0.36100008245557547], "steps": [49, 274, 286, 167, 318], "results": [1, 1, 0, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.045000044628977776, 0.37300002202391624, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [476, 312, 500, 500, 500], "results": [1, 1, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-0.24199993209913373, 1.995000065304339, -0.0029999520629644394, 1.6220000945031643, 3.289999964181334], "steps": [120, 500, 500, 187, 352], "results": [0, 0.5, 0, 0.5, 1]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9189999843947589, 0.8770000468939543, 0.756999995559454, 0.9049999853596091, 0.9009999856352806], "steps": [39, 60, 120, 46, 48], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8929999861866236, -1.904999865218997, 0.8850000463426113, 0.5990000064484775, 0.8049999922513962], "steps": [52, 452, 56, 199, 96], "results": [1, 0, 1, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0470000435598195, 0.8469999893568456, -1.0689999228343368, 0.587000007275492, 0.8990000453777611], "steps": [23, 75, 34, 205, 49], "results": [0, 1, 0, 1, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9009999856352806, 0.8969999859109521, 0.9190000439994037, 0.9189999843947589, 0.9189999843947589], "steps": [48, 50, 39, 39, 39], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.6830000006593764, 0.8469999893568456, 0.42700001830235124, 0.8589999885298312, 0.7609999952837825], "steps": [157, 75, 285, 69, 118], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.3990000202320516, 0.8529999889433384, 0.8610000479966402, 0.9109999849461019, 0.6710000014863908], "steps": [299, 72, 68, 43, 163], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.1200002310797572], "steps": [438], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.7850000532343984], "steps": [106], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.7710000541992486], "steps": [113], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.7969999928027391], "steps": [100], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.8209999911487103], "steps": [88], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.7769999941810966], "steps": [110], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.31900002574548125], "steps": [339], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.874000085517764], "steps": [61], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8280000290833414], "steps": [84], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.894000024534762], "steps": [51], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.877999966032803], "steps": [59], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.8920000246725976], "steps": [52], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.9179999632760882], "steps": [39], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.85800008662045], "steps": [69], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.9670000323094428], "steps": [14], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.6659999806433916], "steps": [165], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [1.8339999690651894], "steps": [81], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.9200000567361712], "steps": [38], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.922000175807625], "steps": [37], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.9520000545307994], "steps": [22], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9520000545307994], "steps": [22], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9680000534281135], "steps": [14], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9700001724995673], "steps": [13], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.9520000545307994], "steps": [22], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [1.9480001740157604], "steps": [24], "results": [1]}, "YellowOverGreen_1.yaml": {"rewards": [0.9770000400021672], "steps": [10], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9769999803975224], "steps": [10], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9769999803975224], "steps": [10], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.975000040140003], "steps": [11], "results": [0]}}}, "level_01_food": 0.6793650793650793, "level_02_preferences": 0.7333333333333333, "mean_score": 0.7063492063492063}