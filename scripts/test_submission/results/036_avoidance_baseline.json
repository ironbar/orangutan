{"elapsed_time": 537.5585100650787, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 0.15550002176314592, 0.4195000333711505, -1.003999930806458], "steps": [249, 250, 85, 19, 250], "results": [0, 0, 1, 1, 0]}, "GoodGoal_size1.yaml": {"rewards": [0.867000013589859, 0.5710000339895487, 0.8510000146925449, 0.5910000326111913, 0.6950000254437327], "steps": [32, 106, 36, 101, 75], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.653999981470406, -1.003999930806458, 1.3820001194253564, 1.0260000247508287, 1.298000006005168], "steps": [85, 250, 153, 242, 174], "results": [1, 0, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.6650002915412188, 2.7650002846494317, 2.537000061944127, 2.861000278033316, 2.1450000889599323], "steps": [82, 57, 114, 33, 212], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.3600003849714994, 3.8640001118183136, 3.5080001363530755, 3.404000143520534, 3.572000131942332], "steps": [158, 32, 121, 147, 105], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [-0.9999999310821295, 4.547000206075609, 4.819000187329948, 4.683000196702778, 4.591000203043222], "steps": [249, 111, 43, 77, 100], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [-0.35649994295090437, -1.003999930806458, 0.4435000317171216, -1.003999930806458, -1.003999930806458], "steps": [213, 250, 13, 250, 250], "results": [1, 0, 1, 0, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [-0.9999999310821295, 0.759000021032989, 0.6470000287517905, 0.6149999713525176, 0.3910000463947654], "steps": [249, 59, 87, 95, 151], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.77799997292459, 1.8900000844150782, 1.5339999897405505, 1.845999968238175, 1.4780001128092408], "steps": [54, 26, 115, 37, 129], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.6770002907142043, -1.003999930806458, -1.003999930806458, 2.913000274449587, 2.8570002783089876], "steps": [79, 250, 250, 20, 34], "results": [1, 0, 0, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.464000139385462, 3.928000345826149, 3.6080001294612885, 3.2240001559257507, -1.003999930806458], "steps": [132, 16, 96, 192, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.447000212967396, 4.467000211589038, 4.539000206626952, 4.475000211037695, 4.619000201113522], "steps": [136, 131, 113, 129, 93], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, -0.25649992004036903, 0.15950002148747444, -1.003999930806458, 0.03950005955994129], "steps": [249, 188, 84, 250, 114], "results": [0, 1, 1, 0, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.5989999724552035, 0.4230000441893935, -1.003999930806458, 0.3230000510811806], "steps": [249, 99, 143, 250, 168], "results": [0, 1, 1, 0, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.398999739438295, 4.174999754875898, 4.807000188156962, -1.003999930806458], "steps": [249, 148, 204, 46, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, -0.012499936856329441, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 127, 250, 250, 250], "results": [0, 1, 0, 0, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.05100001022219658, -1.003999930806458, 0.147000003606081, -1.003999930806458], "steps": [249, 236, 250, 212, 250], "results": [0, 1, 0, 1, 0]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.631000200286508, 4.218999751843512, 4.983000176027417, -1.003999930806458], "steps": [249, 90, 193, 2, 250], "results": [0, 1, 1, 1, 0]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [-1.3389999042265117, 0.8849999867379665, -1.1570000359788537, 0.4490000167861581, -1.3690000213682652], "steps": [169, 56, 78, 274, 184], "results": [0, 1, 0, 1, 0]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.121000038459897, 0.710999998729676, -1.1509999171830714, -1.46499989554286, -1.1229999191127717], "steps": [60, 143, 75, 232, 61], "results": [0, 1, 0, 0, 0]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-1.469000014476478, -1.162999916356057, -1.0609999233856797, -1.6989998794160783, -2.1199999917298555], "steps": [234, 81, 30, 349, 60], "results": [0, 0, 0, 0, 0]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.075000041630119, -1.7329998770728707, -1.804999872110784, -1.2309999116696417, 0.7809999939054251], "steps": [37, 366, 402, 115, 108], "results": [0, 0, 0, 0, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-1.4149998989887536, -0.33399986615404487, -0.2460000510327518, -0.5079998541623354, -0.43999991845339537], "steps": [207, 166, 122, 253, 219], "results": [0, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9229999841190875, 0.9009999856352806, -1.8569998685270548, 0.7610000548884273, -1.059000042732805], "steps": [37, 48, 428, 118, 29], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8669999879784882, -1.2669999091885984, -2.091999993659556, -1.0429999246262014, -1.1549999169074], "steps": [65, 133, 46, 21, 77], "results": [1, 0, 0, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.1229999191127717, -1.0410000439733267, -1.1110000391490757, 0.8629999882541597, -1.0410000439733267], "steps": [61, 20, 55, 67, 20], "results": [0, 0, 0, 1, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.818999991286546, 0.8849999867379665, 0.9229999841190875, -1.0489999242126942, 0.9209999842569232], "steps": [89, 56, 37, 24, 38], "results": [1, 1, 1, 0, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-1.4209998985752463, 0.8969999859109521, -1.0969999209046364, -1.1229999191127717, 0.818999991286546], "steps": [210, 50, 48, 61, 89], "results": [0, 1, 0, 0, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.035000044386834, -1.1450000368058681, -1.7269999966956675, -1.1189999193884432, -1.021000045351684], "steps": [17, 72, 363, 59, 10], "results": [0, 0, 0, 0, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [-1.0609999233856797], "steps": [30], "results": [0]}, "DeadComing_2.yaml": {"rewards": [-1.0749999224208295], "steps": [37], "results": [0]}, "DeadComing_3.yaml": {"rewards": [-1.03299992531538], "steps": [16], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.5070000723935664], "steps": [245], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-1.2609999096021056], "steps": [130], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [-2.0479998774826527], "steps": [24], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-3.0490000690333545], "steps": [25], "results": [0]}, "RedWall_1.yaml": {"rewards": [-1.0689999228343368], "steps": [34], "results": [0]}, "RedWall_2.yaml": {"rewards": [-1.1730000348761678], "steps": [86], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.9789998601190746], "steps": [489], "results": [0]}, "RedWall_4.yaml": {"rewards": [-1.1069999202154577], "steps": [53], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-1.054999923799187], "steps": [27], "results": [0]}, "RedWall_7.yaml": {"rewards": [-1.0530000431463122], "steps": [26], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.6570000620558858, 0.12100009899586439, -1.750999875832349, -1.0019999309442937, -1.2369999112561345], "steps": [170, 438, 375, 500, 118], "results": [1, 1, 0, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [1.6420000419020653], "steps": [177], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [0.6969999996945262], "steps": [150], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [-0.000999892596155405], "steps": [499], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "YellowOverGreen_5.yaml": {"rewards": [1.7120000370778143], "steps": [142], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.4940000521019101], "steps": [251], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.5440000486560166], "steps": [226], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.721000049263239], "steps": [137], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.0380000239238143], "steps": [479], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.5810001781210303], "steps": [207], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.8250000504776835, 0.5170000120997429, -1.0019999309442937, 0.9029999854974449, 0.8369999900460243, 0.805000051856041, -1.0019999309442937, 0.45900007570162416, 0.9590000412426889, -1.0019999309442937], "steps": [86, 240, 500, 47, 80, 96, 500, 269, 19, 500], "results": [1, 1, 0, 1, 1, 1, 0, 1, 1, 0]}, "objectManipulation.yaml": {"rewards": [0.5910000666044652, 0.810999991837889, 0.8389999899081886, 0.9310000431723893, -1.0019999309442937, 0.7630000547505915, -1.0019999309442937, 0.6350000635720789, 0.2050000336021185, 0.6890000002458692], "steps": [203, 93, 79, 33, 500, 117, 500, 181, 396, 154], "results": [1, 1, 1, 1, 0, 1, 0, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8569999886676669], "steps": [70], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.8369999900460243], "steps": [80], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.5310000111348927], "steps": [233], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [0.718999998178333], "steps": [139], "results": [1]}, "Ring_2.yaml": {"rewards": [0.7249999977648258], "steps": [136], "results": [1]}, "Ring_3.yaml": {"rewards": [-1.1319999652914703], "steps": [65], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.105999967083335], "steps": [52], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.0199999730102718], "steps": [9], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-1.0199998538009822], "steps": [9], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-1.0533333553466946], "steps": [39], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-1.0839999024756253], "steps": [62], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-1.9480000124312937], "steps": [710], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.3669999970588833], "steps": [473], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-1.0199999730102718, 0.8529999889433384, 0.8749999874271452, 0.8529999889433384, 0.8249999908730388], "steps": [9, 72, 61, 72, 86], "results": [0, 1, 1, 1, 1]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 0.45500007597729564], "steps": [499, 500, 500, 500, 271], "results": [0, 0, 0, 0, 1]}, "ChessBoard_3.yaml": {"rewards": [0.7070000586099923, 0.6610000021755695, 0.481000074185431, 0.7009999994188547, 0.11766673997044563], "steps": [145, 168, 258, 148, 253], "results": [1, 1, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.35033334558829665, 0.6716666663996875, 0.5576667338609695, -1.0553332641720772, 0.22233335999771953], "steps": [260, 156, 213, 500, 354], "results": [1, 1, 1, 0, 1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.0009999522008001804, -0.002999892458319664, -0.0029999520629644394, -0.002999892458319664, -0.0029999520629644394, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937, 1.3560000616125762, -0.002999892458319664], "steps": [499, 500, 500, 500, 500, 500, 500, 500, 320, 500], "results": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0, 1, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, -0.004999926313757896, -0.004999985918402672, -0.004999985918402672], "steps": [249, 250, 250, 250, 250, 250, 250, 250, 250, 250], "results": [0.5, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.1310000643134117, -1.003999930806458, -1.003999930806458, 1.861999967135489, -1.003999930806458], "steps": [249, 250, 250, 250, 250, 216, 250, 250, 33, 250], "results": [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.9110000105574727, -1.003999930806458, 0.934999949298799, -1.003999930806458, 0.6230000304058194, 0.9469999484717846, 0.22300005797296762, -1.003999930806458, 0.8869999526068568, -1.003999930806458], "steps": [21, 250, 15, 250, 93, 12, 193, 250, 27, 250], "results": [1, 0, 1, 0, 1, 1, 1, 0, 1, 0]}, "InternalMemory_3.yaml": {"rewards": [0.8190000150352716, 0.6590000111609697, 0.425666612572968, -1.0066666910424829, -1.0066666910424829, 0.36566667072474957, -1.0066666910424829, 0.36566667072474957, -1.0066666910424829, -1.0066666910424829], "steps": [26, 50, 85, 150, 150, 94, 150, 94, 150, 150], "results": [1, 1, 1, 0, 0, 1, 0, 1, 0, 0]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, -1.0099999774247408, 0.23900003917515278, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408], "steps": [99, 100, 75, 100, 100, 100, 100, 100, 100, 100], "results": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_2.yaml": {"rewards": [0.519000037573278], "steps": [119], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}}}, "level_01_food": 0.38095238095238093, "level_03_obstacles": 0.75, "level_04_avoidance": 0.44000000000000006, "level_05_spatial_reasoning": 0.45, "level_06_generalization": 0.2, "level_07_internal_memory": 0.35000000000000003, "level_09_advanced_preferences": 0.2, "mean_score": 0.3958503401360545}