{"elapsed_time": 425.5050790309906, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [-0.06849993299692869, 0.27550001349300146, 0.0035000620409846306, 0.4195000035688281, 0.13550005294382572], "steps": [141, 55, 123, 19, 90], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8389999559149146, 0.7909999592229724, 0.8470000149682164, 0.875000013038516, 0.2590000554919243], "steps": [39, 51, 37, 30, 184], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [-0.9999999310821295, 1.8540000868961215, 1.529999990016222, 1.637999982573092, -1.003999930806458], "steps": [249, 35, 116, 89, 250], "results": [0, 1, 1, 1, 0]}, "GoodGoal_size3.yaml": {"rewards": [2.6570000536739826, 2.845000040717423, 2.6730000525712967, 2.8730000387877226, 2.90500027500093], "steps": [84, 37, 80, 30, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [-0.9999999310821295, 3.876000110991299, -1.003999930806458, 3.7640003571286798, 3.6240001283586025], "steps": [249, 29, 250, 57, 92], "results": [0, 1, 0, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.583000203594565, 4.411000215448439, 4.858999707736075, 4.78700018953532, 4.343000220134854], "steps": [102, 145, 33, 51, 162], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.3275000397115946, -1.003999930806458, 0.43150000274181366, 0.22750004660338163, -1.003999930806458], "steps": [42, 250, 16, 67, 250], "results": [1, 0, 1, 1, 0]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9270000094547868, 0.8430000152438879, 0.635000029578805, 0.7229999639093876, 0.14700006321072578], "steps": [17, 38, 90, 68, 212], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7939999718219042, 1.9099999638274312, 1.6579999811947346, 1.8460000874474645, 1.5899999858811498], "steps": [50, 21, 84, 37, 101], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.2530000815168023, 2.3610000740736723, 2.9170000357553363, 2.9170000357553363, 2.9050000365823507], "steps": [185, 158, 19, 19, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.7800001176074147, 3.936000106856227, 3.472000138834119, -1.003999930806458, 3.552000133320689], "steps": [53, 14, 130, 250, 110], "results": [1, 1, 1, 0, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.810999711044133, 4.910999704152346, 4.535000206902623, 4.535000206902623, 4.57100020442158], "steps": [45, 20, 114, 114, 105], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.19150004908442497, 0.035500059835612774, -1.003999930806458, -0.276499948464334, -0.3124999161809683], "steps": [76, 115, 250, 193, 202], "results": [1, 1, 0, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.7950000185519457, 0.7709999606013298, 0.7630000207573175, 0.5910000326111913, 0.6550000282004476], "steps": [50, 56, 58, 101, 85], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.735000193119049, -1.003999930806458, -1.003999930806458, 4.763000191189349, 4.786999712698162], "steps": [64, 250, 250, 57, 51], "results": [1, 0, 0, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.9999999310821295, 0.07550002727657557, -1.003999930806458, -0.26449991948902607, -0.3404999142512679], "steps": [249, 105, 250, 190, 209], "results": [0, 1, 0, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.6110000312328339, 0.12300006486475468, 0.5630000345408916, 0.6030000317841768, 0.7630000207573175], "steps": [96, 218, 108, 98, 58], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.871000183746219, 4.510999731719494, 4.942999701946974, 4.983000176027417, 4.215000228956342], "steps": [30, 120, 12, 2, 194], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.643000063020736, 0.8449999894946814, 0.641000003553927, 0.880999987013638, 0.6310000638477504], "steps": [177, 76, 178, 58, 183], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8810000466182828, 0.4670000155456364, 0.7629999951459467, -1.0019999309442937, 0.8489999892190099], "steps": [58, 265, 117, 500, 74], "results": [1, 1, 1, 0, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [-0.9999999310821295, 0.8169999914243817, 0.06100010313093662, 0.6710000014863908, 0.6190000646747649], "steps": [499, 90, 468, 163, 189], "results": [0, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.7269999976269901, -1.0019999309442937, -1.0019999309442937, 0.4930000137537718, -1.0019999309442937], "steps": [135, 500, 500, 252, 500], "results": [1, 0, 0, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.9970000651665032, 0.9960000864230096, -0.0029999520629644394, -0.0029999520629644394, -0.0029999520629644394], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0, 0, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9250000435858965, 0.9069999852217734, 0.8989999857731164, 0.8929999861866236, 0.6650000615045428], "steps": [36, 45, 49, 52, 166], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8689999878406525, 0.8690000474452972, 0.8930000457912683, 0.7870000530965626, -1.1149999196641147], "steps": [64, 64, 52, 105, 57], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0690000420436263, 0.7890000529587269, 0.8569999886676669, -1.1209999192506075, -1.8749998672865331], "steps": [34, 104, 70, 60, 437], "results": [0, 1, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8829999868758023, 0.8929999861866236, 0.9209999842569232, 0.9209999842569232, 0.9209999842569232], "steps": [57, 52, 38, 38, 38], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.8570000482723117, 0.8990000453777611, -1.0989999207668006, -1.086999921593815, -1.0389999249018729], "steps": [70, 49, 49, 43, 19], "results": [1, 1, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.1010000398382545, -1.5869998871348798, -1.0610000425949693, 0.8990000453777611, 0.7829999937675893], "steps": [50, 293, 30, 49, 107], "results": [0, 0, 0, 1, 1]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [1.8140000640414655], "steps": [91], "results": [1]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.9110000445507467], "steps": [43], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.9289999837055802], "steps": [34], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0310000446625054], "steps": [15], "results": [0]}, "DeadComing_4.yaml": {"rewards": [-2.0559999961405993], "steps": [28], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.8669999879784882], "steps": [65], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "HidingGoal_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.880999987013638], "steps": [58], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [0.8429999896325171], "steps": [77], "results": [1]}, "RedWall_5.yaml": {"rewards": [0.8629999882541597], "steps": [67], "results": [1]}, "RedWall_6.yaml": {"rewards": [0.5710000083781779], "steps": [213], "results": [1]}, "RedWall_7.yaml": {"rewards": [0.7609999952837825], "steps": [118], "results": [1]}, "YellowOverGreen_1.yaml": {"rewards": [1.5680001066066325], "steps": [214], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8579999674111605], "steps": [69], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8579999674111605], "steps": [69], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.8179999701678753], "steps": [89], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.81800002977252], "steps": [89], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.810000030323863], "steps": [93], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8220000294968486], "steps": [87], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.8139999704435468], "steps": [91], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [0]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [-0.9999999310821295, 0.9209999842569232, -1.0019999309442937, 0.8489999892190099, -1.0019999309442937, 0.8790000467561185, 0.8150000511668622, 0.5370000107213855, 0.7750000539235771, -1.0019999309442937], "steps": [499, 38, 500, 74, 500, 59, 91, 230, 111, 500], "results": [0, 1, 0, 1, 0, 1, 1, 1, 1, 0]}, "objectManipulation.yaml": {"rewards": [-0.9999999310821295, 0.929000043310225, 0.43500007735565305, 0.8150000511668622, 0.3450000239536166, 0.5550000094808638, 0.4530000165104866, 0.9689999809488654, 0.7850000532343984, 0.4690000154078007], "steps": [499, 34, 281, 91, 326, 221, 272, 14, 106, 264], "results": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8310000500641763], "steps": [83], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.1650000959634781], "steps": [416], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "CenterMoat_4.yaml": {"rewards": [-1.1659998437389731], "steps": [82], "results": [0]}, "Ring_1.yaml": {"rewards": [0.5690000085160136], "steps": [214], "results": [1]}, "Ring_2.yaml": {"rewards": [-1.983999787364155], "steps": [491], "results": [0]}, "Ring_3.yaml": {"rewards": [-1.369999948889017], "steps": [184], "results": [0]}, "Ring_4.yaml": {"rewards": [-1.2579999566078186], "steps": [128], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-1.5879999338649213], "steps": [293], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-1.0253333556465805], "steps": [18], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-1.1053333547897637], "steps": [78], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-1.1040000214707106], "steps": [77], "results": [0]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [-0.9999999310821295, -0.002999892458319664, -0.002999892458319664, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937, -0.002999892458319664, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500, 500, 500, 500, 500, 500], "results": [0, 0.5, 0.5, 0, 0.5, 0, 0, 0.5, 0, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, 1.2979999976232648, -0.004999985918402672, -1.003999930806458, 1.1220000693574548, -0.004999985918402672, -0.004999926313757896, 1.3300000550225377, -1.003999930806458, -0.004999926313757896], "steps": [249, 174, 250, 250, 218, 250, 250, 166, 250, 250], "results": [0, 1, 0.5, 0, 1, 0.5, 0.5, 1, 0, 0.5]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.9030000111088157, -1.003999930806458, 0.5670000342652202, 0.5550000350922346, 0.419000044465065, 0.6110000312328339, 0.6190000306814909, -1.003999930806458, 0.4590000417083502, 0.04300007037818432], "steps": [23, 250, 107, 110, 144, 96, 94, 250, 134, 238], "results": [1, 0, 1, 1, 1, 1, 1, 0, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [-0.9999999310821295, 0.9310000091791153, 0.5910000326111913, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.8110000174492598, -1.003999930806458, 0.5829999735578895, 0.694999965839088], "steps": [249, 16, 101, 250, 250, 250, 46, 250, 103, 75], "results": [0, 1, 1, 0, 0, 0, 1, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [-1.000000024214387, 0.16566666588187218, 0.5990000097081065, 0.8190000150352716, -1.0066666910424829, 0.559000008739531, 0.8456666823476553, -1.0066666910424829, -1.0066666910424829, 0.9256666842848063], "steps": [149, 124, 59, 26, 150, 65, 22, 150, 150, 10], "results": [0, 1, 1, 1, 0, 1, 1, 0, 0, 1]}, "InternalMemory_4.yaml": {"rewards": [-0.9999999776482582, 0.7190000284463167, -1.0099999774247408, 0.4990000333636999, -1.0099999774247408, 0.7790000271052122, 0.6690000295639038, -1.0099999774247408, 0.3890000358223915, -1.0099999774247408], "steps": [99, 27, 100, 49, 100, 21, 32, 100, 60, 100], "results": [0, 1, 0, 1, 0, 1, 1, 0, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.2630000552162528], "steps": [183], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.4590000417083502], "steps": [134], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [0.5109999785199761], "steps": [121], "results": [1]}, "forcedChoice_4.yaml": {"rewards": [0.7909999592229724], "steps": [51], "results": [1]}, "forcedChoice_5.yaml": {"rewards": [0.643000029027462], "steps": [88], "results": [0]}}}, "level_01_food": 0.6403225806451612, "level_03_obstacles": 0.75, "level_04_avoidance": 0.1875, "level_05_spatial_reasoning": 0.2, "level_06_generalization": 0.5, "level_07_internal_memory": 0.6, "level_09_advanced_preferences": 0.8, "mean_score": 0.5254032258064516}