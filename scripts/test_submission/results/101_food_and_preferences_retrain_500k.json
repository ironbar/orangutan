{"elapsed_time": 243.02578020095825, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.17950004991143942, -0.5044999327510595, 0.3035000413656235, 0.41150003392249346, 0.32350003998726606], "steps": [79, 250, 48, 21, 43], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.859000014141202, 0.6830000262707472, 0.8110000174492598, 0.6990000251680613, 0.7509999619796872], "steps": [34, 78, 46, 74, 61], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7700000926852226, 1.8219999698922038, 1.8819999657571316, 1.7219999767839909, 1.8780000852420926], "steps": [56, 43, 28, 68, 29], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.845000040717423, 2.6490000542253256, 2.8570000398904085, 2.789000282995403, 2.837000279687345], "steps": [37, 86, 34, 51, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7600003574043512, 3.8200001148507, 3.796000116504729, 3.804000354371965, 3.9240003461018205], "steps": [58, 43, 49, 47, 17], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.815000187605619, 4.695000195875764, 4.750999715179205, 4.726999716833234, 4.89500018209219], "steps": [44, 74, 60, 66, 24], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.21550004743039608, 0.3315000394359231, 0.43550003226846457, 0.23150004632771015, 0.23150004632771015], "steps": [70, 41, 15, 66, 66], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.6750000268220901, 0.8430000152438879, 0.8510000146925449, 0.7750000199303031, 0.859000014141202], "steps": [80, 38, 36, 55, 34], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7899999720975757, 1.88599996548146, 1.7700000926852226, 1.8299999693408608, 1.6939999787136912], "steps": [51, 27, 56, 41, 75], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.721000049263239, 2.777000045403838, 2.6330000553280115, 2.8410000409930944, 2.74500004760921], "steps": [68, 54, 90, 38, 62], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [-0.9999999310821295, 3.912000346928835, 3.7560001192614436, 3.620000367052853, 3.436000141315162], "steps": [249, 20, 59, 93, 139], "results": [0, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.323000221513212, -1.003999930806458, 4.570999727584422, 4.695000195875764, 4.7230001939460635], "steps": [167, 250, 105, 74, 67], "results": [1, 0, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.9999999310821295, 0.07150002755224705, 0.2675000438466668, -0.0004999376833438873, 0.3795000361278653], "steps": [249, 106, 57, 124, 29], "results": [0, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.694999965839088, 0.5670000342652202, 0.7990000182762742, 0.743000022135675, 0.7550000213086605], "steps": [75, 107, 49, 63, 60], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.786999712698162, 4.690999719314277, 4.730999716557562, 4.471000211313367, 4.815000187605619], "steps": [51, 75, 65, 130, 44], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.2195000471547246, 0.23150001652538776, 0.2195000471547246, 0.20750001817941666, 0.3115000408142805], "steps": [69, 66, 69, 72, 46], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.651000028476119, 0.7789999600499868, 0.5750000337138772, 0.7829999597743154, 0.7750000199303031], "steps": [86, 54, 105, 53, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.610999724827707, 4.635000200010836, -1.003999930806458, 4.983000176027417, 4.7709997138008475], "steps": [95, 89, 250, 2, 55], "results": [1, 1, 0, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8589999885298312, 0.8349999901838601, 0.705000058747828, 0.8950000456534326, 0.3650000225752592], "steps": [69, 81, 146, 51, 316], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.8949999860487878, 0.6530000027269125, 0.764999995008111, 0.867000047583133, 0.8470000489614904], "steps": [51, 172, 116, 65, 75], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.8349999901838601, 0.8229999910108745, 0.6910000001080334, 0.3150000856257975, 0.6989999995566905], "steps": [81, 87, 153, 341, 149], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.22500003222376108, 0.6250000046566129, 0.7330000568181276, 0.6770000010728836, -1.6110000046901405], "steps": [386, 186, 132, 160, 305], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [1.5339999813586473, 3.4440000131726265, 0.4830000656656921, 1.9950000056996942, -0.0029999520629644394], "steps": [231, 275, 257, 500, 500], "results": [0.5, 1, 0, 0.5, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9190000439994037, 0.9069999852217734, 0.8629999882541597, 0.9129999848082662, 0.9029999854974449], "steps": [39, 45, 67, 42, 47], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8449999894946814, 0.3910000207833946, 0.8770000468939543, 0.48100001458078623, 0.8449999894946814], "steps": [76, 303, 60, 258, 76], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.8149999915622175, 0.7890000529587269, 0.7169999983161688, 0.7490000557154417, 0.8229999910108745], "steps": [91, 104, 140, 124, 87], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8669999879784882, 0.8989999857731164, 0.9190000439994037, 0.9229999841190875, 0.9190000439994037], "steps": [65, 49, 39, 37, 39], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.7529999958351254, 0.9009999856352806, -1.1589999166317284, 0.8669999879784882, 0.8789999871514738], "steps": [122, 48, 79, 65, 59], "results": [1, 1, 0, 1, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7889999933540821, 0.7449999963864684, 0.880999987013638, 0.8170000510290265, 0.4630000158213079], "steps": [104, 126, 58, 90, 267], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [0.34300002409145236], "steps": [327], "results": [1]}, "RedHouse_2.yaml": {"rewards": [0.41100001940503716], "steps": [293], "results": [1]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [0.2730000289157033], "steps": [362], "results": [1]}, "RedHouse_5.yaml": {"rewards": [-1.2890000268816948], "steps": [144], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [1.532000083476305], "steps": [232], "results": [1]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8329999903216958], "steps": [82], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.772999994456768], "steps": [112], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.8530000485479832], "steps": [72], "results": [1]}, "DeadComing_4.yaml": {"rewards": [-1.1349999182857573], "steps": [67], "results": [0]}, "HidingGoal_1.yaml": {"rewards": [0.665000001899898], "steps": [166], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.7270000572316349], "steps": [135], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.44100001733750105], "steps": [278], "results": [1]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.1750000356696546, 0.4090000195428729, -1.0019999309442937, 0.2490000305697322, 0.10100004076957703], "steps": [411, 294, 500, 374, 448], "results": [1, 1, 0, 1, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.8780000256374478], "steps": [59], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8140000300481915], "steps": [91], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8919999650679529], "steps": [52], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.842000087723136], "steps": [77], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.761999974027276], "steps": [117], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.92600002232939], "steps": [35], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.8320000288076699], "steps": [82], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9700001724995673], "steps": [13], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.8719999664463103], "steps": [62], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [1.9660000535659492], "steps": [15], "results": [0]}, "YellowOverGreen_11.yaml": {"rewards": [1.8500000275671482], "steps": [73], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.9120001764968038], "steps": [42], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9220000565983355], "steps": [37], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.9500001738779247], "steps": [23], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.9460001741535962], "steps": [25], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.9580000541172922], "steps": [19], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9700000532902777], "steps": [13], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.9460001741535962], "steps": [25], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9700000532902777], "steps": [13], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [1.9400000553578138], "steps": [28], "results": [1]}, "YellowOverGreen_1.yaml": {"rewards": [0.9749999805353582], "steps": [11], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9730000402778387], "steps": [12], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.975000040140003], "steps": [11], "results": [0]}}}, "level_01_food": 0.746031746031746, "level_02_preferences": 0.7333333333333333, "mean_score": 0.7396825396825397}