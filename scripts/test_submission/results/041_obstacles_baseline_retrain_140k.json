{"elapsed_time": 2058.419362783432, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.059500028379261494, 0.3715000366792083, 0.2675000438466668, 0.423500033095479, 0.33550000935792923], "steps": [109, 31, 57, 18, 40], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8630000138655305, 0.8310000160709023, 0.8510000146925449, 0.8910000119358301, 0.751000021584332], "steps": [33, 41, 36, 26, 61], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7579999743029475, 1.853999967686832, 1.8659999668598175, 1.8739999663084745, 1.869999966584146], "steps": [59, 35, 32, 30, 31], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.8490000404417515, 2.845000040717423, 2.7650000462308526, 2.6410000547766685, 2.9010002752766013], "steps": [36, 37, 57, 88, 23], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.104000164195895, 3.868000111542642, 3.1000001644715667, 3.812000115402043, 3.544000133872032], "steps": [222, 31, 223, 45, 112], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.582999726757407, 4.671000197529793, 4.811000187881291, 4.727000193670392, 4.8310001865029335], "steps": [102, 80, 45, 66, 40], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.31950004026293755, 0.33950003888458014, 0.44750000163912773, 0.33950003888458014, 0.3075000112876296], "steps": [44, 39, 12, 39, 47], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.9270000094547868, 0.8310000160709023, 0.6989999655634165, 0.7709999606013298, 0.8430000152438879], "steps": [17, 41, 74, 56, 38], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.7939999718219042, 1.9099999638274312, 1.753999974578619, 1.8460000874474645, 1.8460000874474645], "steps": [50, 21, 60, 37, 37], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.861000278033316, 2.777000045403838, 2.913000274449587, 2.913000274449587, 2.901000036858022], "steps": [33, 54, 20, 20, 23], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.836000352166593, 3.936000106856227, 3.728000121191144, 3.772000356577337, 3.836000113748014], "steps": [39, 14, 66, 55, 39], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.735000193119049, 4.75900019146502, 4.815000187605619, 4.730999716557562, 4.826999709941447], "steps": [64, 58, 44, 65, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.2915000421926379, 0.0835000267252326, 0.2835000427439809, 0.2195000471547246, -1.003999930806458], "steps": [51, 103, 53, 69, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.7710000202059746, 0.2109999991953373, 0.8390000155195594, 0.818999957293272, 0.8310000160709023], "steps": [56, 196, 39, 44, 41], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.515000208280981, 4.175000231713057, 4.371000218205154, 4.46300021186471, 4.935000179335475], "steps": [119, 204, 155, 132, 14], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.004499937407672405, 0.22350004687905312, 0.035500059835612774, 0.1075000548735261, 0.12350005377084017], "steps": [125, 68, 115, 97, 93], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7910000188276172, 0.7910000188276172, 0.7230000235140324, 0.419000044465065, 0.7750000199303031], "steps": [51, 51, 68, 144, 55], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.863000184297562, 4.68299971986562, 4.943000178784132, 4.983000176027417, 4.86700018402189], "steps": [32, 77, 12, 2, 31], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.7530000554397702, 0.7290000570937991, -1.2470000297762454, 0.9170000441372395, 0.8589999885298312], "steps": [122, 134, 123, 40, 69], "results": [1, 1, 0, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9069999852217734, 0.6950000594370067, 0.8909999863244593, 0.8929999861866236, 0.9190000439994037], "steps": [45, 151, 53, 52, 39], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.7389999967999756, 0.8949999860487878, 0.8229999910108745, 0.7889999933540821, 0.5510000097565353], "steps": [129, 51, 87, 104, 223], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.772999994456768, 0.7289999974891543, 0.7869999934919178, 0.651000062469393, 0.10700009996071458], "steps": [112, 134, 105, 173, 445], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-0.17799999611452222, 1.9950000056996942, 1.307999996934086, 3.2540001454763114, 3.6160000609233975], "steps": [88, 500, 344, 370, 189], "results": [0, 0.5, 0.5, 1, 1]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.9209999842569232, 0.9150000442750752, 0.9189999843947589, 0.7849999936297536], "steps": [36, 38, 41, 39, 106], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8529999889433384, -1.426999898161739, -1.0330000445246696, 0.5310000111348927, 0.9010000452399254], "steps": [72, 213, 16, 233, 48], "results": [1, 0, 0, 1, 1]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.0449999244883657, 0.9089999850839376, -1.0669999229721725, -1.0309999254532158, 0.9089999850839376], "steps": [22, 44, 33, 15, 44], "results": [0, 1, 0, 0, 1]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9009999856352806, 0.9150000442750752, 0.9009999856352806, 0.9250000435858965, 0.9209999842569232], "steps": [48, 41, 48, 36, 38], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.8929999861866236, 0.9110000445507467, -1.0769999222829938, -1.0809999220073223, -1.0309999254532158], "steps": [52, 43, 38, 40, 15], "results": [1, 1, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7769999941810966, 0.6610000617802143, 0.8049999922513962, 0.9230000437237322, 0.7570000551640987], "steps": [110, 168, 96, 37, 120], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [0.805000051856041], "steps": [96], "results": [1]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.7969999928027391], "steps": [100], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.8209999911487103], "steps": [88], "results": [1]}, "DeadComing_3.yaml": {"rewards": [-1.0309999254532158], "steps": [15], "results": [0]}, "DeadComing_4.yaml": {"rewards": [0.8749999874271452], "steps": [61], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.6930000595748425], "steps": [152], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.9069999852217734], "steps": [45], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.4430000171996653], "steps": [277], "results": [1]}, "RedWall_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [0.6390000632964075], "steps": [179], "results": [1]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.7210000576451421, 0.3510000235401094, 0.6930000595748425, -1.0019999309442937, 0.2590000298805535], "steps": [138, 323, 152, 500, 369], "results": [1, 1, 1, 0, 1]}, "YellowOverGreen_1.yaml": {"rewards": [1.8420000281184912], "steps": [77], "results": [1]}, "YellowOverGreen_2.yaml": {"rewards": [1.8780000852420926], "steps": [59], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.8579999674111605], "steps": [69], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.907999963965267], "steps": [44], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.9220000226050615], "steps": [37], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.810000030323863], "steps": [93], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.7859999723732471], "steps": [105], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [2.857000159099698], "steps": [69], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [1.8339999690651894], "steps": [81], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.833000160753727], "steps": [81], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.8360000881366432], "steps": [80], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [0.9189999843947589], "steps": [39], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240001756697893], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9549999819137156], "steps": [21], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.956000054255128], "steps": [20], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [0.9649999812245369], "steps": [16], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [1.9200000567361712], "steps": [38], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9549999819137156, 0.9229999841190875, 0.6110000652261078, 0.9090000446885824, 0.9230000437237322, 0.9029999854974449, 0.649000003002584, 0.9569999817758799, 0.7829999937675893, 0.996999979019165], "steps": [21, 37, 193, 44, 37, 47, 174, 20, 107, 0], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.9229999841190875, 0.48100001458078623, 0.6390000036917627, 0.9530000416561961, 0.9509999821893871, -1.0019999309442937, 0.5110000125132501, 0.8030000519938767, 0.8950000456534326, 0.8710000473074615], "steps": [37, 258, 179, 22, 23, 500, 243, 97, 51, 63], "results": [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]}, "Goal_on_platform_1.yaml": {"rewards": [0.8789999531581998, -1.003999930806458, -1.003999930806458, 0.2149999989196658, 0.44700004253536463], "steps": [29, 250, 250, 195, 137], "results": [1, 0, 0, 1, 1]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [0.5950000323355198, 0.7669999608770013, 0.7670000204816461, -1.003999930806458, 0.810999957844615], "steps": [100, 57, 57, 250, 46], "results": [1, 1, 1, 0, 1]}, "Goal_on_platform_4.yaml": {"rewards": [0.6630000309087336, 0.6256666979752481, 0.33233336778357625, 0.575000031851232, 0.36166670080274343], "steps": [125, 139, 249, 158, 238], "results": [1, 1, 1, 1, 1]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, 0.23500003153458238, 0.3850000808015466, 0.3810000214725733, -1.0019999309442937], "steps": [499, 381, 306, 308, 500], "results": [0, 1, 1, 1, 0]}, "Goal_on_platform_6.yaml": {"rewards": [0.7910000188276172, -1.003999930806458, 0.015000072307884693, -1.003999930806458, 0.027000071480870247], "steps": [51, 250, 245, 250, 242], "results": [1, 0, 1, 0, 1]}, "Wall_with_ramp_1.yaml": {"rewards": [0.595000006724149], "steps": [201], "results": [1]}, "Wall_with_ramp_2.yaml": {"rewards": [0.3269999912008643], "steps": [167], "results": [1]}, "Wall_with_obstacle_1.yaml": {"rewards": [0.44900007639080286], "steps": [274], "results": [1]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9229999841190875], "steps": [37], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9249999839812517], "steps": [36], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [0.8470000489614904], "steps": [75], "results": [1]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [0.6470000031404197], "steps": [175], "results": [1]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.7329999972134829], "steps": [132], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.05100010382011533], "steps": [473], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "WallTransparent_middle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Navigation_1.yaml": {"rewards": [1.6179999839514494, 1.8000000310130417, 1.7740000924095511, 1.7520000343210995, 1.8600000268779695], "steps": [189, 98, 111, 122, 68], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [1.6900000385940075, 1.7679999736137688, 1.8060000305995345, 1.7400000947527587, 1.8020000904798508], "steps": [153, 114, 95, 128, 97], "results": [1, 1, 1, 1, 1]}, "Navigation_3.yaml": {"rewards": [1.1980000725015998, 1.796000090893358, 1.8679999667219818, 1.7240000362508, 1.907999963965267], "steps": [399, 100, 64, 136, 44], "results": [1, 1, 1, 1, 1]}, "Navigation_4.yaml": {"rewards": [1.68399997940287, 1.3840001192875206, 1.4600000544451177, 1.6279999832622707, 1.1100000785663724], "steps": [156, 306, 268, 184, 443], "results": [1, 1, 1, 1, 1]}, "Navigation_5.yaml": {"rewards": [1.9040000238455832, 1.8980000242590904, 1.8419999685138464, 1.8039999711327255, 1.645999982021749], "steps": [46, 49, 77, 96, 175], "results": [1, 1, 1, 1, 1]}, "Navigation_6.yaml": {"rewards": [1.8920000246725976, 1.416000057477504, 1.7139999773353338, 1.826000029221177, -0.0029999520629644394], "steps": [52, 290, 141, 85, 500], "results": [1, 1, 1, 1, 0.5]}, "Navigation_7.yaml": {"rewards": [1.8439999683760107, 1.7920000315643847, 1.6979999784380198, 1.7359999758191407, 1.570000046864152], "steps": [76, 102, 149, 130, 213], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [1.6040000445209444, 1.8380000283941627, 1.6240001027472317, 1.8279999694786966, 1.2500000093132257], "steps": [196, 79, 186, 84, 373], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [1.5639999876730144, 1.8340000286698341, 1.68399997940287, 1.77799997292459, 1.7220000363886356], "steps": [216, 81, 156, 109, 137], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [1.7219999767839909, 1.5920000453479588, 1.7439999752677977, 1.3300000634044409, 1.6540000410750508], "steps": [137, 202, 126, 333, 171], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_3.yaml": {"rewards": [1.6920000980608165, 1.6899999789893627, 1.8320000288076699, 1.2720000077970326, 1.1640000748448074], "steps": [152, 153, 82, 362, 416], "results": [1, 1, 1, 1, 1]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.9999999310821295, -0.0029999520629644394, 1.848000027704984, 1.6819999795407057, 1.3760001198388636], "steps": [499, 500, 74, 157, 310], "results": [0, 0.5, 1, 1, 1]}, "Navigation_on_splitted_arena_1.yaml": {"rewards": [1.5440000486560166, 1.6899999789893627, 1.939999961759895, 1.5439999890513718, 1.6820000391453505], "steps": [226, 153, 28, 226, 157], "results": [1, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_2.yaml": {"rewards": [1.0680001410655677, -0.0029999520629644394, 1.6639999807812274, 1.8519999678246677, -0.7679998958483338], "steps": [464, 500, 166, 72, 383], "results": [1, 0.5, 1, 1, 0]}, "Navigation_on_splitted_arena_3.yaml": {"rewards": [1.6720000398345292, 1.8920000246725976, 1.9040000238455832, 1.3360001225955784, 1.4380000559613109], "steps": [162, 52, 46, 330, 279], "results": [1, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_4.yaml": {"rewards": [-0.5759999686852098, 1.6140000438317657, 1.1100000785663724, 1.6820000391453505, 1.7140000965446234], "steps": [287, 191, 443, 157, 141], "results": [0, 1, 1, 1, 1]}, "Navigation_on_splitted_arena_5.yaml": {"rewards": [1.7800000323913991, 1.8060000305995345, 1.0400000237859786, 1.2100000120699406, 1.88599996548146], "steps": [108, 95, 478, 393, 55], "results": [1, 1, 1, 1, 1]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [-1.3059999532997608], "steps": [152], "results": [0]}, "CenterMoat_2.yaml": {"rewards": [0.772999994456768], "steps": [112], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.2770000286400318], "steps": [360], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [0.718999998178333], "steps": [139], "results": [1]}, "Ring_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [0.24699999834410846], "steps": [563], "results": [1]}, "CenterMoatBlocked_3.yaml": {"rewards": [0.6589999343268573], "steps": [254], "results": [1]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [0.7449999963864684, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [126, 500, 500, 500, 500], "results": [1, 0, 0, 0, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "ChessBoard_3.yaml": {"rewards": [-4.427000202704221, -1.839000043924898, 0.5736666298471391, 0.5363333467394114, -1.7563333814032376], "steps": [332, 168, 35, 37, 210], "results": [0, 0, 1, 1, 0]}, "ChessBoard_4.yaml": {"rewards": [0.4696666346862912, -1.419666700065136, -0.5410000062547624, -2.5930000920780003, -3.6876667952165008], "steps": [77, 225, 209, 295, 359], "results": [1, 0, 0, 0, 0]}, "Labyrinth_1.yaml": {"rewards": [0.7181110926903784, -0.2956667165271938, -7.312444587470964, -1.9796667711343616, -6.659111310727894], "steps": [33, 180, 750, 343, 750], "results": [1, 0, 0, 0, 0]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [-7.380000069737434, -3.59233332099393, 0.5309999817982316, 0.5556666497141123, -0.8496666778810322], "steps": [499, 348, 33, 34, 120], "results": [0, 0, 1, 1, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7630000533536077], "steps": [38], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [-0.8049999224022031], "steps": [150], "results": [0]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.6869999933987856], "steps": [37], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-1.1720000561326742], "steps": [42], "results": [0]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-1.6400000238791108], "steps": [159], "results": [0]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [-1.4040000401437283], "steps": [100], "results": [0]}, "Goal_in_DeathZone_5.yaml": {"rewards": [-1.3880000412464142], "steps": [96], "results": [0]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.5310000367462635], "steps": [116], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8050000448711216], "steps": [46], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.3843333818949759], "steps": [83], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.040333344135433435], "steps": [235], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.08166665863245726], "steps": [111], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.6303333761170506], "steps": [40], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.8060000305995345, 1.718000096268952, 1.6019999850541353, 1.198000012896955, 1.8259999696165323, 1.5260000498965383, 1.8600000268779695, 1.3020000653341413, -0.0029999520629644394, -1.0019999309442937], "steps": [95, 139, 197, 399, 85, 235, 68, 347, 500, 500], "results": [1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.0009999265894293785, -1.003999930806458, 1.618000035174191, 1.0580000737681985, 1.4179999893531203, 1.6299999747425318, -0.004999926313757896, 1.0900000715628266, 1.6060000360012054, 1.2540000602602959], "steps": [249, 250, 94, 234, 144, 91, 250, 226, 97, 185], "results": [0.5, 0, 1, 1, 1, 1, 0.5, 1, 1, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.6070000315085053, 0.3070000521838665, 0.7910000188276172, 0.9070000108331442, 0.9030000111088157, 0.643000029027462, 0.419000044465065, 0.8830000124871731, 0.9390000086277723, 0.46699998155236244], "steps": [97, 172, 51, 22, 23, 88, 144, 28, 14, 132], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_2.yaml": {"rewards": [0.4910000395029783, 0.6630000276491046, -1.003999930806458, 0.9310000091791153, 0.5149999782443047, -1.003999930806458, -1.003999930806458, -1.003999930806458, 0.875000013038516, 0.9230000097304583], "steps": [126, 83, 250, 16, 120, 250, 250, 250, 30, 18], "results": [1, 1, 0, 1, 1, 0, 0, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.7990000145509839, 0.7589999539777637, 0.8056666813790798, 0.6656666779890656, 0.7990000145509839, 0.7723333472386003, 0.35900000389665365, 0.7456666799262166, 0.49899994768202305, 0.7856666212901473], "steps": [29, 35, 28, 49, 29, 33, 95, 37, 74, 31], "results": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.7390000279992819, 0.2890000380575657, -1.0099999774247408, 0.449000034481287, 0.25900003872811794, 0.31900003738701344, -1.0099999774247408, 0.8590000253170729, -1.0099999774247408, -1.0099999774247408], "steps": [25, 70, 100, 54, 73, 67, 100, 13, 100, 100], "results": [1, 1, 0, 1, 1, 1, 0, 1, 0, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8910000119358301], "steps": [26], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [0.710999964736402], "steps": [71], "results": [1]}, "forcedChoice_3.yaml": {"rewards": [0.7549999617040157], "steps": [60], "results": [1]}, "forcedChoice_4.yaml": {"rewards": [0.818999957293272], "steps": [44], "results": [1]}, "forcedChoice_5.yaml": {"rewards": [0.8629999542608857], "steps": [33], "results": [0]}}}, "level_01_food": 0.7365079365079364, "level_02_preferences": 1.0, "level_03_obstacles": 0.6954545454545454, "level_04_avoidance": 0.4052631578947368, "level_05_spatial_reasoning": 0.85, "level_06_generalization": 0.8, "level_07_internal_memory": 0.8, "level_09_advanced_preferences": 0.8, "mean_score": 0.7609032049821524}