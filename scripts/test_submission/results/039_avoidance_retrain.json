{"elapsed_time": 1860.5267493724823, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.07150005735456944, 0.003500032238662243, 0.199500048533082, 0.42750000301748514, 0.1955000190064311], "steps": [106, 123, 74, 17, 75], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.8310000160709023, 0.4830000400543213, 0.8549999548122287, 0.8950000116601586, 0.43100004363805056], "steps": [41, 128, 35, 25, 141], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.718000096268952, 1.85800008662045, 1.1980001321062446, 1.8659999668598175, 1.5780001059174538], "steps": [69, 34, 199, 32, 104], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.7490000473335385, 2.753000047057867, 2.729000048711896, 2.265000080689788, 2.9010002752766013], "steps": [61, 60, 66, 182, 23], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.7000001231208444, 3.8720001112669706, 3.752000357955694, 3.696000123396516, -1.003999930806458], "steps": [73, 30, 60, 74, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoal_size5.yaml": {"rewards": [4.282999747432768, 4.510999731719494, 4.851000185124576, 4.511000208556652, 4.235000227577984], "steps": [177, 120, 35, 120, 189], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.08350005652755499, 0.06750002782791853, 0.4475000314414501, 0.039500029757618904, 0.31950001046061516], "steps": [103, 107, 12, 114, 44], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.643000029027462, 0.8430000152438879, -1.003999930806458, 0.7750000199303031, 0.47500004060566425], "steps": [88, 38, 250, 55, 130], "results": [1, 1, 0, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.8019999712705612, 1.7900000913068652, 1.745999975129962, 1.8379999687895179, -1.003999930806458], "steps": [48, 51, 62, 39, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.6810000520199537, 2.7570002852007747, 2.8970000371336937, 2.9130000360310078, 2.8890000376850367], "steps": [78, 59, 24, 20, 26], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.688000123947859, 3.936000106856227, 3.6240003667771816, 3.612000129185617, 3.596000368706882], "steps": [76, 14, 92, 95, 99], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.766999714076519, 4.370999741367996, 4.523000207729638, 4.647000199183822, 4.65100019890815], "steps": [56, 155, 117, 86, 85], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [-0.4964999333024025, -0.23249995149672031, 0.2635000143200159, 0.011500061489641666, -0.028499935753643513], "steps": [248, 182, 58, 121, 131], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [-0.9999999310821295, 0.8829999528825283, 0.41100004501640797, 0.7149999644607306, 0.49099997989833355], "steps": [249, 28, 146, 70, 126], "results": [0, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [-0.9999999310821295, 4.479000210762024, 4.166999755427241, 4.779000190086663, 4.923000180162489], "steps": [249, 128, 206, 53, 17], "results": [0, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [0.3715000068768859, 0.06350002810359001, 0.2635000143200159, -0.4564999360591173, -1.003999930806458], "steps": [31, 108, 58, 238, 250], "results": [1, 1, 1, 1, 0]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.7229999639093876, 0.04700001049786806, 0.7150000240653753, 0.8430000152438879, 0.3310000505298376], "steps": [68, 237, 70, 38, 166], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.863000184297562, -1.003999930806458, 4.49499973282218, 4.983000176027417, 4.758999714627862], "steps": [32, 250, 124, 2, 58], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8369999900460243, -1.0730000417679548, 0.8489999892190099, 0.9149999846704304, 0.7489999961107969], "steps": [80, 36, 74, 41, 124], "results": [1, 0, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9029999854974449, 0.7650000546127558, 0.8850000463426113, 0.6030000657774508, 0.8769999872893095], "steps": [47, 116, 56, 197, 60], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.6210000049322844, 0.888999986462295, 0.6990000591613352, -1.2850000271573663, 0.8069999921135604], "steps": [188, 54, 149, 142, 95], "results": [1, 1, 1, 0, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [-1.0650000423192978, 0.6929999999701977, -1.4389998973347247, 0.8610000479966402, 0.8069999921135604], "steps": [32, 152, 219, 68, 95], "results": [0, 1, 0, 1, 1]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [-0.1379998796619475, -1.1689999159425497, 1.2960000573657453, -0.09999994188547134, 0.6589999343268573], "steps": [68, 84, 350, 49, 169], "results": [0, 0, 0.5, 0, 0]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9249999839812517, 0.6630000020377338, 0.9249999839812517, 0.9189999843947589, -1.1909999144263566], "steps": [36, 167, 36, 39, 95], "results": [1, 1, 1, 1, 0]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8470000489614904, 0.5850000670179725, 0.8289999905973673, -1.0649999231100082, -1.0509999240748584], "steps": [75, 206, 84, 32, 25], "results": [1, 1, 1, 0, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [-1.04699992435053, 0.9090000446885824, 0.9149999846704304, -0.1300000250339508, -1.0849999217316508], "steps": [23, 44, 41, 64, 42], "results": [0, 1, 1, 0, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.9030000451020896, 0.8929999861866236, 0.9249999839812517, 0.9189999843947589, 0.9190000439994037], "steps": [47, 52, 36, 39, 39], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [0.9110000445507467, 0.9009999856352806, -2.0639999955892563, -1.0449999244883657, -1.0769999222829938], "steps": [43, 48, 32, 22, 38], "results": [1, 1, 0, 0, 0]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [-1.116999919526279, 0.8529999889433384, -1.0489999242126942, 0.9149999846704304, -1.0209999261423945], "steps": [58, 72, 24, 41, 10], "results": [0, 1, 0, 1, 0]}, "RedHouse_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-1.0649999231100082], "steps": [32], "results": [0]}, "RedHouse_6.yaml": {"rewards": [-1.1030000397004187], "steps": [51], "results": [0]}, "RedHouse_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.9330000430345535], "steps": [32], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.934999983292073], "steps": [31], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.929000043310225], "steps": [34], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.926999983843416], "steps": [35], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [0.7930000526830554], "steps": [102], "results": [1]}, "HidingGoal_2.yaml": {"rewards": [0.8070000517182052], "steps": [95], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [0.209000033326447], "steps": [394], "results": [1]}, "RedWall_1.yaml": {"rewards": [0.9190000439994037], "steps": [39], "results": [1]}, "RedWall_2.yaml": {"rewards": [-1.2189999124966562], "steps": [109], "results": [0]}, "RedWall_3.yaml": {"rewards": [-1.1350000374950469], "steps": [67], "results": [0]}, "RedWall_4.yaml": {"rewards": [0.8930000457912683], "steps": [52], "results": [1]}, "RedWall_5.yaml": {"rewards": [-1.2650000285357237], "steps": [132], "results": [0]}, "RedWall_6.yaml": {"rewards": [0.8790000467561185], "steps": [59], "results": [1]}, "RedWall_7.yaml": {"rewards": [0.7389999967999756], "steps": [129], "results": [1]}, "RedRandomWall.yaml": {"rewards": [0.8629999882541597, 0.6830000006593764, 0.6030000657774508, -1.2490000296384096, -1.0770000414922833], "steps": [67, 157, 197, 124, 38], "results": [1, 1, 1, 0, 0]}, "YellowOverGreen_1.yaml": {"rewards": [0.5530000096186996], "steps": [222], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [1.6040000445209444], "steps": [196], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.729999976232648], "steps": [133], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.4199999975971878], "steps": [288], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.2160000116564333], "steps": [390], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.5680000470019877], "steps": [214], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.1620000153779984], "steps": [417], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "YellowOverGreen_9.yaml": {"rewards": [0.9689999809488654], "steps": [14], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.445000068284571], "steps": [275], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.3360000969842076], "steps": [330], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [1.6480001946911216], "steps": [174], "results": [1]}, "Green_sizes12_4.yaml": {"rewards": [1.952000173740089], "steps": [22], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.968000172637403], "steps": [14], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.594000079203397], "steps": [201], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [1.9460001741535962], "steps": [25], "results": [1]}, "Green_sizes12_10.yaml": {"rewards": [0.9510000417940319], "steps": [23], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9729999806731939], "steps": [12], "results": [1]}}, "03_obstacles": {"Obstacles.yaml": {"rewards": [0.9550000415183604, 0.9189999843947589, -1.0019999309442937, -1.0019999309442937, 0.9250000435858965, 0.764999995008111, 0.8409999897703528, 0.9590000412426889, 0.8230000506155193, 0.996999979019165], "steps": [21, 39, 500, 500, 36, 116, 78, 19, 87, 0], "results": [1, 1, 0, 0, 1, 1, 1, 1, 1, 1]}, "objectManipulation.yaml": {"rewards": [0.6850000601261854, 0.8869999866001308, 0.7669999948702753, 0.9509999821893871, 0.9489999823272228, 0.8049999922513962, -1.0019999309442937, 0.7429999965243042, 0.6170000052079558, -1.0019999309442937], "steps": [156, 55, 115, 23, 24, 96, 500, 127, 190, 500], "results": [1, 1, 1, 1, 1, 1, 0, 1, 1, 0]}, "Goal_on_platform_1.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_4.yaml": {"rewards": [-0.9999999892897904, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965, -1.0026666559278965], "steps": [374, 375, 375, 375, 375], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_5.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Goal_on_platform_6.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, -1.003999930806458, -1.003999930806458, -1.003999930806458], "steps": [249, 250, 250, 250, 250], "results": [0, 0, 0, 0, 0]}, "Wall_with_ramp_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_ramp_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "Wall_with_obstacle_1.yaml": {"rewards": [0.6250000046566129], "steps": [186], "results": [1]}, "Wall_with_obstacle_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_4.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_obstacle_6.yaml": {"rewards": [-0.9999999892897904], "steps": [374], "results": [0]}, "Wall_with_obstacle_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_1.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [1]}, "Wall_with_tunnel_2.yaml": {"rewards": [0.9250000435858965], "steps": [36], "results": [1]}, "Wall_with_tunnel_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_with_tunnel_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Wall_middle.yaml": {"rewards": [0.8509999890811741], "steps": [73], "results": [1]}, "WallTransparent_middle_1.yaml": {"rewards": [0.8430000492371619], "steps": [77], "results": [1]}, "WallTransparent_middle_2.yaml": {"rewards": [0.8249999908730388], "steps": [86], "results": [1]}, "WallTransparent_middle_3.yaml": {"rewards": [0.6830000006593764], "steps": [157], "results": [1]}, "Navigation_1.yaml": {"rewards": [1.810000030323863, 1.6900000385940075, 1.8080000304616988, 1.3100000647827983, 1.7260000361129642], "steps": [93, 153, 94, 343, 135], "results": [1, 1, 1, 1, 1]}, "Navigation_2.yaml": {"rewards": [-0.0009999522008001804, 1.8920000246725976, -0.0029999520629644394, 1.3520000618882477, -1.0019999309442937], "steps": [499, 52, 500, 322, 500], "results": [0.5, 1, 0.5, 1, 0]}, "Navigation_3.yaml": {"rewards": [-0.000999892596155405, -0.0029999520629644394, -0.0029999520629644394, -0.002999892458319664, -0.0029999520629644394], "steps": [499, 500, 500, 500, 500], "results": [0.5, 0.5, 0.5, 0.5, 0.5]}, "Navigation_4.yaml": {"rewards": [1.4600000544451177, -0.0029999520629644394, 1.0660000815987587, -0.0029999520629644394, 1.2440000693313777], "steps": [268, 500, 465, 500, 376], "results": [1, 0.5, 1, 0.5, 1]}, "Navigation_5.yaml": {"rewards": [1.5100000509992242, -0.0029999520629644394, 1.516000050585717, -0.0029999520629644394, 1.8719999664463103], "steps": [243, 500, 240, 500, 62], "results": [1, 0.5, 1, 0.5, 1]}, "Navigation_6.yaml": {"rewards": [1.8519999678246677, -0.002999892458319664, 1.5200000503100455, 1.5900000454857945, 1.1180001376196742], "steps": [72, 500, 238, 203, 439], "results": [1, 0.5, 1, 1, 1]}, "Navigation_7.yaml": {"rewards": [1.6580000407993793, 1.591999985743314, 1.650000100955367, 1.8559999675489962, 1.0440000831149518], "steps": [169, 202, 173, 70, 476], "results": [1, 1, 1, 1, 1]}, "Navigation_8.yaml": {"rewards": [-0.000999892596155405, 1.4600000544451177, 1.1280000773258507, 1.7900000317022204, 1.1740000741556287], "steps": [499, 268, 434, 103, 411], "results": [0.5, 1, 1, 1, 1]}, "Navigation_on_platform_1.yaml": {"rewards": [-0.000999892596155405, -0.0029999520629644394, 1.5400001085363328, -0.0029999520629644394, 1.4940000521019101], "steps": [499, 500, 228, 500, 251], "results": [0.5, 0.5, 1, 0.5, 1]}, "Navigation_on_platform_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -0.0029999520629644394, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0.5, 0]}, "Navigation_on_platform_3.yaml": {"rewards": [-0.9999999310821295, -0.0029999520629644394, -0.0029999520629644394, -0.0029999520629644394, -1.4669998954050243], "steps": [499, 500, 500, 500, 233], "results": [0, 0.5, 0.5, 0.5, 0]}, "Navigation_on_platform_4.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}}, "04_avoidance": {"CenterMoat_1.yaml": {"rewards": [0.8609999883919954], "steps": [68], "results": [1]}, "CenterMoat_2.yaml": {"rewards": [0.818999991286546], "steps": [89], "results": [1]}, "CenterMoat_3.yaml": {"rewards": [0.595000006724149], "steps": [201], "results": [1]}, "CenterMoat_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_1.yaml": {"rewards": [-1.4139998266473413], "steps": [206], "results": [0]}, "Ring_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "Ring_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_1.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RingBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "RingBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_1.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_2.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_3.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "CenterMoatBlocked_4.yaml": {"rewards": [-0.9999999892897904], "steps": [749], "results": [0]}, "ChessBoard_1.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, 0.32300008507445455, 0.7969999928027391, -1.0019999309442937], "steps": [499, 500, 337, 100, 500], "results": [0, 0, 1, 1, 0]}, "ChessBoard_2.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, 0.8129999917000532], "steps": [499, 500, 500, 500, 92], "results": [0, 0, 0, 0, 1]}, "ChessBoard_3.yaml": {"rewards": [0.7116666478104889, -4.034999989904463, 0.8336666487157345, 0.929000043310225, 0.7343333689495921], "steps": [36, 266, 35, 34, 48], "results": [1, 0, 1, 1, 1]}, "ChessBoard_4.yaml": {"rewards": [0.05499996151775122, 0.7429999820888042, 0.7656667083501816, 0.7616666527464986, 0.6623333245515823], "steps": [51, 37, 39, 51, 94], "results": [1, 1, 1, 1, 1]}, "Labyrinth_1.yaml": {"rewards": [0.7212222039233893, 0.7167777593713254, 0.7109999810345471, 0.7167777591384947, 0.7212222036905587], "steps": [34, 34, 35, 34, 34], "results": [1, 1, 1, 1, 1]}, "Labyrinth_2.yaml": {"rewards": [-0.9999999892897904, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434, -1.0013333226088434], "steps": [749, 750, 750, 750, 750], "results": [0, 0, 0, 0, 0]}, "Labyrinth_3.yaml": {"rewards": [-0.9999999310821295, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937, -1.0019999309442937], "steps": [499, 500, 500, 500, 500], "results": [0, 0, 0, 0, 0]}, "Labyrinth_4.yaml": {"rewards": [0.5116667058318853, 0.5403333767317235, 0.5136666498146951, 0.10433338535949588, -0.3323332783766091], "steps": [36, 35, 45, 113, 128], "results": [1, 1, 1, 1, 0]}, "Goal_in_HotZone_1.yaml": {"rewards": [0.7576666576787829], "steps": [36], "results": [1]}, "Goal_in_HotZone_2.yaml": {"rewards": [0.7349999928846955], "steps": [35], "results": [1]}, "Goal_in_HotZone_3.yaml": {"rewards": [0.712333326227963], "steps": [34], "results": [1]}, "Goal_in_DeathZone_1.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [1]}, "Goal_in_DeathZone_4.yaml": {"rewards": [0.8270000163465738], "steps": [42], "results": [1]}, "Goal_in_DeathZone_5.yaml": {"rewards": [0.7829999597743154], "steps": [53], "results": [1]}, "Goal_in_DeathZone_6.yaml": {"rewards": [0.651000028476119], "steps": [86], "results": [1]}, "Goal_behind_HotZone_1.yaml": {"rewards": [0.8470000415109098], "steps": [35], "results": [1]}, "Goal_behind_HotZone_2.yaml": {"rewards": [0.8296666508540511], "steps": [37], "results": [1]}, "Goal_behind_HotZone_3.yaml": {"rewards": [0.8429999840445817], "steps": [37], "results": [1]}, "Goal_behind_HotZone_4.yaml": {"rewards": [0.7763333166949451], "steps": [37], "results": [1]}, "Goal_behind_HotZone_5.yaml": {"rewards": [0.6863333168439567], "steps": [42], "results": [1]}}, "05_spatial_reasoning": {"SpatialReasoning.yaml": {"rewards": [1.7120000370778143, -1.0019999309442937, -0.0029999520629644394, -0.002999892458319664, -0.0029999520629644394, 1.4079999984242022, 1.5380000490695238, 1.3000000058673322, 1.553999988362193, -0.0029999520629644394], "steps": [142, 500, 500, 500, 500, 294, 229, 348, 221, 500], "results": [1, 0, 0.5, 0.5, 0.5, 1, 1, 1, 1, 0.5]}}, "06_generalization": {"Generalization.yaml": {"rewards": [-0.9999999310821295, -1.003999930806458, 1.2779999990016222, -0.004999926313757896, -1.003999930806458, 1.8219999615103006, -0.004999985918402672, -0.004999926313757896, -1.003999930806458, 1.410000049509108], "steps": [249, 250, 179, 250, 250, 43, 250, 250, 250, 146], "results": [0, 0, 1, 0.5, 0, 1, 0.5, 0.5, 0, 1]}}, "07_internal_memory": {"InternalMemory_1.yaml": {"rewards": [0.7750000199303031, 0.5549999754875898, 0.926999949850142, 0.09900006651878357, 0.9429999487474561, 0.08300000801682472, 0.9390000086277723, -1.003999930806458, 0.8989999517798424, -1.003999930806458], "steps": [55, 110, 17, 224, 13, 228, 14, 250, 24, 250], "results": [1, 1, 1, 1, 1, 1, 1, 0, 1, 0]}, "InternalMemory_2.yaml": {"rewards": [0.5150000378489494, 0.2150000585243106, 0.7629999611526728, 0.5630000345408916, 0.8870000122115016, 0.859000014141202, -1.003999930806458, -1.003999930806458, 0.5110000381246209, 0.8710000133141875], "steps": [120, 195, 58, 108, 27, 34, 250, 250, 121, 31], "results": [1, 1, 1, 1, 1, 1, 0, 0, 1, 1]}, "InternalMemory_3.yaml": {"rewards": [0.5523332823067904, 0.4990000072866678, -1.0066666910424829, 0.19233333319425583, -1.0066666910424829, 0.7590000135824084, 0.2123332740738988, 0.3589999442920089, 0.17233327310532331, 0.3390000034123659], "steps": [66, 74, 150, 120, 150, 35, 117, 95, 123, 98], "results": [1, 1, 0, 1, 0, 1, 1, 1, 1, 1]}, "InternalMemory_4.yaml": {"rewards": [0.24900003895163536, -1.0099999774247408, 0.8590000253170729, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, -1.0099999774247408, 0.2790000382810831, 0.5290000326931477, -1.0099999774247408], "steps": [74, 100, 13, 100, 100, 100, 100, 71, 46, 100], "results": [1, 0, 1, 0, 0, 0, 0, 1, 1, 0]}}, "09_advanced_preferences": {"forcedChoice_1.yaml": {"rewards": [0.8790000127628446], "steps": [29], "results": [1]}, "forcedChoice_2.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_3.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_4.yaml": {"rewards": [-0.9999999310821295], "steps": [249], "results": [0]}, "forcedChoice_5.yaml": {"rewards": [0.859000014141202], "steps": [34], "results": [0]}}}, "level_01_food": 0.7158730158730159, "level_02_preferences": 1.0, "level_03_obstacles": 0.41538461538461535, "level_04_avoidance": 0.5578947368421052, "level_05_spatial_reasoning": 0.7, "level_06_generalization": 0.45, "level_07_internal_memory": 0.7000000000000001, "level_09_advanced_preferences": 0.2, "mean_score": 0.592394046012467}