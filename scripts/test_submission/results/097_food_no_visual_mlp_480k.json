{"elapsed_time": 320.59085035324097, "results": {"01_food": {"GoodGoal_size05.yaml": {"rewards": [0.21550004743039608, 0.08750002644956112, 0.25150004494935274, -0.00849996693432331, 0.12350005377084017], "steps": [70, 102, 61, 126, 93], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size1.yaml": {"rewards": [0.875000013038516, 0.5990000320598483, 0.8390000155195594, 0.6670000273734331, 0.694999965839088], "steps": [30, 99, 39, 82, 75], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size2.yaml": {"rewards": [1.7139999773353338, 1.8499999679625034, 1.8659999668598175, 1.6059999847784638, 1.6620001001283526], "steps": [70, 36, 32, 97, 83], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size3.yaml": {"rewards": [2.6570002920925617, 2.605000295676291, 2.761000046506524, 2.8650000393390656, 2.9050000365823507], "steps": [84, 97, 58, 32, 22], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size4.yaml": {"rewards": [3.752000119537115, 3.8720003496855497, 3.7480003582313657, 3.6720001250505447, 3.5080003747716546], "steps": [60, 30, 61, 80, 121], "results": [1, 1, 1, 1, 1]}, "GoodGoal_size5.yaml": {"rewards": [4.57499972730875, 4.603000202216208, 4.686999719589949, 4.643000199459493, 4.719000194221735], "steps": [104, 97, 76, 87, 68], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size05.yaml": {"rewards": [0.2635000143200159, 0.36350003723055124, 0.45150003116577864, 0.11950005404651165, 0.25550001487135887], "steps": [58, 33, 11, 94, 60], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size1.yaml": {"rewards": [0.7030000248923898, 0.8150000171735883, 0.8430000152438879, 0.7550000213086605, 0.759000021032989], "steps": [73, 45, 38, 60, 59], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size2.yaml": {"rewards": [1.729999976232648, 1.8979999646544456, 1.6739999800920486, 1.845999968238175, 1.653999981470406], "steps": [66, 24, 80, 37, 85], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size3.yaml": {"rewards": [2.5490000611171126, 2.7330002868548036, 2.901000036858022, 2.9130000360310078, 2.85300004016608], "steps": [111, 65, 23, 20, 35], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size4.yaml": {"rewards": [3.444000140763819, 3.8160003535449505, 3.652000126428902, 3.752000119537115, 3.668000125326216], "steps": [137, 44, 85, 60, 81], "results": [1, 1, 1, 1, 1]}, "GoodGoalMulti_size5.yaml": {"rewards": [4.67900019697845, 4.2069997526705265, -1.003999930806458, 4.691000196151435, 4.663000198081136], "steps": [78, 196, 250, 75, 82], "results": [1, 1, 0, 1, 1]}, "GoodGoalBounce_size05.yaml": {"rewards": [0.25550001487135887, -0.48849993385374546, -1.003999930806458, -1.003999930806458, -0.060499933548271656], "steps": [60, 246, 250, 250, 139], "results": [1, 1, 0, 0, 1]}, "GoodGoalBounce_size1.yaml": {"rewards": [0.25100005604326725, 0.6550000282004476, 0.7989999586716294, 0.6950000254437327, 0.06700006872415543], "steps": [186, 85, 49, 75, 232], "results": [1, 1, 1, 1, 1]}, "GoodGoalBounce_size5.yaml": {"rewards": [4.763000191189349, 4.650999722070992, 4.803000188432634, 4.8230001870542765, 4.582999726757407], "steps": [57, 85, 47, 42, 102], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size05.yaml": {"rewards": [-0.22449995204806328, -0.028499935753643513, 0.0075000617653131485, -0.05649993382394314, 0.17950004991143942], "steps": [180, 131, 122, 138, 79], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size1.yaml": {"rewards": [0.22699999809265137, 0.8870000122115016, 0.5550000350922346, 0.4350000433623791, 0.49099997989833355], "steps": [192, 27, 110, 140, 126], "results": [1, 1, 1, 1, 1]}, "GoodGoalMultiBounce_size5.yaml": {"rewards": [4.071000238880515, 4.774999713525176, -1.003999930806458, 4.983000176027417, 4.210999752394855], "steps": [230, 54, 250, 2, 195], "results": [1, 1, 0, 1, 1]}, "Labyrinth15_GoodGoal.yaml": {"rewards": [0.8589999885298312, 0.8790000467561185, 0.05300004407763481, 0.9149999846704304, 0.9009999856352806], "steps": [69, 59, 472, 41, 48], "results": [1, 1, 1, 1, 1]}, "Labyrinth15_GoodGoalMulti.yaml": {"rewards": [0.9069999852217734, -1.1809999151155353, 0.8229999910108745, 0.49900001334026456, 0.859000048134476], "steps": [45, 90, 87, 249, 69], "results": [1, 0, 1, 1, 1]}, "Labyrinth30_GoodGoal.yaml": {"rewards": [0.3890000209212303, 0.11100004008039832, 0.49900007294490933, 0.8329999903216958, 0.36700002243742347], "steps": [304, 443, 249, 82, 315], "results": [1, 1, 1, 1, 1]}, "Labyrinth30_GoodGoalMulti.yaml": {"rewards": [0.5210000118240714, 0.7509999959729612, 0.7809999939054251, 0.764999995008111, -1.3790000206790864], "steps": [238, 123, 108, 116, 189], "results": [1, 1, 1, 1, 0]}, "Labyrinth30_GoodGoalMulti4.yaml": {"rewards": [3.240000027231872, 1.9950000056996942, -0.25199987180531025, 1.5960000366903841, 1.9950000056996942], "steps": [377, 500, 125, 200, 500], "results": [1, 0.5, 0, 0.5, 0.5]}, "MovingLabyrinth5_GoodGoal.yaml": {"rewards": [0.9189999843947589, 0.9089999850839376, 0.880999987013638, 0.9129999848082662, 0.9130000444129109], "steps": [39, 44, 58, 42, 42], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoal.yaml": {"rewards": [0.8709999877028167, 0.8709999877028167, -1.0349999251775444, 0.7970000524073839, -1.0609999233856797], "steps": [63, 63, 17, 100, 30], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth15_GoodGoal.yaml": {"rewards": [0.7970000524073839, 0.8409999897703528, -1.0649999231100082, 0.7789999940432608, -1.1070000394247472], "steps": [100, 78, 32, 109, 53], "results": [1, 1, 0, 1, 0]}, "MovingLabyrinth5_GoodGoalMulti.yaml": {"rewards": [0.8969999859109521, 0.7350000566802919, 0.9229999841190875, 0.9229999841190875, 0.9189999843947589], "steps": [50, 131, 37, 37, 39], "results": [1, 1, 1, 1, 1]}, "MovingLabyrinth10_GoodGoalMulti.yaml": {"rewards": [-1.116999919526279, 0.9010000452399254, 0.35700008273124695, 0.8810000466182828, 0.8829999868758023], "steps": [58, 48, 320, 58, 57], "results": [0, 1, 1, 1, 1]}, "MovingLabyrinth15_GoodGoalMulti.yaml": {"rewards": [0.7330000568181276, 0.8070000517182052, 0.8849999867379665, 0.883000046480447, 0.3850000808015466], "steps": [132, 95, 56, 57, 306], "results": [1, 1, 1, 1, 1]}, "RedHouse_1.yaml": {"rewards": [0.40100002009421587], "steps": [298], "results": [1]}, "RedHouse_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedHouse_6.yaml": {"rewards": [1.208000105805695], "steps": [394], "results": [1]}, "RedHouse_7.yaml": {"rewards": [-2.677999953273684], "steps": [339], "results": [0]}, "RedHouse_8.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "DeadComing_1.yaml": {"rewards": [0.8589999885298312], "steps": [69], "results": [1]}, "DeadComing_2.yaml": {"rewards": [0.872999987564981], "steps": [62], "results": [1]}, "DeadComing_3.yaml": {"rewards": [0.883000046480447], "steps": [57], "results": [1]}, "DeadComing_4.yaml": {"rewards": [0.8850000463426113], "steps": [56], "results": [1]}, "HidingGoal_1.yaml": {"rewards": [-1.3989999000914395], "steps": [199], "results": [0]}, "HidingGoal_2.yaml": {"rewards": [0.7929999930784106], "steps": [102], "results": [1]}, "HidingGoal_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_1.yaml": {"rewards": [0.7990000522695482], "steps": [99], "results": [1]}, "RedWall_2.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_3.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_4.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_5.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_6.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedWall_7.yaml": {"rewards": [-0.9999999310821295], "steps": [499], "results": [0]}, "RedRandomWall.yaml": {"rewards": [0.20900009293109179, 0.7929999930784106, -1.0019999309442937, 0.32700008479878306, -1.0019999309442937], "steps": [394, 102, 500, 335, 500], "results": [1, 1, 0, 1, 0]}, "YellowOverGreen_1.yaml": {"rewards": [0.8789999871514738], "steps": [59], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [1.7300000358372927], "steps": [133], "results": [1]}, "YellowOverGreen_3.yaml": {"rewards": [1.7979999715462327], "steps": [99], "results": [1]}, "YellowOverGreen_4.yaml": {"rewards": [1.6720000398345292], "steps": [162], "results": [1]}, "YellowOverGreen_5.yaml": {"rewards": [1.7740000328049064], "steps": [111], "results": [1]}, "YellowOverGreen_6.yaml": {"rewards": [1.6199999838136137], "steps": [188], "results": [1]}, "YellowOverGreen_7.yaml": {"rewards": [1.5859999861568213], "steps": [205], "results": [1]}, "YellowOverGreen_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [0]}, "YellowOverGreen_9.yaml": {"rewards": [1.7339999759569764], "steps": [131], "results": [1]}, "YellowOverGreen_10.yaml": {"rewards": [2.889000156894326], "steps": [53], "results": [1]}, "YellowOverGreen_11.yaml": {"rewards": [1.7160000368021429], "steps": [140], "results": [1]}}, "02_preferences": {"Green_sizes12_1.yaml": {"rewards": [1.926000056322664], "steps": [35], "results": [1]}, "Green_sizes12_2.yaml": {"rewards": [1.9240000564604998], "steps": [36], "results": [1]}, "Green_sizes12_3.yaml": {"rewards": [0.9509999821893871], "steps": [23], "results": [0]}, "Green_sizes12_4.yaml": {"rewards": [1.9500000546686351], "steps": [23], "results": [1]}, "Green_sizes12_5.yaml": {"rewards": [1.972000053152442], "steps": [12], "results": [1]}, "Green_sizes12_6.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_7.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_8.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_9.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "Green_sizes12_10.yaml": {"rewards": [1.9740000530146062], "steps": [11], "results": [1]}, "Green_sizes12_11.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_1.yaml": {"rewards": [0.9749999805353582], "steps": [11], "results": [0]}, "YellowOverGreen_2.yaml": {"rewards": [0.9709999808110297], "steps": [13], "results": [0]}, "YellowOverGreen_3.yaml": {"rewards": [0.9789999802596867], "steps": [9], "results": [0]}, "YellowOverGreen_4.yaml": {"rewards": [0.9769999803975224], "steps": [10], "results": [0]}}}, "level_01_food": 0.6968253968253968, "level_02_preferences": 0.5333333333333333, "mean_score": 0.6150793650793651}